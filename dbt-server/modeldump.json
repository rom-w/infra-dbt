{"state_id": "", "body": {"packages.yml": {"contents": "packages:\n  - package: dbt-labs/metrics\n    version: 1.4.0\n  - package: dbt-labs/dbt_utils\n    version: 1.0.0", "hash": "addd59e75ca76d52b818d147334a558d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/packages.yml"}, "dbt_project.yml": {"contents": "\n# Name your project! Project names should contain only lowercase characters\n# and underscores. A good package name should reflect your organization's\n# name or the intended use of these models\nname: 'test_dbt'\nversion: '1.0.0'\nconfig-version: 2\n\n# This setting configures which \"profile\" dbt uses for this project.\nprofile: 'test_dbt'\n\n# These configurations specify where dbt should look for different types of files.\n# The `model-paths` config, for example, states that models in this project can be\n# found in the \"models/\" directory. You probably won't need to change these!\nmodel-paths: [\"models\"]\nanalysis-paths: [\"analyses\"]\ntest-paths: [\"tests\"]\nseed-paths: [\"seeds\"]\nmacro-paths: [\"macros\"]\nsnapshot-paths: [\"snapshots\"]\n\ntarget-path: \"target\"  # directory which will store compiled SQL files\nclean-targets:         # directories to be removed by `dbt clean`\n  - \"target\"\n  - \"dbt_packages\"\n\n\n# Configuring models\n# Full documentation: https://docs.getdbt.com/docs/configuring-models\n\n# In this example config, we tell dbt to build all models in the example/\n# directory as views. These settings can be overridden in the individual model\n# files using the `{{ config(...) }}` macro.\nmodels:\n  test_dbt:\n    # Config indicated by + and applies to all files under models/example/\n    example:\n      +materialized: view\n", "hash": "b6117bcb223fba5c1cffd8b5bcd1d0c5", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_project.yml"}, "models/example/schema.yml": {"contents": "\nversion: 2\n\nmodels:\n  - name: my_first_dbt_model\n    description: \"A starter dbt model\"\n    columns:\n      - name: id\n        description: \"The primary key for this table\"\n        tests:\n          - unique\n          - not_null\n      - name: name\n      - name: date_id\n      - name: score\n\n  - name: my_second_dbt_model\n    description: \"A starter dbt model\"\n    columns:\n      - name: id\n        description: \"The primary key for this table\"\n        tests:\n          - unique\n          - not_null\n\n#  - name: my_python_model\n#    description: \"A starter dbt model\"\n#    columns:\n#      - name: id\n#        description: \"The primary key for this table\"\n#        tests:\n#          - unique\n#          - not_null", "hash": "de2a20297ab130fff77fb555b57a59d5", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/models/example/schema.yml"}, "models/example/my_first_dbt_model.sql": {"contents": "\n/*\n    Welcome to your first dbt model!\n    Did you know that you can also configure models directly within SQL files?\n    This will override configurations stated in dbt_project.yml\n\n    Try changing \"table\" to \"view\" below\n*/\n\n{{ config(materialized='table') }}\n\nwith source_data as (\n\n    select 1 as id,'alexey' as name, '1991-01-01' as date_id, 97 score\n    union all\n    select 1 as id,'alexey' as name, '1991-01-02' as date_id, 66 score\n    union all\n    select 2 as id,'sergey' as name, '1991-01-03' as date_id, 50 score\n\n)\n\nselect *\nfrom source_data\n\n/*\n    Uncomment the line below to remove records with null `id` values\n*/\n\n-- where id is not null\n", "hash": "2f7f428ff4f9738e601f97569fe7a670", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/models/example/my_first_dbt_model.sql"}, "models/example/my_second_dbt_model.sql": {"contents": "\n-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\n", "hash": "b74fa34d8b723a67716b3242002bcb92", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/models/example/my_second_dbt_model.sql"}, "models/example/metrics.yml": {"contents": "version: 2\n\nmetrics:\n  - name: rolling_new_customers\n    label: New Customers\n    model: ref('my_first_dbt_model')\n    description: \"The 14 day rolling count of paying customers using the product\"\n\n    calculation_method: sum\n    expression: score\n\n    timestamp: date_id\n    time_grains: [day, week, month, quarter, year]\n\n    dimensions:\n      - name\n\n    # general properties\n    config:\n      enabled: true\n      treat_null_values_as_zero: true\n\n    meta: {team: Finance}\n\n  - name: test_update\n    label: New Customers\n    model: ref('my_first_dbt_model')\n    description: \"The 14 day rolling count of paying customers using the product\"\n\n    calculation_method: max\n    expression: score\n\n    timestamp: date_id\n    time_grains: [day, week, month, quarter, year]\n\n#    window:\n#      count: 3\n#      period: day\n\n    dimensions:\n      - name\n\n    # general properties\n    config:\n      enabled: true\n      treat_null_values_as_zero: true\n\n    meta: {team: Finance}\n\n  - name: average_revenue_per_customer\n    label: Average Revenue Per Customer\n    description: \"The average revenue received per customer\"\n\n    calculation_method: derived\n    expression: \"{{metric('rolling_new_customers')}} / {{metric('test_update')}}\"\n\n    timestamp: date_id\n    time_grains: [day, week, month, quarter, year, all_time]\n    dimensions:\n      - name\n\n#  - name: test_window_metric\n#    description: Rolling average of order amounts over a 7-day period\n#    type: sum\n#    value: score\n#    rolling_window:\n#      size: 7\n#      offset: \"1 day\"\n#      field: date_id\n#      timeframes:\n#        - \"7 days\"\n#    label: test_label\n#    sql: >\n#      select\n#        date_id,\n#        avg(score) over (\n#          order by order_date\n#          rows between 6 preceding and current row\n#        ) as rolling_average\n#      from {{ ref('my_first_dbt_model') }}", "hash": "351a81a1d616fa4bc2744c5c1a25bb4a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/models/example/metrics.yml"}, "models/example/metric_test.sql": {"contents": "select *,{{ dbt.dateadd(month, 1, dbt.current_timestamp()) }}\nfrom {{ metrics.calculate(\n        [metric('rolling_new_customers'), metric('test_update')],\n        grain='week',\n        dimensions=['name']\n    ) }}", "hash": "0f9ccc4555cc1405875f64e9ae6449a8", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/models/example/metric_test.sql"}, "dbt_packages/metrics/dbt_project.yml": {"contents": "\n# Name your project! Project names should contain only lowercase characters\n# and underscores. A good package name should reflect your organization's\n# name or the intended use of these models\nname: 'metrics'\nversion: '1.0.0'\nconfig-version: 2\n\n# This setting configures which \"profile\" dbt uses for this project.\nprofile: 'user'\n\n# These configurations specify where dbt should look for different types of files.\n# The `source-paths` config, for example, states that models in this project can be\n# found in the \"models/\" directory. You probably won't need to change these!\nmodel-paths: [\"models\"]\nanalysis-paths: [\"analyses\"]\ntest-paths: [\"tests\"]\nseed-paths: [\"seeds\"]\nmacro-paths: [\"macros\"]\nsnapshot-paths: [\"snapshots\"]\n\nrequire-dbt-version: [\">=1.4.0-a1\", \"<1.5.0\"]\n# require-dbt-version: [\">=1.3.0-a1\", \"<1.4.0\"]\n\ntarget-path: \"target\"  # directory which will store compiled SQL files\nclean-targets:         # directories to be removed by `dbt clean`\n  - \"target\"\n  - \"dbt_packages\"\n", "hash": "56ad43d73dbf92570d33a877963df1be", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/dbt_project.yml"}, "dbt_packages/metrics/models/dbt_metrics_default_calendar.sql": {"contents": "{{ config(materialized='table') }}\n\nwith days as (\n    {{ metrics.metric_date_spine(\n    datepart=\"day\",\n    start_date=\"cast('1990-01-01' as date)\",\n    end_date=\"cast('2030-01-01' as date)\"\n   )\n    }}\n),\n\nfinal as (\n    select \n        cast(date_day as date) as date_day,\n        cast({{ date_trunc('week', 'date_day') }} as date) as date_week,\n        cast({{ date_trunc('month', 'date_day') }} as date) as date_month,\n        cast({{ date_trunc('quarter', 'date_day') }} as date) as date_quarter,\n        cast({{ date_trunc('year', 'date_day') }} as date) as date_year\n    from days\n)\n\nselect * from final\n", "hash": "f5341d9e683b57dde602984df7d0973d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/models/dbt_metrics_default_calendar.sql"}, "dbt_packages/metrics/tests/conftest.py": {"contents": "import pytest\nimport os\n\n# Import the standard functional fixtures as a plugin\n# Note: fixtures with session scope need to be local\npytest_plugins = [\"dbt.tests.fixtures.project\"]\n\n# The profile dictionary, used to write out profiles.yml\n# dbt will supply a unique schema per test, so we do not specify 'schema' here\n\n# We use os.environ here instead of os.getenv because environ with [] input will\n# return a KeyError exception instead of None or Default Value. It's better to know\n# when the error is from the environment variables and not have it potentially lead\n# you down a red herring path with other issues.\n@pytest.fixture(scope=\"class\")\ndef dbt_profile_target():\n    \n    if os.environ['dbt_target'] == 'postgres':\n        return {\n            'type': 'postgres',\n            'threads': 8,\n            'host': os.environ['POSTGRES_TEST_HOST'],\n            'user': os.environ['POSTGRES_TEST_USER'],\n            'password': os.environ['POSTGRES_TEST_PASSWORD'],\n            'port': int(os.environ['POSTGRES_TEST_PORT']),\n            'database': os.environ['POSTGRES_TEST_DB'],\n        }\n\n    if os.environ['dbt_target'] == 'redshift':\n        return {\n            'type': 'redshift',\n            'threads': 8,\n            'host': os.environ['REDSHIFT_TEST_HOST'],\n            'user': os.environ['REDSHIFT_TEST_USER'],\n            'pass': os.environ['REDSHIFT_TEST_PASS'],\n            'dbname': os.environ['REDSHIFT_TEST_DBNAME'],\n            'port': int(os.environ['REDSHIFT_TEST_PORT']),\n        }\n\n    if os.environ['dbt_target'] == 'snowflake':\n        return {\n            'type': 'snowflake',\n            'threads': 8,\n            'account': os.environ['SNOWFLAKE_TEST_ACCOUNT'],\n            'user': os.environ['SNOWFLAKE_TEST_USER'],\n            'password': os.environ['SNOWFLAKE_TEST_PASSWORD'],\n            'role': os.environ['SNOWFLAKE_TEST_ROLE'],\n            'database': os.environ['SNOWFLAKE_TEST_DATABASE'],\n            'warehouse': os.environ['SNOWFLAKE_TEST_WAREHOUSE'],\n        }\n\n    if os.environ['dbt_target'] == 'bigquery':\n        return {\n            'type': 'bigquery',\n            'threads': 8,\n            'method': 'service-account',\n            'project': os.environ['BIGQUERY_TEST_PROJECT'],\n            'keyfile': os.environ['BIGQUERY_SERVICE_KEY_PATH'],\n        }\n\n    if os.environ['dbt_target'] == 'databricks':\n        return {\n            'type': 'databricks',\n            'threads': 8,\n            'catalog': os.environ['DATABRICKS_TEST_CATALOG'],\n            'schema': os.environ['DATABRICKS_TEST_SCHEMA'],\n            'host': os.environ['DATABRICKS_TEST_HOST'],\n            'http_path': os.environ['DATABRICKS_TEST_HTTP_PATH'],\n            'token': os.environ['DATABRICKS_TEST_TOKEN'],\n        }", "hash": "2875b15a6b8e8ac06a23957c8a2b7887", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/conftest.py"}, "dbt_packages/metrics/tests/functional/fixtures.py": {"contents": "# seeds/seed_slack_users.csv\nseed_slack_users_csv = \"\"\"\nuser_id,joined_at,is_active_past_quarter,has_messaged\n1,2021-01-01,true,true\n2,2021-02-03,false,true\n3,2021-04-01,false,false\n4,2021-04-08,false,false\n\"\"\".lstrip()\n\n# seeds/fact_orders_source.csv\nfact_orders_source_csv = \"\"\"\norder_id,order_country,order_total,had_discount,customer_id,order_date\n4,France,1,true,3,2022-01-06\n5,France,1,false,4,2022-01-08\n3,France,1,false,1,2022-01-13\n2,Japan,1,false,2,2022-01-20\n6,Japan,1,false,5,2022-01-21\n7,Japan,1,true,2,2022-01-22\n1,France,2,false,1,2022-01-28\n9,Japan,1,false,2,2022-02-03\n10,Japan,1,false,3,2022-02-13\n8,France,4,true,1,2022-02-15\n\"\"\".lstrip()\n\n# seeds/fact_orders_duplicate_source.csv\nfact_orders_duplicate_source_csv = \"\"\"\norder_id,order_country,order_total,had_discount,customer_id,order_date\n4,France,1,true,3,2022-01-07\n5,France,1,false,4,2022-01-09\n3,France,1,false,1,2022-01-14\n2,Japan,1,false,2,2022-01-21\n6,Japan,1,false,5,2022-01-22\n7,Japan,1,true,2,2022-01-23\n1,France,2,false,1,2022-01-29\n9,Japan,1,false,2,2022-02-04\n10,Japan,1,false,3,2022-02-14\n8,France,4,true,1,2022-02-16\n\"\"\".lstrip()\n\n# seeds/dim_customers_source.csv\ndim_customers_source_csv = \"\"\"\ncustomer_id,first_name,last_name,email,gender,is_new_customer,date_added\n1,Geodude,Hills,bhills0@altervista.org,Male,FALSE,2022-01-01\n2,Mew,Coxhead,mcoxhead1@symantec.com,Genderfluid,TRUE,2022-01-06\n3,Mewtwo,Redish,aredish2@last.fm,Genderqueer,FALSE,2022-01-13\n4,Charizard,Basant,lbasant3@dedecms.com,Female,TRUE,2022-02-01\n5,Snorlax,Pokemon,the_email@dedecms.com,Male,TRUE,2022-02-03\n\"\"\".lstrip()\n\n# seeds/mock_purchase_data.csv\nmock_purchase_data_csv = \"\"\"\npurchased_at,payment_type,payment_total\n2021-02-14,maestro,10\n2021-02-15,jcb,10\n2021-02-15,solo,10\n2021-02-16,americanexpress,10\n2021-02-17,americanexpress,10\n\"\"\".lstrip()\n\n# models/custom_calendar.sql\ncustom_calendar_sql = \"\"\"\n{{ config(materialized='table') }}\nwith days as (\n    {{ metrics.metric_date_spine(\n    datepart=\"day\",\n    start_date=\"cast('2010-01-01' as date)\",\n    end_date=\"cast('2030-01-01' as date)\"\n   )\n    }}\n),\nfinal as (\n    select \n        cast(date_day as date) as date_day,\n        {% if target.type == 'bigquery' %}\n            --BQ starts its weeks on Sunday. I don't actually care which day it runs on for auto testing purposes, just want it to be consistent with the other seeds\n            cast({{ date_trunc('week(MONDAY)', 'date_day') }} as date) as date_week,\n        {% else %}\n            cast({{ date_trunc('week', 'date_day') }} as date) as date_week,\n        {% endif %}\n        cast({{ date_trunc('month', 'date_day') }} as date) as date_month,\n        cast({{ date_trunc('quarter', 'date_day') }} as date) as date_quarter,\n        cast('2022-01-01' as date) as date_test,\n        cast({{ date_trunc('year', 'date_day') }} as date) as date_year,\n        true as is_weekend\n    from days\n)\nselect * from final\n\"\"\"\n\n# models/fact_orders.sql\nfact_orders_sql = \"\"\"\nselect \n    *\n    ,round(order_total - (order_total/2)) as discount_total\nfrom {{ref('fact_orders_source')}}\n\"\"\"\n\n# models/fact_orders_duplicate.sql\nfact_orders_duplicate_sql = \"\"\"\nselect \n    *\n    ,round(order_total - (order_total/2)) as discount_total\nfrom {{ref('fact_orders_duplicate_source')}}\n\"\"\"\n\n# models/dim_customers.sql\ndim_customers_sql = \"\"\"\nselect * from {{ref('dim_customers_source')}}\n\"\"\"\n\n# models/combined__orders_customers.sql\ncombined__orders_customers_sql = \"\"\"\nwith orders as (\n    select * from {{ ref('fact_orders') }}\n)\n,\ncustomers as (\n    select * from {{ ref('dim_customers') }}\n)\n,\nfinal as (\n    select *\n    from orders\n    left join customers using (customer_id)\n)\nselect * from final\n\"\"\"\n\n\n# models/fact_orders.yml\nfact_orders_yml = \"\"\"\nversion: 2 \nmodels: \n  - name: fact_orders\n    columns:\n      - name: order_id\n        description: TBD\n      - name: order_country\n        description: TBD\n      - name: order_total\n        description: TBD\n      - name: had_discount\n        description: TBD\n      - name: customer_id\n        description: TBD\n      - name: order_date\n        description: TBD\n\"\"\"\n\n# models/fact_orders.yml\nfact_orders_duplicate_yml = \"\"\"\nversion: 2 \nmodels: \n  - name: fact_orders_duplicate\n    columns:\n      - name: order_id\n        description: TBD\n      - name: order_country\n        description: TBD\n      - name: order_total\n        description: TBD\n      - name: had_discount\n        description: TBD\n      - name: customer_id\n        description: TBD\n      - name: order_date\n        description: TBD\n\"\"\"\n\n# models/dim_customers.yml\ndim_customers_yml = \"\"\"\nversion: 2 \nmodels: \n  - name: dim_customers\n    columns:\n      - name: customer_id\n        description: TBD\n      - name: first_name\n        description: TBD\n      - name: last_name\n        description: TBD\n      - name: email\n        description: TBD\n      - name: gender\n        description: TBD\n        \n      - name: is_new_customer\n        description: TBD\n\"\"\"\n\n# packages.yml\npackages_yml = \"\"\"\n  - package: calogica/dbt_expectations\n    version: [\">=0.6.0\", \"<0.7.0\"]\n\n  - package: dbt-labs/dbt_utils\n    version: [\">=0.9.0\", \"<1.0.0\"]\n\"\"\"\n\n# seeds/events.csv\nevents_source_csv = \"\"\"\nid,country,timestamp_field\n1,FR,2022-01-01\n2,UK,2022-02-01\n\"\"\".lstrip()\n\n# models/event.sql\nevent_sql = \"\"\"\nwith source as (\n    select * from {{ ref('events_source') }}\n)\n,\nfinal as (\n    select *\n    from source \n)\nselect * from final\n\"\"\"\n\n# models/event.yml\nevent_yml = \"\"\"\nversion: 2 \nmodels: \n  - name: event\n    columns:\n      - name: id\n        description: TBD\n      - name: country\n        description: TBD\n      - name: timestamp_field\n        description: TBD\n\"\"\"", "hash": "4af0ff5dd625c98eb040777b8aa29e9f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/fixtures.py"}, "dbt_packages/metrics/tests/functional/develop/test_develop.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n)\n\n# models/develop_metric_monthly.sql\ndevelop_metric_monthly_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: develop_metric_monthly\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      treat_null_values_as_zero: false\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        metric_list=['develop_metric_monthly'],\n        grain='month'\n        )\n    }}\n\"\"\"\n\n# models/develop_metric_monthly.yml\ndevelop_metric_monthly_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: develop_metric_monthly\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('develop_metric_monthly__expected')\n\n\"\"\"\n\n# seeds/develop_metric__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    develop_metric_monthly__expected_csv = \"\"\"\ndate_month,develop_metric_monthly\n2022-01-01,1.000000\n2022-02-01,1.333333\n\"\"\".lstrip()\nelse:\n    develop_metric_monthly__expected_csv = \"\"\"\ndate_month,develop_metric_monthly\n2022-01-01,1.00000000000000000000\n2022-02-01,1.3333333333333333\n\"\"\".lstrip()\n\n# seeds/develop_metric_monthly___expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    develop_metric_monthly__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: develop_metric__expected\n    config:\n      column_types:\n        date_month: date\n        develop_metric_monthly: FLOAT64\n\"\"\".lstrip()\nelse: \n    develop_metric_monthly__expected_yml = \"\"\"\"\"\"\n\nclass TestDevelopMonthlyMetric:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"develop_metric_monthly__expected.csv\": develop_metric_monthly__expected_csv,\n            \"develop_metric_monthly__expected.yml\": develop_metric_monthly__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"develop_metric_monthly.sql\": develop_metric_monthly_sql,\n            \"develop_metric_monthly.yml\": develop_metric_monthly_yml\n        }\n\n    def test_develop_monthly_metric(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        # breakpoint()\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/develop_metric.sql\ndevelop_multiple_metrics_sql = \"\"\"\n{% set my_metric_yml -%}\n{% raw %}\n\nmetrics:\n  - name: develop_metric_multiple\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: derived_metric_multiple\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{ metric('develop_metric_multiple') }} - 1 \"\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: some_other_metric_not_using_multiple\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{ metric('derived_metric_multiple') }} - 1 \"\n    dimensions:\n      - had_discount\n      - order_country\n\n{% endraw %}\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        metric_list=['derived_metric_multiple'],\n        grain='month'\n        )\n    }}\n\"\"\"\n\n# models/develop_multiple_metrics.yml\ndevelop_multiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: develop_multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('develop_multiple_metrics__expected')\n\n\"\"\"\n\n# seeds/develop_multiple_metrics___expected.yml\nif os.getenv('dbt_target') == 'snowflake':\n    develop_multiple_metrics__expected_csv = \"\"\"\ndate_month,develop_metric_multiple,derived_metric_multiple\n2022-02-01,1.333333,0.333333\n2022-01-01,1.0,0.0\n\"\"\".lstrip()\nelse: \n    develop_multiple_metrics__expected_csv = \"\"\"\ndate_month,develop_metric_multiple,derived_metric_multiple\n2022-02-01,1.3333333333333333,0.33333333333333326\n2022-01-01,1.0,0.0\n\"\"\".lstrip()\n\n# seeds/develop_multiple_metrics___expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    develop_multiple_metrics__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: develop_multiple_metrics__expected\n    config:\n      column_types:\n        date_month: date\n        develop_metric_multiple: FLOAT64\n        derived_metric_multiple: FLOAT64\n\"\"\".lstrip()\nelse: \n    develop_multiple_metrics__expected_yml = \"\"\"\"\"\"\n\nclass TestDevelopMultipleMetrics:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"develop_multiple_metrics__expected.csv\": develop_multiple_metrics__expected_csv,\n            \"develop_multiple_metrics__expected.yml\": develop_multiple_metrics__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"develop_multiple_metrics.sql\": develop_multiple_metrics_sql,\n            \"develop_multiple_metrics.yml\": develop_multiple_metrics_yml\n        }\n\n    def test_develop_multiple_metrics(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/develop_metric_window.sql\ndevelop_metric_window_sql = \"\"\"\n{% set my_metric_yml -%}\nmetrics:\n  - name: develop_metric_window\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14 \n        period: day\n    dimensions:\n      - had_discount\n      - order_country\n{%- endset %}\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        metric_list=['develop_metric_window'],\n        grain='week'\n        )\n    }}\n\"\"\"\n\n# models/develop_metric_window.yml\ndevelop_metric_window_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: develop_metric_window\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('develop_metric_window__expected')\n\"\"\"\n\n# seeds/develop_metric__expected.csv\ndevelop_metric_window__expected_csv = \"\"\"\ndate_week,develop_metric_window\n2022-01-10,2\n2022-01-17,3\n2022-01-24,4\n2022-01-31,4\n2022-02-07,2\n2022-02-14,2\n2022-02-21,3\n2022-02-28,2\n\"\"\".lstrip()\n\nclass TestDevelopMetricWindow:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"develop_metric_window__expected.csv\": develop_metric_window__expected_csv\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"develop_metric_window.sql\": develop_metric_window_sql,\n            \"develop_metric_window.yml\": develop_metric_window_yml,\n            \"custom_calendar.sql\": custom_calendar_sql\n        }\n\n    def test_develop_metric_window(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/develop_metric_dimension.sql\ndevelop_metric_dimension_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: develop_metric_dimension\n    model: ref('fact_orders')\n    label: develop metric dimensions\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        metric_list='develop_metric_dimension',\n        grain='month',\n        dimensions=['had_discount','order_country']\n        )\n    }}\n\"\"\"\n\n# models/develop_metric_dimension.yml\ndevelop_metric_dimension_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: develop_metric_dimension\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('develop_metric_dimension__expected')\n\n\"\"\"\n\n# seeds/develop_metric_dimension__expected.csv\ndevelop_metric_dimension__expected_csv = \"\"\"\ndate_month,had_discount,order_country,develop_metric_dimension\n2022-01-01,TRUE,France,1\n2022-01-01,TRUE,Japan,1\n2022-01-01,FALSE,France,4\n2022-01-01,FALSE,Japan,2\n2022-02-01,TRUE,France,4\n2022-02-01,FALSE,Japan,2\n\"\"\".lstrip()\n\nclass TestDevelopMetricDimension:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"develop_metric_dimension__expected.csv\": develop_metric_dimension__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"develop_metric_dimension.sql\": develop_metric_dimension_sql,\n            \"develop_metric_dimension.yml\": develop_metric_dimension_yml\n        }\n\n    def test_develop_metric_dimension(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/testing_metric__develop.sql\ntesting_metric_develop_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: testing_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        metric_list='testing_metric',\n        grain='month'\n        )\n    }}\n\"\"\"\n\n# models/testing_metric_calculate.yml\ntesting_metric_calculate_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: testing_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/testing_metric_calculate.sql\ntesting_metric_calculate_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('testing_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/testing_metric_develop.yml\ntesting_metric_develop_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: testing_metric_develop\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('testing_metric_calculate')\n\n\"\"\"\n\nclass TestDevelopMatchesCalculate:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"testing_metric_develop.sql\": testing_metric_develop_sql,\n            \"testing_metric_develop.yml\": testing_metric_develop_yml,\n            \"testing_metric_calculate.sql\": testing_metric_calculate_sql,\n            \"testing_metric_calculate.yml\": testing_metric_calculate_yml\n        }\n\n    def test_develop_matches_calculate_second_run(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "22c9063e3a9e7dc586e80495b811e64f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/develop/test_develop.py"}, "dbt_packages/metrics/tests/functional/metric_options/date_alias/test_date_alias.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/date_alias_single_quote_base_metric.sql\ndate_alias_single_quote_base_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('date_alias_single_quote_base_metric'), \n    grain='month',\n    dimensions=['had_discount'],\n    date_alias='date'\n    )\n}}\n\"\"\"\n\n# models/date_alias_single_quote_base_metric.yml\ndate_alias_single_quote_base_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: date_alias_single_quote_base_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('date_alias_single_quote_base_metric__expected')\nmetrics:\n  - name: date_alias_single_quote_base_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/date_alias_single_quote_base_metric__expected.csv\ndate_alias_single_quote_base_metric__expected_csv = \"\"\"\ndate,had_discount,date_alias_single_quote_base_metric\n2022-01-01,TRUE,2\n2022-01-01,FALSE,6\n2022-02-01,TRUE,4\n2022-02-01,FALSE,2\n\"\"\".lstrip()\n\nclass TestDateAliasSingleQuoteMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"date_alias_single_quote_base_metric__expected.csv\": date_alias_single_quote_base_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"date_alias_single_quote_base_metric.sql\": date_alias_single_quote_base_metric_sql,\n            \"date_alias_single_quote_base_metric.yml\": date_alias_single_quote_base_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/date_alias_double_quote_base_metric.sql\ndate_alias_double_quote_base_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('date_alias_double_quote_base_metric'), \n    grain='month',\n    dimensions=['had_discount'],\n    date_alias=\"date\"\n    )\n}}\n\"\"\"\n\n# models/date_alias_double_quote_base_metric.yml\ndate_alias_double_quote_base_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: date_alias_double_quote_base_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('date_alias_double_quote_base_metric__expected')\nmetrics:\n  - name: date_alias_double_quote_base_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/date_alias_double_quote_base_metric__expected.csv\ndate_alias_double_quote_base_metric__expected_csv = \"\"\"\ndate,had_discount,date_alias_double_quote_base_metric\n2022-01-01,TRUE,2\n2022-01-01,FALSE,6\n2022-02-01,TRUE,4\n2022-02-01,FALSE,2\n\"\"\".lstrip()\n\nclass TestDateAliasDoubleQuoteMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"date_alias_double_quote_base_metric__expected.csv\": date_alias_double_quote_base_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"date_alias_double_quote_base_metric.sql\": date_alias_double_quote_base_metric_sql,\n            \"date_alias_double_quote_base_metric.yml\": date_alias_double_quote_base_metric_yml,\n        }\n\n    def test_date_alias_double_quote(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "0738ca58499dcde3ab56a35758dfb262", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/date_alias/test_date_alias.py"}, "dbt_packages/metrics/tests/functional/metric_options/start_date/test_start_date.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/start_date_base_sum_metric.sql\nstart_date_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('start_date_base_sum_metric'), \n    grain='month',\n    start_date='2022-02-01'\n    )\n}}\n\"\"\"\n\n# models/start_date_base_sum_metric.yml\nstart_date_base_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: start_date_base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('start_date_base_sum_metric__expected')\nmetrics:\n  - name: start_date_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/start_date_base_sum_metric__expected.csv\nstart_date_base_sum_metric__expected_csv = \"\"\"\ndate_month,start_date_base_sum_metric\n2022-02-01,6\n\"\"\".lstrip()\n\nclass TestEarlyStartDateBaseSumMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"start_date_base_sum_metric__expected.csv\": start_date_base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"start_date_base_sum_metric.sql\": start_date_base_sum_metric_sql,\n            \"start_date_base_sum_metric.yml\": start_date_base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/start_date_derived_metric.sql\nstart_date_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('start_date_derived_metric'), \n    grain='month',\n    start_date='2022-02-01'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/start_date_derived_metric.yml\nstart_date_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: start_date_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('start_date_derived_metric__expected')\nmetrics:\n  - name: start_date_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/start_date_derived_metric__expected.csv\nstart_date_derived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,start_date_derived_metric\n2022-02-01,6,7\n\"\"\".lstrip()\n\nclass TestEarlyStartDateDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"start_date_derived_metric__expected.csv\": start_date_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"start_date_derived_metric.yml\": start_date_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"start_date_derived_metric.sql\": start_date_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/late_start_date_derived_metric.sql\nlate_start_date_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('late_start_date_derived_metric'), \n    grain='month',\n    start_date='2022-02-04'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/late_start_date_derived_metric.yml\nlate_start_date_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: late_start_date_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('late_start_date_derived_metric__expected')\nmetrics:\n  - name: late_start_date_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/late_start_date_derived_metric__expected.csv\nlate_start_date_derived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,late_start_date_derived_metric\n2022-02-01,5,6\n\"\"\".lstrip()\n\nclass TestLateStartDateDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"late_start_date_derived_metric__expected.csv\": late_start_date_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"late_start_date_derived_metric.yml\": late_start_date_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"late_start_date_derived_metric.sql\": late_start_date_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/late_start_date_base_sum_metric.sql\nlate_start_date_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('late_start_date_base_sum_metric'), \n    grain='month',\n    start_date='2022-02-04'\n    )\n}}\n\"\"\"\n\n# models/late_start_date_base_sum_metric.yml\nlate_start_date_base_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: late_start_date_base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('late_start_date_base_sum_metric__expected')\nmetrics:\n  - name: late_start_date_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/late_start_date_base_sum_metric__expected.csv\nlate_start_date_base_sum_metric__expected_csv = \"\"\"\ndate_month,late_start_date_base_sum_metric\n2022-02-01,5\n\"\"\".lstrip()\n\nclass TestLateStartDateBaseSumMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"late_start_date_base_sum_metric__expected.csv\": late_start_date_base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"late_start_date_base_sum_metric.sql\": late_start_date_base_sum_metric_sql,\n            \"late_start_date_base_sum_metric.yml\": late_start_date_base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "6a5711fe35e3997bf227a5166a2328ee", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/start_date/test_start_date.py"}, "dbt_packages/metrics/tests/functional/metric_options/multiple_metrics/test_multiple_metrics.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    event_sql,\n    event_yml,\n    events_source_csv\n)\n\n# models/multiple_metrics.sql\nmultiple_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric'), metric('base_count_metric')],\n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/multiple_metrics.yml\nmultiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics__expected')\nmetrics:\n  - name: base_count_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multiple_metrics__expected.csv\nmultiple_metrics__expected_csv = \"\"\"\ndate_month,base_sum_metric,base_count_metric\n2022-01-01,8,7\n2022-02-01,6,3\n\"\"\".lstrip()\n\nclass TestMultipleMetrics:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multiple_metrics__expected.csv\": multiple_metrics__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multiple_metrics.sql\": multiple_metrics_sql,\n            \"multiple_metrics.yml\": multiple_metrics_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/multiple_metrics.sql\nmultiple_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric'), metric('base_count_metric')],\n    grain='month',\n    dimensions=['had_discount']\n    )\n}}\n\"\"\"\n\n# models/multiple_metrics.yml\nmultiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics__expected')\nmetrics:\n  - name: base_count_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multiple_metrics__expected.csv\nmultiple_metrics__expected_csv = \"\"\"\ndate_month,had_discount,base_sum_metric,base_count_metric\n2022-01-01,TRUE,2,2\n2022-01-01,FALSE,6,5\n2022-02-01,TRUE,4,1\n2022-02-01,FALSE,2,2\n\"\"\".lstrip()\n\nclass TestMultipleMetricsWithDimension:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multiple_metrics__expected.csv\": multiple_metrics__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multiple_metrics.sql\": multiple_metrics_sql,\n            \"multiple_metrics.yml\": multiple_metrics_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/multiple_metrics.sql\nmultiple_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric'), metric('base_count_metric')],\n    grain='month',\n    secondary_calculations=[\n    metrics.period_over_period(\n        comparison_strategy=\"difference\"\n        ,interval=1\n        ,metric_list=['base_sum_metric']\n        ),\n    metrics.period_to_date(\n        aggregate=\"sum\"\n        ,period=\"year\"\n        ,metric_list=['base_sum_metric','base_count_metric']\n        ),\n    metrics.rolling(\n        aggregate=\"max\"\n        ,interval=4\n        ,metric_list='base_sum_metric'\n        )\n        ] \n    )\n}}\n\"\"\"\n\n# models/multiple_metrics.yml\nmultiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics__expected')\nmetrics:\n  - name: base_count_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    type: count\n    sql: order_total\n    dimensions:\n      - had_discount\n      - order_country\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    type: sum\n    sql: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multiple_metrics__expected.csv\nmultiple_metrics__expected_csv = \"\"\"\ndate_month,date_year,base_sum_metric,base_count_metric,base_sum_metric_difference_to_1_month_ago,base_sum_metric_sum_for_year,base_count_metric_sum_for_year,base_sum_metric_rolling_max_4_month\n2022-01-01,2022-01-01,8,7,8,8,7,8\n2022-02-01,2022-01-01,6,3,-2,14,10,8\n\"\"\".lstrip()\n\nclass TestMultipleMetricsSecondaryCalcs:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multiple_metrics__expected.csv\": multiple_metrics__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multiple_metrics.sql\": multiple_metrics_sql,\n            \"multiple_metrics.yml\": multiple_metrics_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/multiple_metrics.sql\nmultiple_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric'), metric('derived_metric')],\n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/multiple_metrics.yml\nmultiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics__expected')\nmetrics:\n  - name: derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multiple_metrics__expected.csv\nmultiple_metrics__expected_csv = \"\"\"\ndate_month,base_sum_metric,derived_metric\n2022-01-01,8,9\n2022-02-01,6,7\n\"\"\".lstrip()\n\nclass TestMultipleMetricsWithDerived:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multiple_metrics__expected.csv\": multiple_metrics__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multiple_metrics.sql\": multiple_metrics_sql,\n            \"multiple_metrics.yml\": multiple_metrics_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/multiple_metrics.sql\nmultiple_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric'), metric('derived_metric')],\n    grain='month',\n    dimensions=['had_discount']\n    )\n}}\n\"\"\"\n\n# models/multiple_metrics.yml\nmultiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics__expected')\nmetrics:\n  - name: derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multiple_metrics__expected.csv\nmultiple_metrics__expected_csv = \"\"\"\ndate_month,had_discount,base_sum_metric,derived_metric\n2022-01-01,TRUE,2,3\n2022-01-01,FALSE,6,7\n2022-02-01,TRUE,4,5\n2022-02-01,FALSE,2,3\n\"\"\".lstrip()\n\nclass TestMultipleMetricsWithDerivedAndDimension:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multiple_metrics__expected.csv\": multiple_metrics__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multiple_metrics.sql\": multiple_metrics_sql,\n            \"multiple_metrics.yml\": multiple_metrics_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/multiple_metrics_filter.sql\nmultiple_metrics_filter_sql = \"\"\"\nselect *\nfrom {{\n  metrics.calculate(\n    [\n      metric('count_fr_events'),\n      metric('count_uk_events'),\n    ],\n    grain='month',\n  )\n}}\n\"\"\"\n\n# models/multiple_metrics_filter.yml\nmultiple_metrics_filter_yml = \"\"\"\nversion: 2\nmodels:\n  - name: multiple_metrics_filter\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics_filter__expected')\n\nmetrics:\n  - name: count_fr_events\n    label: Count number of events in France\n    model: ref('event')\n    type: count\n    sql: id\n    timestamp: timestamp_field\n    time_grains: [month]\n\n    filters:\n      - field: country\n        operator: '='\n        value: \"'FR'\"\n\n  - name: count_uk_events\n    label: Count number of events in UK\n    model: ref('event')\n    type: count\n    sql: id\n    timestamp: timestamp_field\n    time_grains: [month]\n\n    filters:\n      - field: country\n        operator: '='\n        value: \"'UK'\"\n\"\"\"\n\n# seeds/multiple_metrics_filter__expected.csv\nmultiple_metrics_filter__expected_csv = \"\"\"\ndate_month,count_fr_events,count_uk_events\n2022-01-01,1,0\n2022-02-01,0,1\n\"\"\".lstrip()\n\nclass TestMultipleMetricsWithFilter:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"events_source.csv\": events_source_csv,\n            \"multiple_metrics_filter__expected.csv\": multiple_metrics_filter__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"event.sql\": event_sql,\n            \"event.yml\": event_yml,\n            \"multiple_metrics_filter.sql\": multiple_metrics_filter_sql,\n            \"multiple_metrics_filter.yml\": multiple_metrics_filter_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/multiple_metrics_no_time_grain.sql\nmultiple_metrics_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric_no_time_grain'), metric('base_count_metric_no_time_grain')])\n}}\n\"\"\"\n\n# models/multiple_metrics_no_time_grain.yml\nmultiple_metrics_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics_no_time_grain__expected')\nmetrics:\n  - name: base_count_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multiple_metrics_no_time_grain__expected.csv\nmultiple_metrics_no_time_grain__expected_csv = \"\"\"\nbase_sum_metric_no_time_grain,base_count_metric_no_time_grain\n14,10\n\"\"\".lstrip()\n\nclass TestMultipleMetricsNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multiple_metrics_no_time_grain__expected.csv\": multiple_metrics_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multiple_metrics_no_time_grain.sql\": multiple_metrics_no_time_grain_sql,\n            \"multiple_metrics_no_time_grain.yml\": multiple_metrics_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/multiple_metrics_no_time_grain_multiple_dimensions.sql\nmultiple_metrics_no_time_grain_multiple_dimensions_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric_no_time_grain_multiple_dimensions'), metric('base_count_metric_no_time_grain_multiple_dimensions')],\n    dimensions=['had_discount','order_country'])\n}}\n\"\"\"\n\n# models/multiple_metrics_no_time_grain_multiple_dimensions.yml\nmultiple_metrics_no_time_grain_multiple_dimensions_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics_no_time_grain_multiple_dimensions\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics_no_time_grain_multiple_dimensions__expected')\nmetrics:\n  - name: base_count_metric_no_time_grain_multiple_dimensions\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric_no_time_grain_multiple_dimensions\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multiple_metrics_no_time_grain_multiple_dimensions__expected.csv\nmultiple_metrics_no_time_grain_multiple_dimensions__expected_csv = \"\"\"\nhad_discount,order_country,base_sum_metric_no_time_grain_multiple_dimensions,base_count_metric_no_time_grain_multiple_dimensions\ntrue,France,5,2\ntrue,Japan,1,1\nfalse,France,4,3\nfalse,Japan,4,4\n\"\"\".lstrip()\n\nclass TestMultipleMetricsNoTimeGrainMultipleDimensions:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multiple_metrics_no_time_grain_multiple_dimensions__expected.csv\": multiple_metrics_no_time_grain_multiple_dimensions__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multiple_metrics_no_time_grain_multiple_dimensions.sql\": multiple_metrics_no_time_grain_multiple_dimensions_sql,\n            \"multiple_metrics_no_time_grain_multiple_dimensions.yml\": multiple_metrics_no_time_grain_multiple_dimensions_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "df32ac4f36a3ab6b9ae1dfa10a631e66", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/multiple_metrics/test_multiple_metrics.py"}, "dbt_packages/metrics/tests/functional/metric_options/config/test_restrict_no_time_grain.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/restrict_no_time_grain_false.sql\nrestrict_no_time_grain_false_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('restrict_no_time_grain_false')], \n    grain='day'\n    )\n}}\n\"\"\"\n\n# models/restrict_no_time_grain_false.yml\nrestrict_no_time_grain_false_yml = \"\"\"\nversion: 2 \n\nmodels:\n  - name: restrict_no_time_grain_false\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('restrict_no_time_grain_false__expected')\n\nmetrics:\n  - name: restrict_no_time_grain_false\n    model: ref('fact_orders')\n    label: Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      restrict_no_time_grain: false\n\n\"\"\"\n\n# seeds/restrict_no_time_grain_false__expected.csv\nrestrict_no_time_grain_false__expected_csv = \"\"\"\ndate_day,restrict_no_time_grain_false\n2022-02-15,4\n2022-02-13,1\n2022-02-03,1\n2022-01-28,2\n2022-01-22,1\n2022-01-21,1\n2022-01-20,1\n2022-01-13,1\n2022-01-08,1\n2022-01-06,1\n\"\"\".lstrip()\n\nclass TestRestrictNoTimeGrainFalseMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"restrict_no_time_grain_false__expected.csv\": restrict_no_time_grain_false__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"restrict_no_time_grain_false.yml\": restrict_no_time_grain_false_yml,\n            \"restrict_no_time_grain_false.sql\": restrict_no_time_grain_false_sql\n        }\n\n    def test_restrict_no_time_grain_false(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/restrict_no_time_grain_true.sql\nrestrict_no_time_grain_true_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('restrict_no_time_grain_true')], \n    )\n}}\n\"\"\"\n\n# models/restrict_no_time_grain_true.yml\nrestrict_no_time_grain_true_yml = \"\"\"\nversion: 2 \n\nmodels:\n  - name: restrict_no_time_grain_true\n\nmetrics:\n  - name: restrict_no_time_grain_true\n    model: ref('fact_orders')\n    label: Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      restrict_no_time_grain: true\n\n\"\"\"\n\nclass TestRestrictNoTimeGrainTrueMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"restrict_no_time_grain_true.yml\": restrict_no_time_grain_true_yml,\n            \"restrict_no_time_grain_true.sql\": restrict_no_time_grain_true_sql\n        }\n\n    def test_restrict_no_time_grain_true(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n        # initial run\n        run_dbt([\"run\"],expect_pass = False)", "hash": "ea3216df8764b8592889c6aa1d542d91", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/config/test_restrict_no_time_grain.py"}, "dbt_packages/metrics/tests/functional/metric_options/config/test_treat_null_values_as_zero.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    fact_orders_duplicate_source_csv,\n    fact_orders_duplicate_sql,\n    fact_orders_duplicate_yml,\n)\n\n# models/treat_null_values_as_zero.sql\ntreat_null_values_as_zero_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('treat_null_values_as_zero'),metric('treat_null_values_as_zero_duplicate')], \n    grain='day'\n    )\n}}\n\"\"\"\n\n# models/treat_null_values_as_zero.yml\ntreat_null_values_as_zero_yml = \"\"\"\nversion: 2 \n\nmodels:\n  - name: treat_null_values_as_zero\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('treat_null_values_as_zero__expected')\n\nmetrics:\n  - name: treat_null_values_as_zero\n    model: ref('fact_orders')\n    label: Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      treat_null_values_as_zero: true\n\n  - name: treat_null_values_as_zero_duplicate\n    model: ref('fact_orders_duplicate')\n    label: Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      treat_null_values_as_zero: true\n\"\"\"\n\n# seeds/treat_null_values_as_zero__expected.csv\ntreat_null_values_as_zero__expected_csv = \"\"\"\ndate_day,treat_null_values_as_zero,treat_null_values_as_zero_duplicate\n2022-02-16,0,4\n2022-02-15,4,0\n2022-02-14,0,1\n2022-02-13,1,0\n2022-02-04,0,1\n2022-02-03,1,0\n2022-01-29,0,2\n2022-01-28,2,0\n2022-01-23,0,1\n2022-01-22,1,1\n2022-01-21,1,1\n2022-01-20,1,0\n2022-01-14,0,1\n2022-01-13,1,0\n2022-01-09,0,1\n2022-01-08,1,0\n2022-01-07,0,1\n2022-01-06,1,0\n\"\"\".lstrip()\n\nclass TestDefaultValueNullMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"fact_orders_duplicate_source.csv\": fact_orders_duplicate_source_csv,\n            \"treat_null_values_as_zero__expected.csv\": treat_null_values_as_zero__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders_duplicate.yml\": fact_orders_duplicate_yml,\n            \"fact_orders_duplicate.sql\": fact_orders_duplicate_sql,\n            \"treat_null_values_as_zero.yml\": treat_null_values_as_zero_yml,\n            \"treat_null_values_as_zero.sql\": treat_null_values_as_zero_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 3\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/treat_null_values_as_null.sql\ntreat_null_values_as_null_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('treat_null_values_as_null'),metric('treat_null_values_as_null_duplicate')], \n    grain='day'\n    )\n}}\n\"\"\"\n\n# models/treat_null_values_as_null.yml\ntreat_null_values_as_null_yml = \"\"\"\nversion: 2 \n\nmodels:\n  - name: treat_null_values_as_null\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('treat_null_values_as_null__expected')\n\nmetrics:\n  - name: treat_null_values_as_null\n    model: ref('fact_orders')\n    label: Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      treat_null_values_as_zero: false\n\n  - name: treat_null_values_as_null_duplicate\n    model: ref('fact_orders_duplicate')\n    label: Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      treat_null_values_as_zero: false\n\"\"\"\n\n# seeds/treat_null_values_as_null__expected.csv\ntreat_null_values_as_null__expected_csv = \"\"\"\ndate_day,treat_null_values_as_null,treat_null_values_as_null_duplicate\n2022-02-16,,4\n2022-02-15,4,\n2022-02-14,,1\n2022-02-13,1,\n2022-02-04,,1\n2022-02-03,1,\n2022-01-29,,2\n2022-01-28,2,\n2022-01-23,,1\n2022-01-22,1,1\n2022-01-21,1,1\n2022-01-20,1,\n2022-01-14,,1\n2022-01-13,1,\n2022-01-09,,1\n2022-01-08,1,\n2022-01-07,,1\n2022-01-06,1,\n\"\"\".lstrip()\n\nclass TestFalseValueNullMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"fact_orders_duplicate_source.csv\": fact_orders_duplicate_source_csv,\n            \"treat_null_values_as_null__expected.csv\": treat_null_values_as_null__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders_duplicate.yml\": fact_orders_duplicate_yml,\n            \"fact_orders_duplicate.sql\": fact_orders_duplicate_sql,\n            \"treat_null_values_as_null.yml\": treat_null_values_as_null_yml,\n            \"treat_null_values_as_null.sql\": treat_null_values_as_null_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 3\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n", "hash": "6fac95ea531e89209b0e72b4292bbadc", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/config/test_treat_null_values_as_zero.py"}, "dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_period_over_period.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/period_over_period_difference.sql\nperiod_over_period_difference_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_over_period_difference'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_over_period(comparison_strategy=\"difference\", interval=1, alias = \"1mth\")\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_over_period_difference.yml\nperiod_over_period_difference_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_over_period_difference\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_over_period_difference__expected')\nmetrics:\n  - name: period_over_period_difference\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_over_period_difference__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    period_over_period_difference__expected_csv = \"\"\"\ndate_month,period_over_period_difference,period_over_period_difference_1mth\n2022-01-01,8,8\n2022-02-01,6,-2\n\"\"\".lstrip()\nelse:\n    period_over_period_difference__expected_csv = \"\"\"\ndate_month,period_over_period_difference,period_over_period_difference_1mth\n2022-01-01,8,8\n2022-02-01,6,-2\n\"\"\".lstrip()\n\n# seeds/period_to_period_difference___expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_over_period_difference__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_over_period_difference__expected\n    config:\n      column_types:\n        date_month: date\n        period_over_period_difference: INT64\n        period_over_period_difference_1mth: INT64\n\"\"\".lstrip()\nelse: \n    period_over_period_difference__expected_yml = \"\"\"\"\"\"\n\n\nclass TestPeriodOverPeriodDifference:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_over_period_difference__expected.csv\": period_over_period_difference__expected_csv,\n            \"period_over_period_difference__expected.yml\": period_over_period_difference__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_over_period_difference.sql\": period_over_period_difference_sql,\n            \"period_over_period_difference.yml\": period_over_period_difference_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/period_over_period_ratio.sql\nperiod_over_period_ratio_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_over_period_ratio'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_over_period(comparison_strategy=\"ratio\", interval=1, alias = \"1mth\")\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_over_period_ratio.yml\nperiod_over_period_ratio_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_over_period_ratio\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_over_period_ratio__expected')\nmetrics:\n  - name: period_over_period_ratio\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_over_period_ratio__expected.csv\nperiod_over_period_ratio__expected_csv = \"\"\"\ndate_month,period_over_period_ratio,period_over_period_ratio_1mth\n2022-01-01,8,0\n2022-02-01,6,0.75\n\"\"\".lstrip()\n\n# seeds/period_over_period_ratio___expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_over_period_ratio__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_over_period_ratio__expected\n    config:\n      column_types:\n        date_month: date\n        period_over_period_ratio: INT64\n        period_over_period_ratio_1mth: FLOAT64\n\"\"\".lstrip()\nelse: \n    period_over_period_ratio__expected_yml = \"\"\"\"\"\"\n\nclass TestPeriodOverPeriodRatio:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_over_period_ratio__expected.csv\": period_over_period_ratio__expected_csv,\n            \"period_over_period_ratio__expected.yml\": period_over_period_ratio__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_over_period_ratio.sql\": period_over_period_ratio_sql,\n            \"period_over_period_ratio.yml\": period_over_period_ratio_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "dc523d5867c6bf819a449303dca6835d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_period_over_period.py"}, "dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_rolling.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n)\n\n# models/rolling_average.sql\nrolling_average_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_average'), \n    grain='month',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"max\", interval=2),\n        metrics.rolling(aggregate=\"min\", interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/rolling_average.yml\nrolling_average_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_average\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_average__expected')\nmetrics:\n  - name: rolling_average\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_average__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    rolling_average__expected_csv = \"\"\"\ndate_month,rolling_average,rolling_average_rolling_max_2_month,rolling_average_rolling_min_2_month\n2022-01-01,1,1,1\n2022-02-01,1.333333,1.333333,1\n\"\"\".lstrip()\nelse:\n    rolling_average__expected_csv = \"\"\"\ndate_month,rolling_average,rolling_average_rolling_max_2_month,rolling_average_rolling_min_2_month\n2022-01-01,1,1,1\n2022-02-01,1.3333333333333333,1.3333333333333333,1\n\"\"\".lstrip()\n\n# seeds/rolling_average__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_average__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_average__expected\n    config:\n      column_types:\n        date_month: date\n        rolling_average: FLOAT64\n        rolling_average_rolling_max_2_month: FLOAT64\n        rolling_average_rolling_min_2_month: INT64\n\"\"\".lstrip()\nelse: \n    rolling_average__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingAverage:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_average__expected.csv\": rolling_average__expected_csv,\n            \"rolling_average__expected.yml\": rolling_average__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"rolling_average.sql\": rolling_average_sql,\n            \"rolling_average.yml\": rolling_average_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/rolling_count.sql\nrolling_count_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_count'), \n    grain='week',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"min\"),\n        metrics.rolling(aggregate=\"max\"),\n        metrics.rolling(aggregate=\"sum\"),\n        metrics.rolling(aggregate=\"average\")\n    ]\n    )\n}}\n\"\"\"\n\n# models/rolling_count.yml\nrolling_count_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_count\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_count__expected')\nmetrics:\n  - name: rolling_count\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_count__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    rolling_count__expected_csv = \"\"\"\ndate_week,rolling_count,rolling_count_rolling_min,rolling_count_rolling_max,rolling_count_rolling_sum,rolling_count_rolling_average\n2022-01-03,2,2,2,2,2.000\n2022-01-10,1,1,2,3,1.500\n2022-01-17,3,1,3,6,2.000\n2022-01-24,1,1,3,7,1.750\n2022-01-31,1,1,3,8,1.600\n2022-02-07,1,1,3,9,1.500\n2022-02-14,1,1,3,10,1.428\n\"\"\".lstrip()\nelse:\n    rolling_count__expected_csv = \"\"\"\ndate_week,rolling_count,rolling_count_rolling_min,rolling_count_rolling_max,rolling_count_rolling_sum,rolling_count_rolling_average\n2022-01-03,2,2,2,2,2.0000000000000000\n2022-01-10,1,1,2,3,1.5000000000000000\n2022-01-17,3,1,3,6,2.0000000000000000\n2022-01-24,1,1,3,7,1.7500000000000000\n2022-01-31,1,1,3,8,1.6000000000000000\n2022-02-07,1,1,3,9,1.5000000000000000\n2022-02-14,1,1,3,10,1.4285714285714286\n\"\"\".lstrip()\n\n# seeds/rolling_count__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_count__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_count__expected\n    config:\n      column_types:\n        date_week: date\n        rolling_count: INT64\n        rolling_count_rolling_min: INT64\n        rolling_count_rolling_max: INT64\n        rolling_count_rolling_sum: INT64\n        rolling_count_rolling_average: FLOAT64\n\"\"\".lstrip()\nelse: \n    rolling_count__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingCount:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_count__expected.csv\": rolling_count__expected_csv,\n            \"rolling_count__expected.yml\": rolling_count__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"custom_calendar.sql\": custom_calendar_sql,\n            \"rolling_count.sql\": rolling_count_sql,\n            \"rolling_count.yml\": rolling_count_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/rolling_sum.sql\nrolling_sum_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_sum'), \n    grain='month',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"min\", interval=2),\n        metrics.rolling(aggregate=\"max\", interval=2),\n        metrics.rolling(aggregate=\"sum\", interval=2),\n        metrics.rolling(aggregate=\"average\", interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/rolling_sum.yml\nrolling_sum_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_sum\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_sum__expected')\nmetrics:\n  - name: rolling_sum\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_sum__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    rolling_sum__expected_csv = \"\"\"\ndate_month,rolling_sum,rolling_sum_rolling_min_2_month,rolling_sum_rolling_max_2_month,rolling_sum_rolling_sum_2_month,rolling_sum_rolling_average_2_month\n2022-01-01,18,18,18,18,18.000000\n2022-02-01,6,6,18,24,12.000000\n\"\"\".lstrip()\nelse:\n    rolling_sum__expected_csv = \"\"\"\ndate_month,rolling_sum,rolling_sum_rolling_min_2_month,rolling_sum_rolling_max_2_month,rolling_sum_rolling_sum_2_month,rolling_sum_rolling_average_2_month\n2022-01-01,18,18,18,18,18.0000000000000000\n2022-02-01,6,6,18,24,12.0000000000000000\n\"\"\".lstrip()\n\n# seeds/rolling_sum__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_sum__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_sum__expected\n    config:\n      column_types:\n        date_month: date\n        rolling_sum: INT64\n        rolling_sum_rolling_min_2_month: INT64\n        rolling_sum_rolling_max_2_month: INT64\n        rolling_sum_rolling_sum_2_month: INT64\n        rolling_sum_rolling_average_2_month: FLOAT64\n\"\"\".lstrip()\nelse: \n    rolling_sum__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingSum:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_sum__expected.csv\": rolling_sum__expected_csv,\n            \"rolling_sum__expected.yml\":rolling_sum__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"rolling_sum.sql\": rolling_sum_sql,\n            \"rolling_sum.yml\": rolling_sum_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/rolling_min.sql\nrolling_min_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_min'), \n    grain='month',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"min\", interval=2),\n        metrics.rolling(aggregate=\"max\", interval=2),\n        metrics.rolling(aggregate=\"sum\", interval=2),\n        metrics.rolling(aggregate=\"average\", interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/rolling_min.yml\nrolling_min_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_min\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_min__expected')\nmetrics:\n  - name: rolling_min\n    model: ref('fact_orders')\n    label: rolling min\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: min\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_min__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    rolling_min__expected_csv = \"\"\"\ndate_month,rolling_min,rolling_min_rolling_min_2_month,rolling_min_rolling_max_2_month,rolling_min_rolling_sum_2_month,rolling_min_rolling_average_2_month\n2022-01-01,1,1,1,1,1.000000\n2022-02-01,1,1,1,2,1.000000\n\"\"\".lstrip()\nelse: \n    rolling_min__expected_csv = \"\"\"\ndate_month,rolling_min,rolling_min_rolling_min_2_month,rolling_min_rolling_max_2_month,rolling_min_rolling_sum_2_month,rolling_min_rolling_average_2_month\n2022-01-01,1,1,1,1,1.0000000000000000\n2022-02-01,1,1,1,2,1.0000000000000000\n\"\"\".lstrip()\n\n# seeds/rolling_min__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_min__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_min__expected\n    config:\n      column_types:\n        date_month: date\n        rolling_min: INT64\n        rolling_min_rolling_min_2_month: INT64\n        rolling_min_rolling_max_2_month: INT64\n        rolling_min_rolling_sum_2_month: INT64\n        rolling_min_rolling_average_2_month: FLOAT64\n\"\"\".lstrip()\nelse: \n    rolling_min__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingMin:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_min__expected.csv\": rolling_min__expected_csv,\n            \"rolling_min__expected.yml\": rolling_min__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"rolling_min.sql\": rolling_min_sql,\n            \"rolling_min.yml\": rolling_min_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/rolling_max.sql\nrolling_max_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_max'), \n    grain='month',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"min\", interval=2),\n        metrics.rolling(aggregate=\"max\", interval=2),\n        metrics.rolling(aggregate=\"sum\", interval=2),\n        metrics.rolling(aggregate=\"average\", interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/rolling_max.yml\nrolling_max_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_max\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_max__expected')\nmetrics:\n  - name: rolling_max\n    model: ref('fact_orders')\n    label: rolling min\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: max\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_max__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    rolling_max__expected_csv = \"\"\"\ndate_month,rolling_max,rolling_max_rolling_min_2_month,rolling_max_rolling_max_2_month,rolling_max_rolling_sum_2_month,rolling_max_rolling_average_2_month\n2022-01-01,2,2,2,2,2.000000\n2022-02-01,4,2,4,6,3.000000\n\"\"\".lstrip()\nelse:\n    rolling_max__expected_csv = \"\"\"\ndate_month,rolling_max,rolling_max_rolling_min_2_month,rolling_max_rolling_max_2_month,rolling_max_rolling_sum_2_month,rolling_max_rolling_average_2_month\n2022-01-01,2,2,2,2,2.0000000000000000\n2022-02-01,4,2,4,6,3.0000000000000000\n\"\"\".lstrip()\n\n# seeds/rolling_max__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_max__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_max__expected\n    config:\n      column_types:\n        date_month: date\n        rolling_max: INT64\n        rolling_max_rolling_min_2_month: INT64\n        rolling_max_rolling_max_2_month: INT64\n        rolling_max_rolling_sum_2_month: INT64\n        rolling_max_rolling_average_2_month: FLOAT64\n\"\"\".lstrip()\nelse: \n    rolling_max__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingMax:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_max__expected.csv\": rolling_max__expected_csv,\n            \"rolling_max__expected.yml\": rolling_max__expected_yml,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"rolling_max.sql\": rolling_max_sql,\n            \"rolling_max.yml\": rolling_max_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/rolling_derived_metric.sql\nrolling_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_derived_metric'), \n    grain='month',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"max\", interval=2),\n        metrics.rolling(aggregate=\"min\", interval=2),\n        metrics.rolling(aggregate=\"sum\", interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/rolling_derived_metric.yml\nrolling_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_derived_metric__expected')\nmetrics:\n  - name: rolling_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_derived_metric__expected.csv\nrolling_derived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,rolling_derived_metric,rolling_derived_metric_rolling_max_2_month,rolling_derived_metric_rolling_min_2_month,rolling_derived_metric_rolling_sum_2_month\n2022-01-01,8,9,9,9,9\n2022-02-01,6,7,9,7,16\n\"\"\".lstrip()\n\n# seeds/rolling_derived__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_derived__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_derived__expected\n    config:\n      column_types:\n        date_month: date\n        rolling_derived: INT64\n        rolling_derived_rolling_min_2_month: INT64\n        rolling_derived_rolling_max_2_month: INT64\n        rolling_derived_rolling_sum_2_month: INT64\n\"\"\".lstrip()\nelse: \n    rolling_derived__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_derived_metric__expected.csv\": rolling_derived_metric__expected_csv,\n            \"rolling_derived__expected.yml\": rolling_derived__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"rolling_derived_metric.yml\": rolling_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"rolling_derived_metric.sql\": rolling_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/rolling_count.sql\nrolling_count_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_count'), \n    grain='month',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"min\", interval=2),\n        metrics.rolling(aggregate=\"max\", interval=2),\n        metrics.rolling(aggregate=\"sum\", interval=2),\n        metrics.rolling(aggregate=\"average\", interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/rolling_count.yml\nrolling_count_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_count\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_count__expected')\nmetrics:\n  - name: rolling_count\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_count__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    rolling_count__expected_csv = \"\"\"\ndate_month,rolling_count,rolling_count_rolling_min_2_month,rolling_count_rolling_max_2_month,rolling_count_rolling_sum_2_month,rolling_count_rolling_average_2_month\n2022-01-01,7,7,7,7,7.000000\n2022-02-01,3,3,7,10,5.000000\n\"\"\".lstrip()\nelse:\n    rolling_count__expected_csv = \"\"\"\ndate_month,rolling_count,rolling_count_rolling_min_2_month,rolling_count_rolling_max_2_month,rolling_count_rolling_sum_2_month,rolling_count_rolling_average_2_month\n2022-01-01,7,7,7,7,7.0000000000000000\n2022-02-01,3,3,7,10,5.0000000000000000\n\"\"\".lstrip()\n\n# seeds/rolling_count__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_count__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_count__expected\n    config:\n      column_types:\n        date_month: date\n        rolling_count: INT64\n        rolling_count_rolling_min_2_month: INT64\n        rolling_count_rolling_max_2_month: INT64\n        rolling_count_rolling_sum_2_month: INT64\n        rolling_count_rolling_average_2_month: FLOAT64\n\"\"\".lstrip()\nelse: \n    rolling_count__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingCount:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_count__expected.csv\": rolling_count__expected_csv,\n            \"rolling_count__expected.yml\": rolling_count__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"rolling_count.sql\": rolling_count_sql,\n            \"rolling_count.yml\": rolling_count_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/rolling_count_distinct.sql\nrolling_count_distinct_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('rolling_count_distinct'), \n    grain='month',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"min\", interval=2),\n        metrics.rolling(aggregate=\"max\", interval=2),\n        metrics.rolling(aggregate=\"sum\", interval=2),\n        metrics.rolling(aggregate=\"average\", interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/rolling_count_distinct.yml\nrolling_count_distinct_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: rolling_count_distinct\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('rolling_count_distinct__expected')\nmetrics:\n  - name: rolling_count_distinct\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count_distinct\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/rolling_count_distinct__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    rolling_count_distinct__expected_csv = \"\"\"\ndate_month,rolling_count_distinct,rolling_count_distinct_rolling_min_2_month,rolling_count_distinct_rolling_max_2_month,rolling_count_distinct_rolling_sum_2_month,rolling_count_distinct_rolling_average_2_month\n2022-01-01,5,5,5,5,5.000000\n2022-02-01,3,3,5,8,4.000000\n\"\"\".lstrip()\nelse:\n    rolling_count_distinct__expected_csv = \"\"\"\ndate_month,rolling_count_distinct,rolling_count_distinct_rolling_min_2_month,rolling_count_distinct_rolling_max_2_month,rolling_count_distinct_rolling_sum_2_month,rolling_count_distinct_rolling_average_2_month\n2022-01-01,5,5,5,5,5.0000000000000000\n2022-02-01,3,3,5,8,4.0000000000000000\n\"\"\".lstrip()\n\n# seeds/rolling_count_distinct__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    rolling_count_distinct__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: rolling_count_distinct__expected\n    config:\n      column_types:\n        date_month: date\n        rolling_count_distinct: INT64\n        rolling_count_distinct_rolling_min_2_month: INT64\n        rolling_count_distinct_rolling_max_2_month: INT64\n        rolling_count_distinct_rolling_sum_2_month: INT64\n        rolling_count_distinct_rolling_average_2_month: FLOAT64\n\"\"\".lstrip()\nelse: \n    rolling_count_distinct__expected_yml = \"\"\"\"\"\"\n\nclass TestRollingCountDistinct:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n            \n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"rolling_count_distinct__expected.csv\": rolling_count_distinct__expected_csv,\n            \"rolling_count_distinct__expected.yml\": rolling_count_distinct__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"rolling_count_distinct.sql\": rolling_count_distinct_sql,\n            \"rolling_count_distinct.yml\": rolling_count_distinct_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "6fca314be1b63ddd61d39bdc5b044fbb", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_rolling.py"}, "dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_invalid_secondary_calculations.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n\n)\n\n# models/avg_metric.sql\navg_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('avg_metric'), \n    grain='week',\n    secondary_calculations=[metrics.rolling(aggregate=\"sum\",interval=2)]\n    )\n}}\n\"\"\"\n\n# models/avg_metric.yml\navg_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: avg_metric\n\nmetrics:\n  - name: avg_metric\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidAverageSecondaryCalc:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"avg_metric.sql\": avg_metric_sql,\n            \"avg_metric.yml\": avg_metric_yml\n        }\n\n    def test_invalid_average_metric(self,project,):\n        # running deps to install package\n        run_dbt([\"deps\"])\n        # seed seeds\n        run_dbt([\"seed\"])\n        # initial run\n        run_dbt([\"run\"], expect_pass = False)\n\n\n# models/median_metric.sql\nmedian_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('median_metric'), \n    grain='week',\n    secondary_calculations=[\n        metrics.rolling(aggregate=\"sum\",interval=2)\n    ]\n    )\n}}\n\"\"\"\n\n# models/median_metric.yml\nmedian_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: median_metric\n\nmetrics:\n  - name: median_metric\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: median\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidMedianSecondaryCalc:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"median_metric.sql\": median_metric_sql,\n            \"median_metric.yml\": median_metric_yml\n        }\n\n    def test_invalid_median_metric(self,project,):\n        # running deps to install package\n        run_dbt([\"deps\"])\n        # seed seeds\n        run_dbt([\"seed\"])\n        # initial run\n        run_dbt([\"run\"], expect_pass = False)", "hash": "6f47a34ae49991eb18190b95be00a7c4", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_invalid_secondary_calculations.py"}, "dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_period_to_date.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/period_to_date_average.sql\nperiod_to_date_average_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_to_date_average'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"min\", period=\"year\", alias=\"this_year_min\"),\n        metrics.period_to_date(aggregate=\"max\", period=\"year\"),\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_to_date_average.yml\nperiod_to_date_average_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_to_date_average\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_to_date_average__expected')\nmetrics:\n  - name: period_to_date_average\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_to_date_average__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    period_to_date_average__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_average,period_to_date_average_this_year_min,period_to_date_average_max_for_year\n2022-01-01,2022-01-01,1.000000,1,1\n2022-02-01,2022-01-01,1.333333,1,1.333333\n\"\"\".lstrip()\nelse:\n    period_to_date_average__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_average,period_to_date_average_this_year_min,period_to_date_average_max_for_year\n2022-01-01,2022-01-01,1.00000000000000000000,1,1\n2022-02-01,2022-01-01,1.3333333333333333,1,1.3333333333333333\n\"\"\".lstrip()\n\n# seeds/period_to_date_average__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_to_date_average__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_to_date_average__expected\n    config:\n      column_types:\n        date_month: date\n        date_year: date\n        period_to_date_average: FLOAT64\n        period_to_date_average_this_year_min: INT64\n        period_to_date_average_max_for_year: FLOAT64\n\"\"\".lstrip()\nelse: \n    period_to_date_average__expected_yml = \"\"\"\"\"\"\n\n\nclass TestPeriodToDateAverage:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_to_date_average__expected.csv\": period_to_date_average__expected_csv,\n            \"period_to_date_average__expected.yml\": period_to_date_average__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_to_date_average.sql\": period_to_date_average_sql,\n            \"period_to_date_average.yml\": period_to_date_average_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/period_to_date_count_distinct.sql\nperiod_to_date_count_distinct_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_to_date_count_distinct'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"min\", period=\"year\", alias=\"this_year_min\"),\n        metrics.period_to_date(aggregate=\"max\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"sum\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"average\", period=\"year\"),\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_to_date_count_distinct.yml\nperiod_to_date_count_distinct_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_to_date_count_distinct\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_to_date_count_distinct__expected')\nmetrics:\n  - name: period_to_date_count_distinct\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count_distinct\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_to_date_count_distinct__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    period_to_date_count_distinct__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_count_distinct,period_to_date_count_distinct_this_year_min,period_to_date_count_distinct_max_for_year,period_to_date_count_distinct_sum_for_year,period_to_date_count_distinct_average_for_year\n2022-01-01,2022-01-01,5,5,5,5,5.000000\n2022-02-01,2022-01-01,3,3,5,8,4.000000\n\"\"\".lstrip()\nelse:\n    period_to_date_count_distinct__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_count_distinct,period_to_date_count_distinct_this_year_min,period_to_date_count_distinct_max_for_year,period_to_date_count_distinct_sum_for_year,period_to_date_count_distinct_average_for_year\n2022-01-01,2022-01-01,5,5,5,5,5.0000000000000000\n2022-02-01,2022-01-01,3,3,5,8,4.0000000000000000\n\"\"\".lstrip()\n\n# seeds/period_to_date_count_distinct__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_to_date_count_distinct__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_to_date_count_distinct__expected\n    config:\n      column_types:\n        date_month: date\n        date_year: date\n        period_to_date_count_distinct: INT64\n        period_to_date_count_distinct_this_year_min: INT64\n        period_to_date_count_distinct_max_for_year: INT64\n        period_to_date_count_distinct_sum_for_year: INT64\n        period_to_date_count_distinct_average_for_year: FLOAT64\n\"\"\".lstrip()\nelse: \n    period_to_date_count_distinct__expected_yml = \"\"\"\"\"\"\n\nclass TestPeriodToDateCountDistinct:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_to_date_count_distinct__expected.csv\": period_to_date_count_distinct__expected_csv,\n            \"period_to_date_count_distinct__expected.yml\": period_to_date_count_distinct__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_to_date_count_distinct.sql\": period_to_date_count_distinct_sql,\n            \"period_to_date_count_distinct.yml\": period_to_date_count_distinct_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/period_to_date_count.sql\nperiod_to_date_count_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_to_date_count'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"min\", period=\"year\", alias=\"this_year_min\"),\n        metrics.period_to_date(aggregate=\"max\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"sum\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"average\", period=\"year\"),\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_to_date_count.yml\nperiod_to_date_count_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_to_date_count\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_to_date_count__expected')\nmetrics:\n  - name: period_to_date_count\n    model: ref('fact_orders')\n    label: Count\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_to_date_count__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    period_to_date_count__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_count,period_to_date_count_this_year_min,period_to_date_count_max_for_year,period_to_date_count_sum_for_year,period_to_date_count_average_for_year\n2022-01-01,2022-01-01,7,7,7,7,7.000000\n2022-02-01,2022-01-01,3,3,7,10,5.000000\n\"\"\".lstrip()\nelse:\n    period_to_date_count__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_count,period_to_date_count_this_year_min,period_to_date_count_max_for_year,period_to_date_count_sum_for_year,period_to_date_count_average_for_year\n2022-01-01,2022-01-01,7,7,7,7,7.0000000000000000\n2022-02-01,2022-01-01,3,3,7,10,5.0000000000000000\n\"\"\".lstrip()\n\n# seeds/period_to_date_count__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_to_date_count__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_to_date_count__expected\n    config:\n      column_types:\n        date_month: date\n        date_year: date\n        period_to_date_count: INT64\n        period_to_date_count_this_year_min: INT64\n        period_to_date_count_max_for_year: INT64\n        period_to_date_count_sum_for_year: INT64\n        period_to_date_count_average_for_year: FLOAT64\n\"\"\".lstrip()\nelse: \n    period_to_date_count__expected_yml = \"\"\"\"\"\"\n\nclass TestPeriodToDateCount:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_to_date_count__expected.csv\": period_to_date_count__expected_csv,\n            \"period_to_date_count__expected.yml\": period_to_date_count__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_to_date_count.sql\": period_to_date_count_sql,\n            \"period_to_date_count.yml\": period_to_date_count_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/period_to_date_derived_metric.sql\nperiod_to_date_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_to_date_derived_metric'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"min\", period=\"year\", alias=\"this_year_min\"),\n        metrics.period_to_date(aggregate=\"max\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"sum\", period=\"year\")\n    ]\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/period_to_date_derived_metric.yml\nperiod_to_date_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_to_date_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_to_date_derived_metric__expected')\nmetrics:\n  - name: period_to_date_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_to_date_derived_metric__expected.csv\nperiod_to_date_derived_metric__expected_csv = \"\"\"\ndate_month,date_year,base_sum_metric,period_to_date_derived_metric,period_to_date_derived_metric_this_year_min,period_to_date_derived_metric_max_for_year,period_to_date_derived_metric_sum_for_year\n2022-01-01,2022-01-01,8,9,9,9,9\n2022-02-01,2022-01-01,6,7,7,9,16\n\"\"\".lstrip()\n\n# seeds/period_to_date_derived_metric__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_to_date_derived_metric__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_to_date_derived_metric__expected\n    config:\n      column_types:\n        date_month: date\n        date_year: date\n        period_to_date_derived_metric: INT64\n        period_to_date_derived_metric_this_year_min: INT64\n        period_to_date_derived_metric_max_for_year: INT64\n        period_to_date_derived_metric_sum_for_year: INT64\n\"\"\".lstrip()\nelse: \n    period_to_date_derived_metric__expected_yml = \"\"\"\"\"\"\n\nclass TestPeriodToDateDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_to_date_derived_metric__expected.csv\": period_to_date_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"period_to_date_derived_metric.yml\": period_to_date_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"period_to_date_derived_metric.sql\": period_to_date_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/period_to_date_max.sql\nperiod_to_date_max_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_to_date_max'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"min\", period=\"year\", alias=\"this_year_min\"),\n        metrics.period_to_date(aggregate=\"max\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"sum\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"average\", period=\"year\"),\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_to_date_max.yml\nperiod_to_date_max_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_to_date_max\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_to_date_max__expected')\nmetrics:\n  - name: period_to_date_max\n    model: ref('fact_orders')\n    label: max value\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: max\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_to_date_max__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    period_to_date_max__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_max,period_to_date_max_this_year_min,period_to_date_max_max_for_year,period_to_date_max_sum_for_year,period_to_date_max_average_for_year\n2022-01-01,2022-01-01,5,5,5,5,5.000000\n2022-02-01,2022-01-01,3,3,5,8,4.000000\n\"\"\".lstrip()\nelse:\n    period_to_date_max__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_max,period_to_date_max_this_year_min,period_to_date_max_max_for_year,period_to_date_max_sum_for_year,period_to_date_max_average_for_year\n2022-01-01,2022-01-01,5,5,5,5,5.0000000000000000\n2022-02-01,2022-01-01,3,3,5,8,4.0000000000000000\n\"\"\".lstrip()\n\n# seeds/period_to_date_max__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_to_date_max__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_to_date_max__expected\n    config:\n      column_types:\n        date_month: date\n        date_year: date\n        period_to_date_max: INT64\n        period_to_date_max_this_year_min: INT64\n        period_to_date_max_max_for_year: INT64\n        period_to_date_max_sum_for_year: INT64\n        period_to_date_max_average_for_year: FLOAT64\n\"\"\".lstrip()\nelse: \n    period_to_date_max__expected_yml = \"\"\"\"\"\"\n\nclass TestPeriodToDateMax:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_to_date_max__expected.csv\": period_to_date_max__expected_csv,\n            \"period_to_date_max__expected.yml\": period_to_date_max__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_to_date_max.sql\": period_to_date_max_sql,\n            \"period_to_date_max.yml\": period_to_date_max_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/period_to_date_min.sql\nperiod_to_date_min_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_to_date_min'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"min\", period=\"year\", alias=\"this_year_min\"),\n        metrics.period_to_date(aggregate=\"max\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"sum\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"average\", period=\"year\"),\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_to_date_min.yml\nperiod_to_date_min_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_to_date_min\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_to_date_min__expected')\nmetrics:\n  - name: period_to_date_min\n    model: ref('fact_orders')\n    label: min value\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: min\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_to_date_min__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    period_to_date_min__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_min,period_to_date_min_this_year_min,period_to_date_min_max_for_year,period_to_date_min_sum_for_year,period_to_date_min_average_for_year\n2022-01-01,2022-01-01,1,1,1,1,1.000000\n2022-02-01,2022-01-01,1,1,1,2,1.000000\n\"\"\".lstrip()\nelse:\n    period_to_date_min__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_min,period_to_date_min_this_year_min,period_to_date_min_max_for_year,period_to_date_min_sum_for_year,period_to_date_min_average_for_year\n2022-01-01,2022-01-01,1,1,1,1,1.0000000000000000\n2022-02-01,2022-01-01,1,1,1,2,1.0000000000000000\n\"\"\".lstrip()\n\n# seeds/period_to_date_min__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_to_date_min__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_to_date_min__expected\n    config:\n      column_types:\n        date_month: date\n        date_year: date\n        period_to_date_min: INT64\n        period_to_date_min_this_year_min: INT64\n        period_to_date_min_max_for_year: INT64\n        period_to_date_min_sum_for_year: INT64\n        period_to_date_min_average_for_year: FLOAT64\n\"\"\".lstrip()\nelse: \n    period_to_date_min__expected_yml = \"\"\"\"\"\"\n\nclass TestPeriodToDateMin:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_to_date_min__expected.csv\": period_to_date_min__expected_csv,\n            \"period_to_date_min__expected.yml\": period_to_date_min__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_to_date_min.sql\": period_to_date_min_sql,\n            \"period_to_date_min.yml\": period_to_date_min_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/same_period_and_grain.sql\nsame_period_and_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('same_period_and_grain'), \n    grain='day',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"sum\", period=\"day\",alias=\"day_sum\")\n    ]\n    )\n}}\n\"\"\"\n\n# models/same_period_and_grain.yml\nsame_period_and_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: same_period_and_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('same_period_and_grain__expected')\nmetrics:\n  - name: same_period_and_grain\n    model: ref('fact_orders')\n    label: Count\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/same_period_and_grain__expected.csv\nsame_period_and_grain__expected_csv = \"\"\"\ndate_day,same_period_and_grain,same_period_and_grain_day_sum\n2022-02-03,1,1\n2022-01-12,0,0\n2022-01-07,0,0\n2022-02-01,0,0\n2022-01-08,1,1\n2022-02-10,0,0\n2022-01-28,1,1\n2022-01-14,0,0\n2022-02-15,1,1\n2022-02-08,0,0\n2022-01-21,1,1\n2022-02-13,1,1\n2022-02-04,0,0\n2022-01-17,0,0\n2022-02-09,0,0\n2022-01-13,1,1\n2022-02-06,0,0\n2022-01-11,0,0\n2022-02-12,0,0\n2022-01-16,0,0\n2022-02-05,0,0\n2022-01-15,0,0\n2022-01-23,0,0\n2022-01-06,1,1\n2022-01-26,0,0\n2022-01-22,1,1\n2022-01-19,0,0\n2022-01-25,0,0\n2022-01-09,0,0\n2022-02-14,0,0\n2022-01-10,0,0\n2022-01-30,0,0\n2022-02-11,0,0\n2022-01-27,0,0\n2022-01-29,0,0\n2022-01-24,0,0\n2022-01-31,0,0\n2022-01-20,1,1\n2022-01-18,0,0\n2022-02-02,0,0\n2022-02-07,0,0\n\"\"\".lstrip()\n\nclass TestSamePeriodAndGrainCount:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"same_period_and_grain__expected.csv\": same_period_and_grain__expected_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"same_period_and_grain.sql\": same_period_and_grain_sql,\n            \"same_period_and_grain.yml\": same_period_and_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/period_to_date_sum.sql\nperiod_to_date_sum_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('period_to_date_sum'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"sum\", period=\"year\", alias=\"this_year_sum\"),\n        metrics.period_to_date(aggregate=\"max\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"min\", period=\"year\"),\n        metrics.period_to_date(aggregate=\"average\", period=\"year\"),\n    ]\n    )\n}}\n\"\"\"\n\n# models/period_to_date_sum.yml\nperiod_to_date_sum_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: period_to_date_sum\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('period_to_date_sum__expected')\nmetrics:\n  - name: period_to_date_sum\n    model: ref('fact_orders')\n    label: sum value\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/period_to_date_sum__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    period_to_date_sum__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_sum,period_to_date_sum_this_year_sum,period_to_date_sum_max_for_year,period_to_date_sum_min_for_year,period_to_date_sum_average_for_year\n2022-01-01,2022-01-01,18,18,18,18,18.000000\n2022-02-01,2022-01-01,6,24,18,6,12.000000\n\"\"\".lstrip()\nelse:\n    period_to_date_sum__expected_csv = \"\"\"\ndate_month,date_year,period_to_date_sum,period_to_date_sum_this_year_sum,period_to_date_sum_max_for_year,period_to_date_sum_min_for_year,period_to_date_sum_average_for_year\n2022-01-01,2022-01-01,18,18,18,18,18.0000000000000000\n2022-02-01,2022-01-01,6,24,18,6,12.0000000000000000\n\"\"\".lstrip()\n\n# seeds/period_to_date_sum__expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    period_to_date_sum__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: period_to_date_sum__expected\n    config:\n      column_types:\n        date_month: date\n        date_year: date\n        period_to_date_sum: INT64\n        period_to_date_sum_this_year_sum: INT64\n        period_to_date_sum_max_for_year: INT64\n        period_to_date_sum_min_for_year: INT64\n        period_to_date_sum_average_for_year: FLOAT64\n\"\"\".lstrip()\nelse: \n    period_to_date_sum__expected_yml = \"\"\"\"\"\"\n    \n\nclass TestPeriodToDateSum:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"period_to_date_sum__expected.csv\": period_to_date_sum__expected_csv,\n            \"period_to_date_sum__expected.yml\": period_to_date_sum__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"period_to_date_sum.sql\": period_to_date_sum_sql,\n            \"period_to_date_sum.yml\": period_to_date_sum_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "d8e2c882e69205d805ba8d565f27cb3d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_period_to_date.py"}, "dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_prior.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n\n)\n\n# models/prior_metric.sql\nprior_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('prior_metric'), \n    grain='week',\n    secondary_calculations=[metrics.prior(interval=2)]\n    )\n}}\n\"\"\"\n\n# models/prior_metric.yml\nprior_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: prior_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('prior_metric__expected')\nmetrics:\n  - name: prior_metric\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/prior_metric__expected.csv\nprior_metric__expected_csv = \"\"\"\ndate_week,prior_metric,prior_metric_2_weeks_prior\n2022-02-14,1,1\n2022-02-07,1,1\n2022-01-31,1,3\n2022-01-24,1,1\n2022-01-17,3,2\n2022-01-10,1,\n2022-01-03,2,\n\"\"\".lstrip()\n\n\n# seeds/prior_metric__expected.yml\nprior_metric__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: prior_metric__expected\n\"\"\".lstrip()\n\nclass TestPrior:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"prior_metric__expected.csv\": prior_metric__expected_csv,\n            \"prior_metric__expected.yml\": prior_metric__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"custom_calendar.sql\": custom_calendar_sql,\n            \"prior_metric.sql\": prior_metric_sql,\n            \"prior_metric.yml\": prior_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n        \n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "88fae4faccc5c9dec14f886b459447ef", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/secondary_calculations/test_prior.py"}, "dbt_packages/metrics/tests/functional/metric_options/metric_reference/test_double_quote_ref_name.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/double_quote_ref_metrics.sql\ndouble_quote_ref_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    metric('base_count_metric'),\n    grain='month',\n    dimensions=['had_discount']\n    )\n}}\n\"\"\"\n\n# models/double_quote_ref_metrics.yml\ndouble_quote_ref_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: double_quote_ref_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('double_quote_ref_metrics__expected')\nmetrics:\n  - name: base_count_metric\n    model: ref(\"fact_orders\")\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n\"\"\"\n\n# seeds/double_quote_ref_metrics__expected.csv\ndouble_quote_ref_metrics__expected_csv = \"\"\"\ndate_month,had_discount,base_count_metric\n2022-01-01,TRUE,2\n2022-01-01,FALSE,5\n2022-02-01,TRUE,1\n2022-02-01,FALSE,2\n\"\"\".lstrip()\n\nclass TestDoubleQuoteRefMetrics:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"double_quote_ref_metrics__expected.csv\": double_quote_ref_metrics__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"double_quote_ref_metrics.sql\": double_quote_ref_metrics_sql,\n            \"double_quote_ref_metrics.yml\": double_quote_ref_metrics_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "8982e7329adbf4930b89a1db758f8f42", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/metric_reference/test_double_quote_ref_name.py"}, "dbt_packages/metrics/tests/functional/metric_options/window/test_window.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n)\n\n# models/base_window_metric.sql\nbase_window_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_window_metric'), \n    grain='week'\n    )\n}}\n\"\"\"\n\n# models/base_window_metric.yml\nbase_window_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_window_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_window_metric__expected')\nmetrics:\n  - name: base_window_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14\n        period: day\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_window_metric__expected.csv\nbase_window_metric__expected_csv = \"\"\"\ndate_week,base_window_metric\n2022-01-10,2\n2022-01-17,3\n2022-01-24,4\n2022-01-31,4\n2022-02-07,2\n2022-02-14,2\n2022-02-21,3\n2022-02-28,2\n\"\"\".lstrip()\n\nclass TestBaseDayWindowMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_window_metric__expected.csv\": base_window_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_window_metric.sql\": base_window_metric_sql,\n            \"base_window_metric.yml\": base_window_metric_yml,\n            \"custom_calendar.sql\": custom_calendar_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/base_window_metric.sql\nbase_window_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_window_metric'), \n    grain='week'\n    )\n}}\n\"\"\"\n\n# models/base_window_metric.yml\nbase_window_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_window_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_window_metric__expected')\nmetrics:\n  - name: base_window_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    window:\n        count: 2 \n        period: week\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_window_metric__expected.csv\nbase_window_metric__expected_csv = \"\"\"\ndate_week,base_window_metric\n2022-01-10,2\n2022-01-17,3\n2022-01-24,4\n2022-01-31,4\n2022-02-07,2\n2022-02-14,2\n2022-02-21,3\n2022-02-28,2\n\"\"\".lstrip()\n\nclass TestBaseWeekWindowMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_window_metric__expected.csv\": base_window_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_window_metric.sql\": base_window_metric_sql,\n            \"base_window_metric.yml\": base_window_metric_yml,\n            \"custom_calendar.sql\":custom_calendar_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/base_window_metric.sql\nbase_window_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_window_metric'), \n    grain='week'\n    )\n}}\n\"\"\"\n\n# models/base_window_metric.yml\nbase_window_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_window_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_window_metric__expected')\nmetrics:\n  - name: base_window_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    window:\n        count: 1\n        period: month\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_window_metric__expected.csv\nbase_window_metric__expected_csv = \"\"\"\ndate_week,base_window_metric\n2022-01-10,2\n2022-01-17,3\n2022-01-24,6\n2022-01-31,7\n2022-02-07,7\n2022-02-14,6\n2022-02-21,6\n2022-02-28,4\n2022-03-07,3\n2022-03-14,2\n\"\"\".lstrip()\n\nclass TestBaseMonthWindowMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_window_metric__expected.csv\": base_window_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_window_metric.sql\": base_window_metric_sql,\n            \"base_window_metric.yml\": base_window_metric_yml,\n            \"custom_calendar.sql\":custom_calendar_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "47cc17cfbf8c2876c43d12e62ed94c05", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/window/test_window.py"}, "dbt_packages/metrics/tests/functional/metric_options/date_grains/test_custom_calendar.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n)\n\n# models/base_sum_metric.sql\nbase_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_sum_metric'), \n    grain='month',\n    dimensions=[\"is_weekend\"]\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_sum_metric__expected')\nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_sum_metric__expected.csv\nbase_sum_metric__expected_csv = \"\"\"\ndate_month,is_weekend,base_sum_metric\n2022-01-01,true,8\n2022-02-01,true,6\n\"\"\".lstrip()\n\nclass TestCustomCalendarDimensionsMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_sum_metric__expected.csv\": base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"custom_calendar.sql\": custom_calendar_sql,\n            \"base_sum_metric.sql\": base_sum_metric_sql,\n            \"base_sum_metric.yml\": base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # breakpoint()\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/base_sum_metric_custom_grain.sql\nbase_sum_metric_custom_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_sum_metric_custom_grain'), \n    grain='test'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric_custom_grain.yml\nbase_sum_metric_custom_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_sum_metric_custom_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_sum_metric_custom_grain__expected')\nmetrics:\n  - name: base_sum_metric_custom_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month, test]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_sum_metric_custom_grain__expected.csv\nbase_sum_metric_custom_grain__expected_csv = \"\"\"\ndate_test,base_sum_metric_custom_grain\n2022-01-01,14\n\"\"\".lstrip()\n\nclass TestCustomCalendarGrainMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_sum_metric_custom_grain__expected.csv\": base_sum_metric_custom_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"custom_calendar.sql\": custom_calendar_sql,\n            \"base_sum_metric_custom_grain.sql\": base_sum_metric_custom_grain_sql,\n            \"base_sum_metric_custom_grain.yml\": base_sum_metric_custom_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 4\n\n        # breakpoint()\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "51b61378897d71297802db76ebc0505b", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/date_grains/test_custom_calendar.py"}, "dbt_packages/metrics/tests/functional/metric_options/date_grains/test_date_grains.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/day_grain_metric.sql\nday_grain_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('day_grain_metric'), \n    grain='day'\n    )\n}}\n\"\"\"\n\n# models/day_grain_metric.yml\nday_grain_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: day_grain_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('day_grain__expected')\nmetrics:\n  - name: day_grain_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/day_grain__expected.csv\nday_grain__expected_csv = \"\"\"\ndate_day,day_grain_metric\n2022-02-15,1\n2022-02-13,1\n2022-02-03,1\n2022-01-28,1\n2022-01-22,1\n2022-01-21,1\n2022-01-20,1\n2022-01-13,1\n2022-01-08,1\n2022-01-06,1\n\"\"\".lstrip()\n\nclass TestDayGrain:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"day_grain__expected.csv\": day_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"day_grain_metric.sql\": day_grain_metric_sql,\n            \"day_grain_metric.yml\": day_grain_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/week_grain_metric.sql\nweek_grain_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('week_grain_metric'), \n    grain='week'\n    )\n}}\n\"\"\"\n\n# models/week_grain_metric.yml\nweek_grain_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: week_grain_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('week_grain__expected')\nmetrics:\n  - name: week_grain_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nif os.getenv('dbt_target') == 'bigquery':\n    # seeds/week_grain__expected.csv\n    week_grain__expected_csv = \"\"\"\ndate_week,week_grain_metric\n2022-02-13,2\n2022-01-30,1\n2022-01-23,1\n2022-01-16,3\n2022-01-09,1\n2022-01-02,2\n\"\"\".lstrip()\nelse: \n    # seeds/week_grain__expected.csv\n    week_grain__expected_csv = \"\"\"\ndate_week,week_grain_metric\n2022-02-14,1\n2022-02-07,1\n2022-01-31,1\n2022-01-24,1\n2022-01-17,3\n2022-01-10,1\n2022-01-03,2\n\"\"\".lstrip()\n\nclass TestWeekGrain:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"week_grain__expected.csv\": week_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"week_grain_metric.sql\": week_grain_metric_sql,\n            \"week_grain_metric.yml\": week_grain_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/month_grain_metric.sql\nmonth_grain_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('month_grain_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/month_grain_metric.yml\nmonth_grain_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: month_grain_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('month_grain__expected')\nmetrics:\n  - name: month_grain_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/month_grain__expected.csv\nmonth_grain__expected_csv = \"\"\"\ndate_month,month_grain_metric\n2022-02-01,3\n2022-01-01,7\n\"\"\".lstrip()\n\nclass TestMonthGrain:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"month_grain__expected.csv\": month_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"month_grain_metric.sql\": month_grain_metric_sql,\n            \"month_grain_metric.yml\": month_grain_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n", "hash": "2929822e85e0f2265549362fe42522d4", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/date_grains/test_date_grains.py"}, "dbt_packages/metrics/tests/functional/metric_options/end_date/test_end_date.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n\n# models/early_end_date_base_sum_metric.sql\nearly_end_date_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('early_end_date_base_sum_metric'), \n    grain='month',\n    end_date='2022-01-27'\n    )\n}}\n\"\"\"\n\n# models/early_end_date_base_sum_metric.yml\nearly_end_date_base_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: early_end_date_base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('early_end_date_base_sum_metric__expected')\nmetrics:\n  - name: early_end_date_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/early_end_date_base_sum_metric__expected.csv\nearly_end_date_base_sum_metric__expected_csv = \"\"\"\ndate_month,early_end_date_base_sum_metric\n2022-01-01,6\n\"\"\".lstrip()\n\nclass TestEarlyEndDateBaseSumMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"early_end_date_base_sum_metric__expected.csv\": early_end_date_base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"early_end_date_base_sum_metric.sql\": early_end_date_base_sum_metric_sql,\n            \"early_end_date_base_sum_metric.yml\": early_end_date_base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/end_date_derived_metric.sql\nend_date_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('end_date_derived_metric'), \n    grain='month',\n    end_date='2022-01-27'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/end_date_derived_metric.yml\nend_date_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: end_date_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('end_date_derived_metric__expected')\nmetrics:\n  - name: end_date_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/end_date_derived_metric__expected.csv\nend_date_derived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,end_date_derived_metric\n2022-01-01,6,7\n\"\"\".lstrip()\n\nclass TestEndDateDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"end_date_derived_metric__expected.csv\": end_date_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"end_date_derived_metric.yml\": end_date_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"end_date_derived_metric.sql\": end_date_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/end_date_base_sum_metric.sql\nend_date_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('end_date_base_sum_metric'), \n    grain='month',\n    end_date='2022-01-31'\n    )\n}}\n\"\"\"\n\n# models/end_date_base_sum_metric.yml\nend_date_base_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: end_date_base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('end_date_base_sum_metric__expected')\nmetrics:\n  - name: end_date_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/end_date_base_sum_metric__expected.csv\nend_date_base_sum_metric__expected_csv = \"\"\"\ndate_month,end_date_base_sum_metric\n2022-01-01,8\n\"\"\".lstrip()\n\nclass TestEndDateBaseSumMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"end_date_base_sum_metric__expected.csv\": end_date_base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"end_date_base_sum_metric.sql\": end_date_base_sum_metric_sql,\n            \"end_date_base_sum_metric.yml\": end_date_base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/end_date_derived_metric.sql\nend_date_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('end_date_derived_metric'), \n    grain='month',\n    end_date='2022-01-31'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/end_date_derived_metric.yml\nend_date_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: end_date_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('end_date_derived_metric__expected')\nmetrics:\n  - name: end_date_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/end_date_derived_metric__expected.csv\nend_date_derived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,end_date_derived_metric\n2022-01-01,8,9\n\"\"\".lstrip()\n\nclass TestEndDateDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"end_date_derived_metric__expected.csv\": end_date_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"end_date_derived_metric.yml\": end_date_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"end_date_derived_metric.sql\": end_date_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/end_date_derived_metric.sql\nend_date_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('end_date_derived_metric'), \n    grain='month',\n    end_date='2022-01-31'\n    )\n}}\n\"\"\"\n\n# models/end_date_derived_metric.yml\nend_date_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: end_date_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('end_date_derived_metric__expected')\nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: end_date_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/end_date_derived_metric__expected.csv\nend_date_derived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,end_date_derived_metric\n2022-01-01,8,9\n\"\"\".lstrip()\n\nclass TestEndDateDerivedMetric:\n    \n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"end_date_derived_metric__expected.csv\": end_date_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"end_date_derived_metric.yml\": end_date_derived_metric_yml,\n            \"end_date_derived_metric.sql\": end_date_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "5a2f6fd3c4f96c6e1a45772f5cb65112", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/end_date/test_end_date.py"}, "dbt_packages/metrics/tests/functional/metric_options/case_when/test_case_when_metric.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/case_when_metric.sql\ncase_when_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('case_when_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/case_when_metric.yml\ncase_when_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: case_when_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('case_when_metric__expected')\nmetrics:\n  - name: case_when_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: case when had_discount = true then 1 else 0 end \n    dimensions:\n      - order_country\n\"\"\"\n\n# seeds/case_when_metric__expected.csv\ncase_when_metric__expected_csv = \"\"\"\ndate_month,case_when_metric\n2022-01-01,2\n2022-02-01,1\n\"\"\".lstrip()\n\nclass TestCaseWhenMetric:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"case_when_metric__expected.csv\": case_when_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"case_when_metric.sql\": case_when_metric_sql,\n            \"case_when_metric.yml\": case_when_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/case_when_metric_no_time_grain_sql.sql\ncase_when_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('case_when_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/case_when_metric_no_time_grain_yml.yml\ncase_when_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: case_when_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('case_when_metric_no_time_grain__expected')\nmetrics:\n  - name: case_when_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: case when had_discount = true then 1 else 0 end \n    dimensions:\n      - order_country\n\"\"\"\n\n# seeds/case_when_metric_no_time_grain__expected_csv.csv\ncase_when_metric_no_time_grain__expected_csv = \"\"\"\ncase_when_metric_no_time_grain\n3\n\"\"\".lstrip()\n\nclass TestNoTimestampCaseWhenMetric:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"case_when_metric_no_time_grain__expected.csv\": case_when_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"case_when_metric_no_time_grain.sql\": case_when_metric_no_time_grain_sql,\n            \"case_when_metric_no_time_grain.yml\": case_when_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "4375cf3402a5d85dae2aefe0afb4a885", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/case_when/test_case_when_metric.py"}, "dbt_packages/metrics/tests/functional/metric_options/dimensions/test_dimensions.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/multi_dimension_base_sum_metric.sql\nmulti_dimension_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('multi_dimension_base_sum_metric'), \n    grain='month',\n    dimensions=['had_discount','order_country']\n    )\n}}\n\"\"\"\n\n# models/multi_dimension_base_sum_metric.yml\nmulti_dimension_base_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multi_dimension_base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multi_dimension_base_sum_metric__expected')\nmetrics:\n  - name: multi_dimension_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multi_dimension_base_sum_metric__expected.csv\nmulti_dimension_base_sum_metric__expected_csv = \"\"\"\ndate_month,had_discount,order_country,multi_dimension_base_sum_metric\n2022-01-01,TRUE,France,1\n2022-01-01,TRUE,Japan,1\n2022-01-01,FALSE,France,4\n2022-01-01,FALSE,Japan,2\n2022-02-01,TRUE,France,4\n2022-02-01,FALSE,Japan,2\n\"\"\".lstrip()\n\nclass TestMultiDimensionBaseSumMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multi_dimension_base_sum_metric__expected.csv\": multi_dimension_base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"multi_dimension_base_sum_metric.sql\": multi_dimension_base_sum_metric_sql,\n            \"multi_dimension_base_sum_metric.yml\": multi_dimension_base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/single_dimension_base_sum_metric.sql\nsingle_dimension_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('single_dimension_base_sum_metric'), \n    grain='month',\n    dimensions=['had_discount']\n    )\n}}\n\"\"\"\n\n# models/single_dimension_base_sum_metric.yml\nsingle_dimension_base_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: single_dimension_base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('single_dimension_base_sum_metric__expected')\nmetrics:\n  - name: single_dimension_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/single_dimension_base_sum_metric__expected.csv\nsingle_dimension_base_sum_metric__expected_csv = \"\"\"\ndate_month,had_discount,single_dimension_base_sum_metric\n2022-01-01,TRUE,2\n2022-01-01,FALSE,6\n2022-02-01,TRUE,4\n2022-02-01,FALSE,2\n\"\"\".lstrip()\n\nclass TestSingleDimensionBaseSumMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"single_dimension_base_sum_metric__expected.csv\": single_dimension_base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"single_dimension_base_sum_metric.sql\": single_dimension_base_sum_metric_sql,\n            \"single_dimension_base_sum_metric.yml\": single_dimension_base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/multi_dimension_derived_metric.sql\nmulti_dimension_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('multi_dimension_derived_metric'), \n    grain='month',\n    dimensions=['had_discount','order_country']\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/multi_dimension_derived_metric.yml\nmulti_dimension_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multi_dimension_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multi_dimension_derived_metric__expected')\nmetrics:\n  - name: multi_dimension_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/multi_dimension_derived_metric__expected.csv\nmulti_dimension_derived_metric__expected_csv = \"\"\"\ndate_month,had_discount,order_country,base_sum_metric,multi_dimension_derived_metric\n2022-01-01,TRUE,France,1,2\n2022-01-01,TRUE,Japan,1,2\n2022-01-01,FALSE,France,4,5\n2022-01-01,FALSE,Japan,2,3\n2022-02-01,TRUE,France,4,5\n2022-02-01,FALSE,Japan,2,3\n\"\"\".lstrip()\n\nclass TestMultiDimensionDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"multi_dimension_derived_metric__expected.csv\": multi_dimension_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"multi_dimension_derived_metric.yml\": multi_dimension_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"multi_dimension_derived_metric.sql\": multi_dimension_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/single_dimension_derived_metric.sql\nsingle_dimension_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('single_dimension_derived_metric'), \n    grain='month',\n    dimensions=['had_discount']\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/single_dimension_derived_metric.yml\nsingle_dimension_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: single_dimension_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('single_dimension_derived_metric__expected')\nmetrics:\n  - name: single_dimension_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/single_dimension_derived_metric__expected.csv\nsingle_dimension_derived_metric__expected_csv = \"\"\"\ndate_month,had_discount,base_sum_metric,single_dimension_derived_metric\n2022-01-01,TRUE,2,3\n2022-01-01,FALSE,6,7\n2022-02-01,TRUE,4,5\n2022-02-01,FALSE,2,3\n\"\"\".lstrip()\n\nclass TestSingleDimensionDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"single_dimension_derived_metric__expected.csv\": single_dimension_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"single_dimension_derived_metric.yml\": single_dimension_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"single_dimension_derived_metric.sql\": single_dimension_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "231cd3889f5da51f8fa2d66247490a9a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/dimensions/test_dimensions.py"}, "dbt_packages/metrics/tests/functional/metric_options/where/test_where.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/where_base_metric.sql\nwhere_base_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('where_base_metric'), \n    grain='month',\n    dimensions=['had_discount'],\n    where=\"had_discount=true\"\n    )\n}}\n\"\"\"\n\n# models/where_base_metric.yml\nwhere_base_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: where_base_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('where_base_metric__expected')\nmetrics:\n  - name: where_base_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/where_base_metric__expected.csv\nwhere_base_metric__expected_csv = \"\"\"\ndate_month,had_discount,where_base_metric\n2022-01-01,TRUE,2\n2022-02-01,TRUE,4\n\"\"\".lstrip()\n\nclass TestWhereBaseMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"where_base_metric__expected.csv\": where_base_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"where_base_metric.sql\": where_base_metric_sql,\n            \"where_base_metric.yml\": where_base_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/where_derived_metric.sql\nwhere_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('where_derived_metric'), \n    grain='month',\n    dimensions=['had_discount'],\n    where=\"had_discount=true\"\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/where_derived_metric.yml\nwhere_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: where_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('where_derived_metric__expected')\nmetrics:\n  - name: where_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/where_derived_metric__expected.csv\nwhere_derived_metric__expected_csv = \"\"\"\ndate_month,had_discount,base_sum_metric,where_derived_metric\n2022-01-01,TRUE,2,3\n2022-02-01,TRUE,4,5\n\"\"\".lstrip()\n\nclass TestWhereDerivedMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"where_derived_metric__expected.csv\": where_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"where_derived_metric.yml\": where_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"where_derived_metric.sql\": where_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "b28451d959dcd78b12f73324d8f83b3c", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/where/test_where.py"}, "dbt_packages/metrics/tests/functional/metric_options/old_metric_spec/test_old_metric_spec.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/old_spec_metric.sql\nold_spec_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('old_spec_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/old_spec_metric.yml\nold_spec_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: old_spec_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('old_spec_metric__expected')\nmetrics:\n  - name: old_spec_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    type: sum\n    sql: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/old_spec_metric__expected.csv\nold_spec_metric__expected_csv = \"\"\"\ndate_month,old_spec_metric\n2022-01-01,8\n2022-02-01,6\n\"\"\".lstrip()\n\nclass TestOldSpecMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"old_spec_metric__expected.csv\": old_spec_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"old_spec_metric.sql\": old_spec_metric_sql,\n            \"old_spec_metric.yml\": old_spec_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "258ce1ac8e218de433cdb0152f5bb36e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/metric_options/old_metric_spec/test_old_metric_spec.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_period_to_date_average.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_period_to_date_average.sql\ninvalid_period_to_date_average_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_period_to_date_average'), \n    grain='month',\n    secondary_calculations=[\n        metrics.period_to_date(aggregate=\"average\", period=\"year\", alias=\"this_year_average\")\n    ]\n    )\n}}\n\"\"\"\n\n# models/invalid_period_to_date_average.yml\ninvalid_period_to_date_average_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_period_to_date_average\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('invalid_period_to_date_average__expected')\nmetrics:\n  - name: invalid_period_to_date_average\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidPeriodToDateAverage:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_period_to_date_average.sql\": invalid_period_to_date_average_sql,\n            \"invalid_period_to_date_average.yml\": invalid_period_to_date_average_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # initial run\n        results = run_dbt([\"run\"], expect_pass = False)\n", "hash": "f961d44119475f30c6b62275fafe91ab", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_period_to_date_average.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_backwards_compatability_metric_list.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/backwards_compatability_metric.sql\nbackwards_compatability_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.metric(\n    metric_name=['backwards_compatability_metric','base_average_metric'], \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/backwards_compatability_metric.yml\nbackwards_compatability_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: backwards_compatability_metric\n\nmetrics:\n  - name: backwards_compatability_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_average_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestBackwardsCompatibility:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"backwards_compatability_metric.sql\": backwards_compatability_metric_sql,\n            \"backwards_compatability_metric.yml\": backwards_compatability_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False)\n", "hash": "7b78dce30452598f15e901f434900f47", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_backwards_compatability_metric_list.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_no_time_grain_calendar_dimension.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n)\n\n# models/no_timestamp_base_sum_metric.sql\nno_timestamp_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('no_timestamp_base_sum_metric'), \n    dimensions=[\"is_weekend\"]\n    )\n}}\n\"\"\"\n\n# models/no_timestamp_base_sum_metric.yml\nno_timestamp_base_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: no_timestamp_base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('no_timestamp_base_sum_metric__expected')\nmetrics:\n  - name: no_timestamp_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_sum_metric__expected.csv\nno_timestamp_base_sum_metric__expected_csv = \"\"\"\nis_weekend,no_timestamp_base_sum_metric\ntrue,14\n\"\"\".lstrip()\n\nclass TestNoTimestampCustomCalendarDimensionsMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"no_timestamp_base_sum_metric__expected.csv\": no_timestamp_base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"custom_calendar.sql\": custom_calendar_sql,\n            \"no_timestamp_base_sum_metric.sql\": no_timestamp_base_sum_metric_sql,\n            \"no_timestamp_base_sum_metric.yml\": no_timestamp_base_sum_metric_yml\n        }\n\n    def test_invalid_no_time_grain_calendar_dimension(self,project):\n        # initial run\n        run_dbt([\"deps\"])\n        run_dbt([\"seed\"])\n        run_dbt([\"run\"],expect_pass = False)\n", "hash": "f48c2d1828dff2663c1118d64386e29f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_no_time_grain_calendar_dimension.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_no_time_grain_window.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\nfrom dbt.exceptions import YamlParseDictError\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml\n)\n\n# models/invalid_window_no_time_grain.yml\ninvalid_window_no_time_grain_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: invalid_window_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14\n        period: day\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/invalid_window_no_time_grain.sql\ninvalid_window_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_window_no_time_grain'))\n}}\n\"\"\"\n\nclass TestInvalidWindowNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_window_no_time_grain.yml\": invalid_window_no_time_grain_yml,\n            \"invalid_window_no_time_grain.sql\": invalid_window_no_time_grain_sql\n        }\n\n    def test_failing_window_no_time_grain(self,project):\n        with pytest.raises(YamlParseDictError):\n            run_dbt([\"deps\"])\n            run_dbt([\"run\"])\n\n\n# models/invalid_develop_window_no_time_grain.sql\ninvalid_develop_window_no_time_grain_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: invalid_window_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14\n        period: day\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        metric_list=['invalid_window_no_time_grain'],\n        develop_yml=my_metric_yml\n        )\n    }}\n\"\"\"\n\nclass TestInvalidDevelopWindowAllTime:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_develop_window_no_time_grain.sql\": invalid_develop_window_no_time_grain_sql\n        }\n\n    def test_failing_develop_window_no_time_grain(self,project):\n        run_dbt([\"deps\"])\n        run_dbt([\"seed\"])\n        run_dbt([\"run\"], expect_pass = False)\n", "hash": "4b92ea88b5dcca4fad9b14d20c8d6b40", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_no_time_grain_window.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_metric_config_value.py": {"contents": "from configparser import ParsingError\nfrom struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_metric_config_value.sql\ninvalid_metric_config_value_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_metric_config_value'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/invalid_metric_config_value.yml\ninvalid_metric_config_value_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_metric_config_value\n\nmetrics:\n  - name: invalid_metric_config_value\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      treat_null_values_as_zero: banana\n\"\"\"\n\nclass TestInvalidMetricConfig:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_metric_config_value.sql\": invalid_metric_config_value_sql,\n            \"invalid_metric_config_value.yml\": invalid_metric_config_value_yml\n        }\n\n    def test_metric_config_value(self,project,):\n        # initial run\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # Here we expect the run to fail because the value provided\n        # in the where clause isn't included in the final dataset\n        run_dbt([\"run\"], expect_pass = False)", "hash": "33aecfab9a2706299b0ade7ed5f9b554", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_metric_config_value.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__invalid_model.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_develop_config.sql\ninvalid_develop_config_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: invalid_develop_config\n    model: ref('some_unknown_model')\n    label: develop metric dimensions\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        grain='month'\n        )\n    }}\n\"\"\"\n\nclass TestDevelopMetricDimension:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_develop_config.sql\": invalid_develop_config_sql,\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False)", "hash": "023b979a9263208a5bd7919bb26c0a9f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__invalid_model.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_backwards_compatability_expression_metric.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/backwards_compatability_metric.sql\nbackwards_compatability_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.metric(\n    metric_name='backwards_compatability_derived_metric', \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/backwards_compatability_metric.yml\nbackwards_compatability_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: backwards_compatability_derived_metric\n\nmetrics:\n  - name: backwards_compatability_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: backwards_compatability_derived_metric\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('backwards_compatability_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestBackwardsCompatibilityDerivedMetric:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"backwards_compatability_derived_metric.sql\": backwards_compatability_derived_metric_sql,\n            \"backwards_compatability_metric.yml\": backwards_compatability_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False)\n", "hash": "c35b41318c8c54d237956975f38e2b90", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_backwards_compatability_expression_metric.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_undefined_metric.py": {"contents": "from configparser import ParsingError\nfrom struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\nfrom dbt.exceptions import TargetNotFoundError\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/undefined_metric.sql\nundefined_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('undefined_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/undefined_metric.yml\nundefined_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: undefined_metric\n\nmetrics:\n  - name: not_undefined_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestUndefinedMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"undefined_metric.sql\": undefined_metric_sql,\n            \"undefined_metric.yml\": undefined_metric_yml\n        }\n\n    def test_undefined_metric(self,project,):\n        with pytest.raises(TargetNotFoundError):\n            run_dbt([\"deps\"])\n            run_dbt([\"seed\"])\n            run_dbt([\"run\"])", "hash": "e0d26ee80ec3495e9f6d185770553428", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_undefined_metric.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__invalid_type.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_develop_config.sql\ninvalid_develop_config_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: invalid_develop_config\n    model: ref('some_unknown_model')\n    label: develop metric dimensions\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: median\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        grain='month'\n        )\n    }}\n\"\"\"\n\nclass TestDevelopMetricDimension:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_develop_config.sql\": invalid_develop_config_sql,\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False)", "hash": "2a788ac6b709e60cda205d4163ec333d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__invalid_type.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_metric_config.py": {"contents": "from configparser import ParsingError\nfrom struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_metric_config.sql\ninvalid_metric_config_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_metric_config'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/invalid_metric_config.yml\ninvalid_metric_config_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_metric_config\n\nmetrics:\n  - name: invalid_metric_config\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n    config:\n      did_dave_write_this: true\n\"\"\"\n\nclass TestInvalidMetricConfig:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_metric_config.sql\": invalid_metric_config_sql,\n            \"invalid_metric_config.yml\": invalid_metric_config_yml\n        }\n\n    def test_invalid_metric_config(self,project,):\n        # initial run\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # Here we expect the run to fail because the value provided\n        # in the where clause isn't included in the final dataset\n        run_dbt([\"run\"], expect_pass = False)", "hash": "24d9adc9b6d2a5cbb5afa4a149b30c4a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_metric_config.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_metric_name.py": {"contents": "from configparser import ParsingError\nfrom struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\nfrom dbt.exceptions import ParsingError\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_metric_name.sql\ninvalid_metric_name_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid metric name'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/invalid_metric_name.yml\ninvalid_metric_name_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_metric_name\n\nmetrics:\n  - name: invalid metric name\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidMetricName:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_metric_name.sql\": invalid_metric_name_sql,\n            \"invalid_metric_name.yml\": invalid_metric_name_yml\n        }\n\n    def test_model_name(self,project,):\n        # initial run\n        with pytest.raises(ParsingError):\n            run_dbt([\"deps\"])\n            run_dbt([\"run\"])", "hash": "9a007a006dc278d643aa74f2980b35b2", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_metric_name.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_no_time_grain_secondary_calc.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    custom_calendar_sql\n)\n\n# models/no_time_grain_base_sum_metric.sql\nno_time_grain_base_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    metric('no_time_grain_base_sum_metric'), \n    secondary_calculations=[\n        metrics.period_over_period(comparison_strategy=\"difference\", interval=1, alias = \"1mth\")\n    ]\n    )\n}}\n\"\"\"\n\n# models/no_time_grain_base_sum_metric.yml\nno_time_grain_base_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: no_time_grain_base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestNoTimeGrainSecondaryCalcMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"custom_calendar.sql\": custom_calendar_sql,\n            \"no_time_grain_base_sum_metric.sql\": no_time_grain_base_sum_metric_sql,\n            \"no_time_grain_base_sum_metric.yml\": no_time_grain_base_sum_metric_yml\n        }\n\n    def test_invalid_no_time_grain_secondary_calc(self,project,):\n        # initial run\n        run_dbt([\"deps\"])\n        run_dbt([\"seed\"])\n        run_dbt([\"run\"],expect_pass = False)\n\n", "hash": "86300dc7013e92f3db3745da5400eb10", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_no_time_grain_secondary_calc.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_where.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_where.sql\ninvalid_where_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_where'), \n    grain='month',\n    dimensions=['had_discount'],\n    where=\"order_country='Japan'\"\n    )\n}}\n\"\"\"\n\n# models/invalid_where.yml\ninvalid_where_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_where\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('invalid_where__expected')\nmetrics:\n  - name: invalid_where\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidWhereMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_where.sql\": invalid_where_sql,\n            \"invalid_where.yml\": invalid_where_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # Here we expect the run to fail because the value provided\n        # in the where clause isn't included in the final dataset\n        results = run_dbt([\"run\"], expect_pass = False)\n\n", "hash": "f6553eb7ea9cccdd43dcc72c50d4f684", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_where.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__missing_timestamp.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_develop_config.sql\ninvalid_develop_config_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: invalid_develop_config\n    model: ref('fact_orders')\n    label: develop metric dimensions\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        grain='month'\n        )\n    }}\n\"\"\"\n\nclass TestDevelopMetricDimension:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_develop_config.sql\": invalid_develop_config_sql,\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False)", "hash": "0913a8e1caa399a7fa5efee8117b30b0", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__missing_timestamp.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__invalid_dimension.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_develop_config.sql\ninvalid_develop_config_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: invalid_develop_config\n    model: ref('fact_orders')\n    label: develop metric dimensions\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        grain='month',\n        dimensions=['invalid_dimension_name']\n        )\n    }}\n\"\"\"\n\nclass TestDevelopMetricDimension:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_develop_config.sql\": invalid_develop_config_sql,\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False)", "hash": "00097717fb1055873e849926280df09c", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config__invalid_dimension.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_time_grain.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_time_grain.sql\ninvalid_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_time_grain'), \n    grain='year'\n    )\n}}\n\"\"\"\n\n# models/multiple_metrics.sql\nmultiple_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric'), metric('base_count_metric')],\n    grain='year'\n    )\n}}\n\"\"\"\n\n\n# models/invalid_time_grain.yml\ninvalid_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_time_grain\n\nmetrics:\n  - name: invalid_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/multiple_metrics.yml\nmultiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics__expected')\nmetrics:\n  - name: base_count_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month, year]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_time_grain.sql\": invalid_time_grain_sql,\n            \"invalid_time_grain.yml\": invalid_time_grain_yml,\n            \"multiple_metrics.sql\": multiple_metrics_sql,\n            \"multiple_metrics.yml\": multiple_metrics_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # Here we expect the run to fail because the incorrect\n        # time grain won't allow it to compile\n        results = run_dbt([\"run\"], expect_pass = False)", "hash": "be1bdc395d4f15b8c484a1eb4320d588", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_time_grain.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_derived_metric.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_derived_metric.sql\ninvalid_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_derived_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/invalid_derived_metric.yml\ninvalid_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_derived_metric\n\nmetrics:\n  - name: invalid_derived_metric\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidDerivedMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_derived_metric.sql\": invalid_derived_metric_sql,\n            \"invalid_derived_metric.yml\": invalid_derived_metric_yml\n        }\n\n    def test_invalid_derived_metric(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # Here we expect the run to fail because the incorrect\n        # config won't allow it to compile\n        run_dbt([\"run\"], expect_pass = False)", "hash": "9dd4043ab66952df44d19aea04d82c65", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_derived_metric.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_window_periods.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\nfrom dbt.exceptions import YamlParseDictError\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml\n)\n\n# models/base_window_metric.yml\nday_window_metric_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: base_window_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14\n        period: days\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestPluralDaysWindow:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"day_window_metric.yml\": day_window_metric_yml,\n        }\n\n    def test_failing_plural_days(self,project,):\n        with pytest.raises(YamlParseDictError):\n            run_dbt([\"deps\"])\n            run_dbt([\"run\"])\n\nweek_window_metric_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: base_window_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14\n        period: weeks\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestPluralWeeksWindow:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"week_window_metric.yml\": week_window_metric_yml,\n        }\n\n    def test_failing_plural_weeks(self,project,):\n        with pytest.raises(YamlParseDictError):\n            run_dbt([\"deps\"])\n            run_dbt([\"run\"])\n\nmonth_window_metric_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: base_window_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14\n        period: months\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestPluralMonthWindow:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"month_window_metric.yml\": month_window_metric_yml,\n        }\n\n    def test_failing_plural_months(self,project,):\n        with pytest.raises(YamlParseDictError):\n            run_dbt([\"deps\"])\n            run_dbt([\"run\"])\n\nyear_window_metric_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: base_window_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: discount_total\n    window: \n        count: 14\n        period: years\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestPluralYearsWindow:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"year_window_metric.yml\": year_window_metric_yml,\n        }\n\n    def test_failing_plural_years(self,project,):\n        with pytest.raises(YamlParseDictError):\n            run_dbt([\"deps\"])\n            run_dbt([\"run\"])", "hash": "30aef05f4397e959f5aa12af7dc09420", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_window_periods.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_dimension.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_dimension.sql\ninvalid_dimension_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('invalid_dimension'), \n    grain='year',\n    dimensions=['invalid_dimension_name']\n    )\n}}\n\"\"\"\n\n# models/multiple_metrics.sql\nmultiple_metrics_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(\n    [metric('base_sum_metric'), metric('base_count_metric')],\n    grain='month',\n    dimensions=['invalid_dimension_name']\n    )\n}}\n\"\"\"\n\n# models/invalid_dimension.yml\ninvalid_dimension_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: invalid_dimension\n\nmetrics:\n  - name: invalid_dimension\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/multiple_metrics.yml\nmultiple_metrics_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: multiple_metrics\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('multiple_metrics__expected')\nmetrics:\n  - name: base_count_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidDimension:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_dimension.sql\": invalid_dimension_sql,\n            \"invalid_dimension.yml\": invalid_dimension_yml,\n            \"multiple_metrics.yml\": multiple_metrics_yml,\n            \"multiple_metrics.sql\": multiple_metrics_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 1\n\n        # Here we expect the run to fail because the incorrect\n        # time grain won't allow it to compile\n        results = run_dbt([\"run\"], expect_pass = False)", "hash": "c2882116bd6eeb6cb2ae4d82fc7bdf46", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_dimension.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_calendar_dim_without_param.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/custom_calendar.sql\ncustom_calendar_sql = \"\"\"\nwith days as (\n    {{ metrics.metric_date_spine(\n    datepart=\"day\",\n    start_date=\"cast('2010-01-01' as date)\",\n    end_date=\"cast('2030-01-01' as date)\"\n   )\n    }}\n),\n\nfinal as (\n    select \n        cast(date_day as date) as date_day,\n        {% if target.type == 'bigquery' %}\n            --BQ starts its weeks on Sunday. I don't actually care which day it runs on for auto testing purposes, just want it to be consistent with the other seeds\n            cast({{ date_trunc('week(MONDAY)', 'date_day') }} as date) as date_week,\n        {% else %}\n            cast({{ date_trunc('week', 'date_day') }} as date) as date_week,\n        {% endif %}\n        cast({{ date_trunc('month', 'date_day') }} as date) as date_month,\n        cast({{ date_trunc('quarter', 'date_day') }} as date) as date_quarter,\n        cast({{ date_trunc('year', 'date_day') }} as date) as date_year,\n        true as is_weekend\n    from days\n)\n\nselect * from final\n\n\"\"\"\n\n\n# models/base_sum_metric.sql\nbase_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_sum_metric'), \n    grain='month',\n    dimensions=[\"is_not_weekend\"]\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_sum_metric__expected')\nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\nclass TestInvalidCustomCalendarDimensionsMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"},\n            \"vars\":{\n                \"dbt_metrics_calendar_model\": \"custom_calendar\",\n                \"custom_calendar_dimension_list\": [\"is_weekend\"]\n            }\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"custom_calendar.sql\": custom_calendar_sql,\n            \"base_sum_metric.sql\": base_sum_metric_sql,\n            \"base_sum_metric.yml\": base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False)", "hash": "c646e2b252f3141cfc292194c99caa06", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_calendar_dim_without_param.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_date_datatype.py": {"contents": "from configparser import ParsingError\nfrom struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/max_date_invalid_datatype.sql\nmax_date_invalid_datatype_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('max_date_invalid_datatype'), \n    grain='day'\n    )\n}}\n\"\"\"\n\n# models/invalid_metric_names.yml\ninvalid_metric_names_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: max_date_invalid_datatype\n    model: ref('fact_orders')\n    label: max_date_invalid_datatype\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: max\n    expression: order_date\n\"\"\"\n\nclass TestInvalidDatatypes:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"max_date_invalid_datatype.sql\": max_date_invalid_datatype_sql,\n            \"invalid_metric_names.yml\": invalid_metric_names_yml\n        }\n\n    def test_invalid_date_datatype(self,project,):\n        # running deps to install package\n        run_dbt([\"deps\"])\n        run_dbt([\"seed\"])\n\n        # initial run\n        run_dbt([\"run\"],expect_pass = False)", "hash": "872c0b3d51bfe2749c3862ab79869ed4", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_date_datatype.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config_invalid_model.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/invalid_develop_config.sql\ninvalid_develop_config_sql = \"\"\"\n{% set my_metric_yml -%}\n\nmetrics:\n  - name: invalid_develop_config\n    model: ref('some_unknown_model')\n    label: develop metric dimensions\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n{%- endset %}\n\nselect * \nfrom {{ metrics.develop(\n        develop_yml=my_metric_yml,\n        grain='month'\n        )\n    }}\n\"\"\"\n\nclass TestDevelopMetricDimension:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"invalid_develop_config.sql\": invalid_develop_config_sql,\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        # initial run\n        results = run_dbt([\"run\"],expect_pass = False) \n        ", "hash": "4b9842bb1ad40148437e7346ca961d87", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_develop_config_invalid_model.py"}, "dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_string_datatype.py": {"contents": "from configparser import ParsingError\nfrom struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/max_string_invalid_datatype.sql\nmax_string_invalid_datatype_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('max_string_invalid_datatype'), \n    grain='day'\n    )\n}}\n\"\"\"\n\n# models/invalid_metric_names.yml\ninvalid_metric_names_yml = \"\"\"\nversion: 2 \n\nmetrics:\n  - name: max_string_invalid_datatype\n    model: ref('fact_orders')\n    label: max_date_invalid_datatype\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: max\n    expression: order_country\n\"\"\"\n\nclass TestInvalidStringDataType:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv\n            }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"max_string_invalid_datatype.sql\":max_string_invalid_datatype_sql,\n            \"invalid_metric_names.yml\": invalid_metric_names_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n        results = run_dbt([\"seed\"])\n\n        if os.getenv('dbt_target') == 'databricks':\n            # initial run. Databricks has a funky way of handling coalesce\n            results = run_dbt([\"run\"])\n        else:\n            # initial run\n            results = run_dbt([\"run\"], expect_pass = False)\n", "hash": "8b92c463d7187081be051c5c13258a87", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/invalid_configs/test_invalid_string_datatype.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_median.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml\n)\n\n# models/base_median_metric.sql\nbase_median_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_median_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_median_metric.yml\nbase_median_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_median_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_median_metric__expected')\nmetrics:\n  - name: base_median_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: median\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_median_metric__expected.csv\nbase_median_metric__expected_csv = \"\"\"\ndate_month,base_median_metric\n2022-01-01,1\n2022-02-01,1\n\"\"\".lstrip()\n\nclass TestBaseMedianMetric:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_median_metric__expected.csv\": base_median_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_median_metric.sql\": base_median_metric_sql,\n            \"base_median_metric.yml\": base_median_metric_yml\n        }\n\n    def test_base_median_metric(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/base_median_metric_no_time_grain.sql\nbase_median_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_median_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/base_median_metric_no_time_grain.yml\nbase_median_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_median_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_median_metric_no_time_grain__expected')\nmetrics:\n  - name: base_median_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: median\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_median_metric_no_time_grain__expected.csv\nbase_median_metric_no_time_grain__expected_csv = \"\"\"\nbase_median_metric_no_time_grain\n1\n\"\"\".lstrip()\n\nclass TestBaseMedianMetricNoTimeGrain:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_median_metric_no_time_grain__expected.csv\": base_median_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_median_metric_no_time_grain.sql\": base_median_metric_no_time_grain_sql,\n            \"base_median_metric_no_time_grain.yml\": base_median_metric_no_time_grain_yml\n        }\n\n    def test_base_median_metric_no_time_grain(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# seeds/complicated_median_source.csv\ncomplicated_median_source_csv = \"\"\"\norder_id,order_country,had_discount,customer_id,order_date,order_total\n4,France,true,3,2022-01-06,1.43\n5,France,false,4,2022-01-08,4.29\n3,France,false,1,2022-01-13,6.56\n2,Japan,false,2,2022-01-20,5.93\n6,Japan,false,5,2022-01-21,1.01\n7,Japan,true,2,2022-01-22,2.7\n1,France,false,1,2022-01-28,3.34\n9,Japan,false,2,2022-02-03,7.11\n10,Japan,false,3,2022-02-13,5.89\n8,France,true,1,2022-02-15,9.12\n\"\"\".lstrip()\n\n# models/base_median_metric_complicated_source.sql\nbase_median_metric_complicated_source_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_median_metric_complicated_source'),\n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_median_metric_complicated_source.yml\nbase_median_metric_complicated_source_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_median_metric_complicated_source\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_median_metric_complicated_source__expected')\nmetrics:\n  - name: base_median_metric_complicated_source\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: median\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_median_metric_complicated_source_expected.csv\nbase_median_metric_complicated_source__expected_csv = \"\"\"\ndate_month,base_median_metric_complicated_source\n2022-01-01,3.34\n2022-02-01,7.11\n\"\"\".lstrip()\n\nclass TestBaseMedianMetricComplicatedSource:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": complicated_median_source_csv,\n            \"base_median_metric_complicated_source__expected.csv\": base_median_metric_complicated_source__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_median_metric_complicated_source.sql\": base_median_metric_complicated_source_sql,\n            \"base_median_metric_complicated_source.yml\": base_median_metric_complicated_source_yml\n        }\n\n    def test_base_median_metric_complicated_source(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "6863aac47cdb20d14f9ed7323ad09c81", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_median.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_max.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/base_max_metric.sql\nbase_max_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_max_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_max_metric.yml\nbase_max_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_max_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_max_metric__expected')\nmetrics:\n  - name: base_max_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: max\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_max_metric__expected.csv\nbase_max_metric__expected_csv = \"\"\"\ndate_month,base_max_metric\n2022-01-01,2\n2022-02-01,4\n\"\"\".lstrip()\n\nclass TestBaseMaxMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_max_metric__expected.csv\": base_max_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_max_metric.sql\": base_max_metric_sql,\n            \"base_max_metric.yml\": base_max_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/base_max_metric_no_time_grain.sql\nbase_max_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_max_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/base_max_metric_no_time_grain.yml\nbase_max_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_max_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_max_metric_no_time_grain__expected')\nmetrics:\n  - name: base_max_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: max\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_max_metric_no_time_grain__expected.csv\nbase_max_metric_no_time_grain__expected_csv = \"\"\"\nbase_max_metric_no_time_grain\n4\n\"\"\".lstrip()\n\nclass TestBaseMaxMetricNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_max_metric_no_time_grain__expected.csv\": base_max_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_max_metric_no_time_grain.sql\": base_max_metric_no_time_grain_sql,\n            \"base_max_metric_no_time_grain.yml\": base_max_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "42a01c779fa9bd823376dcd6f8b94a28", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_max.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_count.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/base_count_metric.sql\nbase_count_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_count_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_count_metric.yml\nbase_count_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_count_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_count_metric__expected')\nmetrics:\n  - name: base_count_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_count_metric__expected.csv\nbase_count_metric__expected_csv = \"\"\"\ndate_month,base_count_metric\n2022-01-01,7\n2022-02-01,3\n\"\"\".lstrip()\n\nclass TestBaseCountMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_count_metric__expected.csv\": base_count_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_count_metric.sql\": base_count_metric_sql,\n            \"base_count_metric.yml\": base_count_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/base_count_metric_no_time_grain.sql\nbase_count_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_count_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/base_count_metric_no_time_grain.yml\nbase_count_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_count_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_count_metric_no_time_grain__expected')\nmetrics:\n  - name: base_count_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: count\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_count_metric_no_time_grain__expected.csv\nbase_count_metric_no_time_grain__expected_csv = \"\"\"\nbase_count_metric_no_time_grain\n10\n\"\"\".lstrip()\n\nclass TestBaseCountMetricNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_count_metric_no_time_grain__expected.csv\": base_count_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_count_metric_no_time_grain.sql\": base_count_metric_no_time_grain_sql,\n            \"base_count_metric_no_time_grain.yml\": base_count_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "5bb1295a3f29ddec23a4e21d87623845", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_count.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_sum.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/base_sum_metric.sql\nbase_sum_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_sum_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_sum_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_sum_metric__expected')\nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_sum_metric__expected.csv\nbase_sum_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric\n2022-01-01,8\n2022-02-01,6\n\"\"\".lstrip()\n\nclass TestBaseSumMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_sum_metric__expected.csv\": base_sum_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.sql\": base_sum_metric_sql,\n            \"base_sum_metric.yml\": base_sum_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/base_sum_metric_no_time_grain.sql\nbase_sum_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_sum_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/base_sum_metric_no_time_grain.yml\nbase_sum_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_sum_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_sum_metric_no_time_grain__expected')\nmetrics:\n  - name: base_sum_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_sum_metric_no_time_grain__expected.csv\nbase_sum_metric_no_time_grain__expected_csv = \"\"\"\nbase_sum_metric_no_time_grain\n14\n\"\"\".lstrip()\n\nclass TestBaseSumMetricNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_sum_metric_no_time_grain__expected.csv\": base_sum_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric_no_time_grain.sql\": base_sum_metric_no_time_grain_sql,\n            \"base_sum_metric_no_time_grain.yml\": base_sum_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "c02205765d0f70bdc65894a5fee6ae23", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_sum.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_count_distinct.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml\n)\n\n# models/base_count_distinct_metric.sql\nbase_count_distinct_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_count_distinct_metric'), \n    grain='month'\n    ) \n}}\n\"\"\"\n\n# models/base_count_distinct_metric.yml\nbase_count_distinct_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_count_distinct_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_count_distinct_metric__expected')\n\nmetrics:\n  - name: base_count_distinct_metric\n    model: ref('fact_orders')\n    label: Count Distinct\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: count_distinct\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_count_distinct_metric__expected.csv\nbase_count_distinct_metric__expected_csv = \"\"\"\ndate_month,base_count_distinct_metric\n2022-01-01,5\n2022-02-01,3\n\"\"\".lstrip()\n\nclass TestBaseCountDistinctMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_count_distinct_metric__expected.csv\": base_count_distinct_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_count_distinct_metric.sql\": base_count_distinct_metric_sql,\n            \"base_count_distinct_metric.yml\": base_count_distinct_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/base_count_distinct_metric_no_time_grain.sql\nbase_count_distinct_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_count_distinct_metric_no_time_grain')) \n}}\n\"\"\"\n\n# models/base_count_distinct_metric_no_time_grain.yml\nbase_count_distinct_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_count_distinct_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_count_distinct_metric_no_time_grain__expected')\n\nmetrics:\n  - name: base_count_distinct_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Count Distinct\n    calculation_method: count_distinct\n    expression: customer_id\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_count_distinct_metric_no_time_grain__expected.csv\nbase_count_distinct_metric_no_time_grain__expected_csv = \"\"\"\nbase_count_distinct_metric_no_time_grain\n5\n\"\"\".lstrip()\n\nclass TestBaseCountDistinctMetricNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_count_distinct_metric_no_time_grain__expected.csv\": base_count_distinct_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_count_distinct_metric_no_time_grain.sql\": base_count_distinct_metric_no_time_grain_sql,\n            \"base_count_distinct_metric_no_time_grain.yml\": base_count_distinct_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "9c354dac6ddfd21b18aa327decce934a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_count_distinct.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_min.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/base_min_metric.sql\nbase_min_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_min_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_min_metric.yml\nbase_min_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_min_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_min_metric__expected')\nmetrics:\n  - name: base_min_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: min\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_min_metric__expected.csv\nbase_min_metric__expected_csv = \"\"\"\ndate_month,base_min_metric\n2022-01-01,1\n2022-02-01,1\n\"\"\".lstrip()\n\nclass TestBaseMinMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_min_metric__expected.csv\": base_min_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_min_metric.sql\": base_min_metric_sql,\n            \"base_min_metric.yml\": base_min_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/base_min_metric_no_time_grain.sql\nbase_min_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_min_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/base_min_metric_no_time_grain.yml\nbase_min_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_min_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_min_metric_no_time_grain__expected')\nmetrics:\n  - name: base_min_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: min\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_min_metric_no_time_grain__expected.csv\nbase_min_metric_no_time_grain__expected_csv = \"\"\"\nbase_min_metric_no_time_grain\n1\n\"\"\".lstrip()\n\nclass TestBaseMinMetricNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_min_metric_no_time_grain__expected.csv\": base_min_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_min_metric_no_time_grain.sql\": base_min_metric_no_time_grain_sql,\n            \"base_min_metric_no_time_grain.yml\": base_min_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "a14764c32fe0410ae03831262b993431", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_min.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_derived.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n)\n\n# models/derived_metric.sql\nderived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('derived_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/derived_metric.yml\nderived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('derived_metric__expected')\nmetrics:\n  - name: derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/derived_metric__expected.csv\nderived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,derived_metric\n2022-02-01,6,7\n2022-01-01,8,9\n\"\"\".lstrip()\n\nclass TestDerivedMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"derived_metric__expected.csv\": derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"derived_metric.yml\": derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"derived_metric.sql\": derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/derived_metric_no_time_grain.sql\nderived_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('derived_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/base_sum_metric_no_time_grain.yml\nbase_sum_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/derived_metric_no_time_grain.yml\nderived_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: derived_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('derived_metric_no_time_grain__expected')\nmetrics:\n  - name: derived_metric_no_time_grain\n    label: derived ($)\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric_no_time_grain')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/derived_metric_no_time_grain__expected.csv\nderived_metric_no_time_grain__expected_csv = \"\"\"\nbase_sum_metric_no_time_grain,derived_metric_no_time_grain\n14,15\n\"\"\".lstrip()\n\nclass TestDerivedMetricNoTimeGrain:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"derived_metric_no_time_grain__expected.csv\": derived_metric_no_time_grain__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric_no_time_grain.yml\": base_sum_metric_no_time_grain_yml,\n            \"derived_metric_no_time_grain.sql\": derived_metric_no_time_grain_sql,\n            \"derived_metric_no_time_grain.yml\": derived_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n\n# models/divide_by_zero_expression_metric.sql\ndivide_by_zero_expression_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate([metric('base_sum_metric'),metric('divide_by_zero_expression_metric')], \n    grain='month',\n    dimensions=['had_discount','order_country']\n    )\n}}\n\"\"\"\n\n# models/divide_by_zero_expression_metric.yml\ndivide_by_zero_expression_metric_yml = \"\"\"\nversion: 2 \n\nmodels:\n  - name: divide_by_zero_expression_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('divide_by_zero_expression_metric__expected')\nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: divide_by_zero_expression_metric\n    label: Inverse Total Amount (Nulls)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"100 / {{ metric('base_sum_metric') }}\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/divide_by_zero_expression_metric__expected.csv\ndivide_by_zero_expression_metric__expected_csv = \"\"\"\ndate_month,had_discount,order_country,base_sum_metric,divide_by_zero_expression_metric\n2022-01-01,TRUE,France,1,100\n2022-01-01,TRUE,Japan,1,100\n2022-01-01,FALSE,France,4,25\n2022-01-01,FALSE,Japan,2,50\n2022-02-01,TRUE,France,4,25\n2022-02-01,FALSE,Japan,2,50\n\"\"\".lstrip()\n\nclass TestDefaultValueNullMetric:\n\n    # configuration in dbt_project.yml\n    # setting bigquery as table to get around query complexity \n    # resource constraints with compunding views\n    if os.getenv('dbt_target') == 'bigquery':\n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"table\"}\n            }\n    else: \n        @pytest.fixture(scope=\"class\")\n        def project_config_update(self):\n            return {\n            \"name\": \"example\",\n            \"models\": {\"+materialized\": \"view\"}\n            }  \n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"divide_by_zero_expression_metric__expected.csv\": divide_by_zero_expression_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"divide_by_zero_expression_metric.yml\": divide_by_zero_expression_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"divide_by_zero_expression_metric.sql\": divide_by_zero_expression_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/metric_on_derived_metric.sql\nmetric_on_derived_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('metric_on_derived_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_sum_metric.yml\nbase_sum_metric_yml = \"\"\"\nversion: 2 \nmetrics:\n  - name: base_sum_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: sum\n    expression: order_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# models/derived_metric.yml\nmetric_on_derived_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: metric_on_derived_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('metric_on_derived_metric__expected')\nmetrics:\n  - name: derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('base_sum_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\n  - name: metric_on_derived_metric\n    label: derived ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: derived\n    expression: \"{{metric('derived_metric')}} + 1\"\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/metric_on_derived_metric__expected.csv\nmetric_on_derived_metric__expected_csv = \"\"\"\ndate_month,base_sum_metric,derived_metric,metric_on_derived_metric\n2022-02-01,6,7,8\n2022-01-01,8,9,10\n\"\"\".lstrip()\n\nclass TestMetricOnDerivedMetric:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"metric_on_derived_metric__expected.csv\": metric_on_derived_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"metric_on_derived_metric.yml\": metric_on_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"metric_on_derived_metric.sql\": metric_on_derived_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n\n# models/metric_on_derived_metric.sql\nall_time_dimension_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('metric_on_derived_metric'), \n    dimensions=['had_discount']\n    )\n}}\n\"\"\"\n\n# seeds/metric_on_expression_metric__expected.csv\nall_time_dimension_metric__expected_csv = \"\"\"\nmetric_start_date,metric_end_date,had_discount,base_sum_metric,metric_on_derived_metric,derived_metric\n2022-01-06,2022-02-15,true,6,8,7\n2022-01-08,2022-02-13,false,8,10,9\n\"\"\".lstrip()\n\nclass TestNoTimeGrainWithDimension:\n\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"metric_on_derived_metric__expected.csv\": all_time_dimension_metric__expected_csv,\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_sum_metric.yml\": base_sum_metric_yml,\n            \"metric_on_derived_metric.yml\": metric_on_derived_metric_yml,\n            \"fact_orders.sql\": fact_orders_sql,\n            \"metric_on_derived_metric.sql\": all_time_dimension_metric_sql\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "bd1320bb6d3316cc65128a7c25e2e3ca", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_derived.py"}, "dbt_packages/metrics/tests/functional/calculation_methods/test_average.py": {"contents": "from struct import pack\nimport os\nimport pytest\nfrom dbt.tests.util import run_dbt\n\n# our file contents\nfrom tests.functional.fixtures import (\n    fact_orders_source_csv,\n    fact_orders_sql,\n    fact_orders_yml,\n    packages_yml\n)\n\n# models/base_average_metric.sql\nbase_average_metric_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_average_metric'), \n    grain='month'\n    )\n}}\n\"\"\"\n\n# models/base_average_metric.yml\nbase_average_metric_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_average_metric\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_average_metric__expected')\nmetrics:\n  - name: base_average_metric\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    timestamp: order_date\n    time_grains: [day, week, month]\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_average_metric__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    base_average_metric__expected_csv = \"\"\"\ndate_month,base_average_metric\n2022-01-01,1.000000\n2022-02-01,1.333333\n\"\"\".lstrip()\nelse: \n    base_average_metric__expected_csv = \"\"\"\ndate_month,base_average_metric\n2022-01-01,1.00000000000000000000\n2022-02-01,1.3333333333333333\n\"\"\".lstrip()\n\n# seeds/base_average_metric___expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    base_average_metric__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: base_average_metric__expected\n    config:\n      column_types:\n        date_month: date\n        base_average_metric: FLOAT64\n\"\"\".lstrip()\nelse: \n    base_average_metric__expected_yml = \"\"\"\"\"\"\n\nclass TestBaseAverageMetric:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_average_metric__expected.csv\": base_average_metric__expected_csv,\n            \"base_average_metric__expected.yml\": base_average_metric__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_average_metric.sql\": base_average_metric_sql,\n            \"base_average_metric.yml\": base_average_metric_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]\n\n# models/base_average_metric_no_time_grain.sql\nbase_average_metric_no_time_grain_sql = \"\"\"\nselect *\nfrom \n{{ metrics.calculate(metric('base_average_metric_no_time_grain'))\n}}\n\"\"\"\n\n# models/base_average_metric_no_time_grain.yml\nbase_average_metric_no_time_grain_yml = \"\"\"\nversion: 2 \nmodels:\n  - name: base_average_metric_no_time_grain\n    tests: \n      - metrics.metric_equality:\n          compare_model: ref('base_average_metric_no_time_grain__expected')\nmetrics:\n  - name: base_average_metric_no_time_grain\n    model: ref('fact_orders')\n    label: Total Discount ($)\n    calculation_method: average\n    expression: discount_total\n    dimensions:\n      - had_discount\n      - order_country\n\"\"\"\n\n# seeds/base_average_metric_no_time_grain__expected.csv\nif os.getenv('dbt_target') == 'snowflake':\n    base_average_metric_no_time_grain__expected_csv = \"\"\"\nbase_average_metric_no_time_grain\n1.1\n\"\"\".lstrip()\nelse: \n    base_average_metric_no_time_grain__expected_csv = \"\"\"\nbase_average_metric_no_time_grain\n1.1\n\"\"\".lstrip()\n\n# seeds/base_average_metric_no_time_grain___expected.yml\nif os.getenv('dbt_target') == 'bigquery':\n    base_average_metric_no_time_grain__expected_yml = \"\"\"\nversion: 2\nseeds:\n  - name: base_average_metric_no_time_grain__expected\n    config:\n      column_types:\n        base_average_metric_no_time_grain: FLOAT64\n\"\"\".lstrip()\nelse: \n    base_average_metric_no_time_grain__expected_yml = \"\"\"\"\"\"\n\nclass TestBaseAverageNoTimeGrainMetric:\n    # configuration in dbt_project.yml\n    @pytest.fixture(scope=\"class\")\n    def project_config_update(self):\n        return {\n          \"name\": \"example\",\n          \"models\": {\"+materialized\": \"table\"}\n        }\n\n    # install current repo as package\n    @pytest.fixture(scope=\"class\")\n    def packages(self):\n        return {\n            \"packages\": [\n                {\"local\": os.getcwd()}\n                ]\n        }\n\n\n    # everything that goes in the \"seeds\" directory\n    @pytest.fixture(scope=\"class\")\n    def seeds(self):\n        return {\n            \"fact_orders_source.csv\": fact_orders_source_csv,\n            \"base_average_metric_no_time_grain__expected.csv\": base_average_metric_no_time_grain__expected_csv,\n            \"base_average_metric_no_time_grain__expected.yml\": base_average_metric_no_time_grain__expected_yml\n        }\n\n    # everything that goes in the \"models\" directory\n    @pytest.fixture(scope=\"class\")\n    def models(self):\n        return {\n            \"fact_orders.sql\": fact_orders_sql,\n            \"fact_orders.yml\": fact_orders_yml,\n            \"base_average_metric_no_time_grain.sql\": base_average_metric_no_time_grain_sql,\n            \"base_average_metric_no_time_grain.yml\": base_average_metric_no_time_grain_yml\n        }\n\n    def test_build_completion(self,project,):\n        # running deps to install package\n        results = run_dbt([\"deps\"])\n\n        # seed seeds\n        results = run_dbt([\"seed\"])\n        assert len(results) == 2\n\n        # initial run\n        results = run_dbt([\"run\"])\n        assert len(results) == 3\n\n        # test tests\n        results = run_dbt([\"test\"]) # expect passing test\n        assert len(results) == 1\n\n        # # # validate that the results include pass\n        result_statuses = sorted(r.status for r in results)\n        assert result_statuses == [\"pass\"]", "hash": "9869dfa56bc09751b17bba847b2e6e5b", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/tests/functional/calculation_methods/test_average.py"}, "dbt_packages/metrics/macros/develop.sql": {"contents": "{%- macro develop(develop_yml, metric_list, grain=none, dimensions=[], secondary_calculations=[], start_date=none, end_date=none, where=none, date_alias=none) -%}\n    {{ return(adapter.dispatch('develop', 'metrics')(develop_yml, metric_list, grain, dimensions, secondary_calculations, start_date, end_date, where, date_alias)) }}\n{%- endmacro -%}\n\n\n{% macro default__develop(develop_yml, metric_list, grain=none, dimensions=[], secondary_calculations=[], start_date=none, end_date=none, where=none, date_alias=none) -%}\n    {#- Need this here, since the actual ref is nested within loops/conditions: -#}\n    -- depends on: {{ ref(var('dbt_metrics_calendar_model', 'dbt_metrics_default_calendar')) }}\n\n    {% if not execute -%}\n        {%- do return(\"not execute\") -%}\n    {%- endif %}\n\n    {%- if metric_list is string -%}\n        {%- set metric_list = [metric_list] -%}\n    {%- endif -%}\n\n    {# For the sake of consistency with metrics definition and the ability to easily\n    reference the metric object, we are creating a metrics_dictionary for set of metrics\n    included in the provided yml. This is used to construct the metric tree #}\n    {%- set develop_yml = fromyaml(develop_yml) -%}\n\n    {% set develop_dictionary = {} %}\n    {% for metric_definition in develop_yml.metrics %}\n        {% do develop_dictionary.update({metric_definition.name:{}}) %}\n        {% do develop_dictionary.update({metric_definition.name:metric_definition}) %}\n    {% endfor %}\n    {% set develop_yml = develop_dictionary %}\n\n    {# ############\n    VALIDATION OF PROVIDED YML - Gotta make sure the metric looks good!\n    ############ #}\n\n    {%- do metrics.validate_develop_metrics(metric_list=metric_list, develop_yml=develop_yml) -%}\n\n    {# ############\n    VARIABLE SETTING - Creating the faux metric tree and faux metric list. The faux fur of 2022\n    ############ #}\n\n    {% set metric_tree = metrics.get_faux_metric_tree(metric_list=metric_list, develop_yml=develop_yml) %}\n\n    {% set metrics_dictionary = metrics.get_metrics_dictionary(metric_tree=metric_tree, develop_yml=develop_yml) %}\n\n    {# ############\n    SECONDARY VALIDATION - Gotta make sure everything else is good!\n    ############ #}\n\n    {%- do metrics.validate_timestamp(grain=grain, metric_tree=metric_tree, metrics_dictionary=metrics_dictionary, dimensions=dimensions) -%}\n\n    {%- do metrics.validate_grain(grain=grain, metric_tree=metric_tree, metrics_dictionary=metrics_dictionary, secondary_calculations=secondary_calculations) -%}\n    \n    {%- do metrics.validate_dimension_list(dimensions=dimensions, metric_tree=metric_tree, metrics_dictionary=metrics_dictionary) -%} \n\n    {%- do metrics.validate_metric_config(metrics_dictionary=metrics_dictionary) -%}\n\n    {%- do metrics.validate_secondary_calculations(metric_tree=metric_tree, metrics_dictionary=metrics_dictionary, grain=grain, secondary_calculations=secondary_calculations) -%} \n\n    {%- do metrics.validate_where(where=where) -%} \n\n    {# ############\n    SQL GENERATION - Lets build that SQL!\n    ############ -#}\n\n    {%- set sql = metrics.get_metric_sql(\n        metrics_dictionary=metrics_dictionary,\n        grain=grain,\n        dimensions=dimensions,\n        secondary_calculations=secondary_calculations,\n        start_date=start_date,\n        end_date=end_date,\n        where=where,\n        date_alias=date_alias,\n        metric_tree=metric_tree\n        ) %}\n    ({{ sql }}) metric_subq\n\n{%- endmacro %}\n", "hash": "9773ca23e63c93ea055523f4b1b4d838", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/develop.sql"}, "dbt_packages/metrics/macros/README.md": {"contents": "### Understanding metrics macros\nIf you're interested in writing your own metrics macro or are curious about how the sql is generated for your metrics query, you've come to the right place! This readme will contain information on the flow of the most important macros, the inputs needed to make them work, and short explanations of how they all work!\n\n#### The Flow \nAs of version v0.3.2, significant work has been done on breaking out logic into discrete and logical components to ensure that each macro always performs the same behavior, regardless of how or where it is called. To wit, the first metrics always called are either:\n\n- **calculate**: this is the most frequently used macro by end-users and is documented well in the overarching README. \n- **develop**:  this macro allows users to provide metric yml and test/simulate what the end result would look like if said metric were included in their project\n\nOnce these macros are called, they both go through two logical steps albeit in slightly different ways.\n\n- validation: Both macros validate that their inputs are correct and match what we are expecting to see. Additionally they also validate the inputs against the existing metrics object in the manifest to ensure that dimensions are correct, time grains are permitted, etc etc. \n- variable creation: Both macros also create 2 variables that are required in downstream processes. The `metric_tree` and the `metrics_dictionary`.\n\n**Metric Tree**: This object is a dictionary that contains 5 key value pairs:\n- full_set: this value is a list of **all** metric names that are required to construct the sql. It includes all parent metrics and experssion metrics.\n- base_set: this value is a list of metric names that are provided to the macro. \n- parent_set: this value is a list of parent metric names, which are defined as all first level (non-derived) metrics upon which downstream metrics are dependent upon.\n- derived_set: this value is a list of derived metric names\n- ordered_derived_set: this value is a list of dictionaries that contains the derived metrics **and** their depth from the parent. This is used to construct the nested CTEs in the sql gen.\n\n**Metrics Dictionary**: This object is a dictionary that contains all of the attributes for each metric in the full_set. It was implemented in v0.3.2 to support the same input provided to `get_metric_sql` from both develop and calculate. It must contain the:\n- Metric name\n- Metric calculation method\n- Metric expression\n- Metric timestamp\n- Metric time grains\n- Metric dimensions\n- Metric filters\n- (If not derived) Metric model name\n- (If not derived) Metric model object", "hash": "e58d87ffb067678d1dcd755a8e9ab12a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/README.md"}, "dbt_packages/metrics/macros/calculate.sql": {"contents": "{% macro calculate(metric_list, grain=none, dimensions=[], secondary_calculations=[], start_date=none, end_date=none, where=none, date_alias=none) %}\n    {{ return(adapter.dispatch('calculate', 'metrics')(metric_list, grain, dimensions, secondary_calculations, start_date, end_date, where, date_alias)) }}\n{% endmacro %}\n\n\n{% macro default__calculate(metric_list, grain=none, dimensions=[], secondary_calculations=[], start_date=none, end_date=none, where=none, date_alias=none) %}\n    {#- Need this here, since the actual ref is nested within loops/conditions: -#}\n    -- depends on: {{ ref(var('dbt_metrics_calendar_model', 'dbt_metrics_default_calendar')) }}\n    \n    {#- ############\n    VARIABLE SETTING - Creating the metric tree and making sure metric list is a list!\n    ############ -#}\n\n    {%- if metric_list is not iterable -%}\n        {%- set metric_list = [metric_list] -%}\n    {%- endif -%}\n\n    {%- set metric_tree = metrics.get_metric_tree(metric_list=metric_list) -%}\n\n    {#- Here we are creating the metrics dictionary which contains all of the metric information needed for sql gen. -#}\n    {%- set metrics_dictionary = metrics.get_metrics_dictionary(metric_tree=metric_tree) -%}\n\n    {#- ############\n    VALIDATION - Make sure everything is good!\n    ############ -#}\n\n    {%- if not execute -%}\n        {%- do return(\"Did not execute\") -%}\n    {%- endif -%}\n\n    {%- if not metric_list -%}\n        {%- do exceptions.raise_compiler_error(\"No metric or metrics provided\") -%}\n    {%- endif -%}\n\n    {%- do metrics.validate_timestamp(grain=grain, metric_tree=metric_tree, metrics_dictionary=metrics_dictionary, dimensions=dimensions) -%}\n\n    {%- do metrics.validate_grain(grain=grain, metric_tree=metric_tree, metrics_dictionary=metrics_dictionary, secondary_calculations=secondary_calculations) -%}\n\n    {%- do metrics.validate_derived_metrics(metric_tree=metric_tree) -%}\n\n    {%- do metrics.validate_dimension_list(dimensions=dimensions, metric_tree=metric_tree, metrics_dictionary=metrics_dictionary) -%} \n\n    {%- do metrics.validate_metric_config(metrics_dictionary=metrics_dictionary) -%} \n\n    {%- do metrics.validate_where(where=where) -%} \n\n    {%- do metrics.validate_secondary_calculations(metric_tree=metric_tree, metrics_dictionary=metrics_dictionary, grain=grain, secondary_calculations=secondary_calculations) -%} \n\n    {#- ############\n    SQL GENERATION - Lets build that SQL!\n    ############ -#}\n\n    {%- set sql = metrics.get_metric_sql(\n        metrics_dictionary=metrics_dictionary,\n        grain=grain,\n        dimensions=dimensions,\n        secondary_calculations=secondary_calculations,\n        start_date=start_date,\n        end_date=end_date,\n        where=where,\n        date_alias=date_alias,\n        metric_tree=metric_tree\n    ) %}\n\n({{ sql }}) metric_subq \n\n{%- endmacro -%}\n", "hash": "36fa69b97241947c27582e1ff9d1504d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/calculate.sql"}, "dbt_packages/metrics/macros/get_metric_sql.sql": {"contents": "{%- macro get_metric_sql(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, where, date_alias, metric_tree) %}\n\n{#- ############\nMost validation occurs in calculate and develop - please reference there for validation\n############ -#}\n\n{#- ############\nLETS SET SOME VARIABLES!\n############ -#}\n\n{#- We have to break out calendar dimensions as their own list of acceptable dimensions. \nThis is because of the date-spining. If we don't do this, it creates impossible combinations\nof calendar dimension + base dimensions -#}\n{%- set calendar_dimensions = metrics.get_calendar_dimensions(dimensions) -%}\n\n{#- Additionally, we also have to restrict the dimensions coming in from the macro to \nno longer include those we've designated as calendar dimensions. That way they \nare correctly handled by the spining. We override the dimensions variable for \ncleanliness -#}\n{%- set non_calendar_dimensions = metrics.get_non_calendar_dimension_list(dimensions, var('custom_calendar_dimension_list',[])) -%}\n\n{#- Finally we set the relevant periods, which is a list of all time grains that need to be contained\nwithin the final dataset in order to accomplish base + secondary calc functionality. -#}\n{%- set relevant_periods = metrics.get_relevent_periods(grain, secondary_calculations) -%}\n\n{#- Setting a variable to denote if the user has provided any dimensions -#}\n{%- if non_calendar_dimensions | length > 0 -%}\n    {%- set dimensions_provided = true -%}\n{%- else -%}\n    {%- set dimensions_provided = false -%}\n{%- endif -%}\n\n{#- Here we set the calendar table as a variable, which ensures the default overwritten if they include\na custom calendar -#}\n{%- set calendar_tbl = ref(var('dbt_metrics_calendar_model', \"dbt_metrics_default_calendar\")) -%}\n\n{#- Here we get the total dimension count for grouping -#}\n{%- set total_dimension_count = metrics.get_total_dimension_count(grain, dimensions, calendar_dimensions, relevant_periods) -%}\n\n{#- Here we are creating the metric grouping that we use to determine if metrics can be pulled from the same base query -#}\n{%- set models_grouping = metrics.get_models_grouping(metric_tree=metric_tree,metrics_dictionary=metrics_dictionary) -%}\n{#- ############\nLET THE COMPOSITION BEGIN!\n############ -#}\n\n{#- First we add the calendar table - we only need to do this once no matter how many\nmetrics there are -#}\n{{ metrics.gen_calendar_cte(\n    calendar_tbl=calendar_tbl,\n    start_date=start_date, \n    end_date=end_date) \n    }}\n{#- Next we check if it is a composite metric or single metric by checking the length of the list -#}\n{#- This filter forms the basis of how we construct the SQL -#}\n{#- If composite, we begin by looping through each of the metric names that make\nup the composite metric. -#}\n\n{%- for group_name, group_values in models_grouping.items() -%}\n\n    {{ metrics.build_metric_sql(\n        metrics_dictionary=metrics_dictionary, \n        grain=grain, \n        dimensions=non_calendar_dimensions, \n        secondary_calculations=secondary_calculations, \n        start_date=start_date, \n        end_date=end_date,\n        relevant_periods=relevant_periods,\n        calendar_dimensions=calendar_dimensions,\n        dimensions_provided=dimensions_provided,\n        total_dimension_count=total_dimension_count,\n        group_name=group_name,\n        group_values=group_values\n        ) \n    }}\n\n{%- endfor -%}\n\n{%- if models_grouping| length > 1 or metric_tree['derived_set'] | length > 0 -%}\n\n    {{ metrics.gen_joined_metrics_cte(\n        metric_tree=metric_tree,\n        metrics_dictionary=metrics_dictionary,\n        models_grouping=models_grouping,\n        grain=grain, \n        dimensions=non_calendar_dimensions, \n        calendar_dimensions=calendar_dimensions, \n        secondary_calculations=secondary_calculations, \n        relevant_periods=relevant_periods,\n        total_dimension_count=total_dimension_count ) \n    }}\n\n{%- endif -%}\n\n{{ metrics.gen_final_cte(\n    metric_tree=metric_tree,\n    metrics_dictionary=metrics_dictionary,\n    models_grouping=models_grouping,\n    grain=grain, \n    dimensions=non_calendar_dimensions, \n    calendar_dimensions=calendar_dimensions, \n    relevant_periods=relevant_periods,\n    secondary_calculations=secondary_calculations,\n    where=where,\n    date_alias=date_alias) \n    }} \n\n{%- endmacro %}", "hash": "f96b234c5f64f69e5311dde2ee2166c2", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/get_metric_sql.sql"}, "dbt_packages/metrics/macros/misc/metrics__date_spine.sql": {"contents": "{% macro metric_get_intervals_between(start_date, end_date, datepart) -%}\n    {{ return(adapter.dispatch('metric_get_intervals_between', 'metrics')(start_date, end_date, datepart)) }}\n{%- endmacro %}\n\n{% macro default__metric_get_intervals_between(start_date, end_date, datepart) -%}\n    {%- call statement('metric_get_intervals_between', fetch_result=True) %}\n\n        select {{ datediff(start_date, end_date, datepart) }}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('metric_get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n{% macro metric_date_spine(datepart, start_date, end_date) %}\n    {{ return(adapter.dispatch('metric_date_spine', 'metrics')(datepart, start_date, end_date)) }}\n{%- endmacro %}\n\n{% macro default__metric_date_spine(datepart, start_date, end_date) %}\n\n\n{# call as follows:\n\nmetric_date_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n) #}\n\n\nwith rawdata as (\n\n    {{metrics.metric_generate_series(\n        metrics.metric_get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}\n\n\n{% macro metric_get_powers_of_two(upper_bound) %}\n    {{ return(adapter.dispatch('metric_get_powers_of_two', 'metrics')(upper_bound)) }}\n{% endmacro %}\n\n{% macro default__metric_get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}\n\n\n{% macro metric_generate_series(upper_bound) %}\n    {{ return(adapter.dispatch('metric_generate_series', 'metrics')(upper_bound)) }}\n{% endmacro %}\n\n{% macro default__metric_generate_series(upper_bound) %}\n\n    {% set n = metrics.metric_get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * power(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "hash": "d1baeccc9f8eefe2d4f1c5622f24c89f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/misc/metrics__date_spine.sql"}, "dbt_packages/metrics/macros/misc/metrics__equality.sql": {"contents": "{% test metric_equality(model, compare_model, compare_columns=none) %}\n  {{ return(adapter.dispatch('test_metric_equality', 'metrics')(model, compare_model, compare_columns)) }}\n{% endtest %}\n\n{% macro default__test_metric_equality(model, compare_model, compare_columns=none) %}\n\n{% set set_diff %}\n    count(*) + coalesce(abs(\n        sum(case when which_diff = 'a_minus_b' then 1 else 0 end) -\n        sum(case when which_diff = 'b_minus_a' then 1 else 0 end)\n    ), 0)\n{% endset %}\n\n{#-- Needs to be set at parse time, before we return '' below --#}\n{{ config(fail_calc = set_diff) }}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do metrics._metric_is_relation(model, 'test_metric_equality') -%}\n\n{#-\nIf the compare_cols arg is provided, we can run this test without querying the\ninformation schema\u00a0\u2014 this allows the model to be an ephemeral model\n-#}\n\n{%- if not compare_columns -%}\n    {%- do metrics._metric_is_ephemeral(model, 'test_metric_equality') -%}\n    {%- set compare_columns = adapter.get_columns_in_relation(model) | map(attribute='quoted') -%}\n{%- endif -%}\n\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select 'a_minus_b' as which_diff, a_minus_b.* from a_minus_b\n    union all\n    select 'b_minus_a' as which_diff, b_minus_a.* from b_minus_a\n\n)\n\nselect * from unioned\n\n{% endmacro %}\n\n\n{% macro _metric_is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}\n\n{% macro _metric_is_ephemeral(obj, macro) %}\n    {%- if obj.is_cte -%}\n        {% set ephemeral_prefix = api.Relation.add_ephemeral_prefix('') %}\n        {% if obj.name.startswith(ephemeral_prefix) %}\n            {% set model_name = obj.name[(ephemeral_prefix|length):] %}\n        {% else %}\n            {% set model_name = obj.name %}\n        {%- endif -%}\n        {% set error_message %}\nThe `{{ macro }}` macro cannot be used with ephemeral models, as it relies on the information schema.\n\n`{{ model_name }}` is an ephemeral model. Consider making it a view or table instead.\n        {% endset %}\n        {%- do exceptions.raise_compiler_error(error_message) -%}\n    {%- endif -%}\n{% endmacro %}", "hash": "08ad483fb39966d2d7f8d8ddbb2a2dd7", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/misc/metrics__equality.sql"}, "dbt_packages/metrics/macros/graph_parsing/get_metric_relation.sql": {"contents": "{% macro get_metric_relation(ref_name) %}\n    \n    {% if execute %}\n        {% set relation = metric(ref_name)%}\n        {% do return(relation) %}\n    {% else %}\n        {% do return(api.Relation.create()) %}\n    {% endif %} \n{% endmacro %}", "hash": "2a92e23ce7dca3fc916eac0f6d139a5e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/graph_parsing/get_metric_relation.sql"}, "dbt_packages/metrics/macros/graph_parsing/get_model_relation.sql": {"contents": "{% macro get_model_relation(ref_name, metric_name) %}\n    {% if execute %}\n        {% set model_ref_node = graph.nodes.values() | selectattr('name', 'equalto', ref_name) | first %}\n        {% if model_ref_node | length == 0 %}\n            {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric_name ~ \" is referencing the model \" ~ ref_name ~ \", which does not exist.\") %}\n        {% endif %}\n\n        {% set relation = api.Relation.create(\n            database = model_ref_node.database,\n            schema = model_ref_node.schema,\n            identifier = model_ref_node.alias\n        )\n        %}\n\n        {% do return(relation) %}\n\n    {% else %}\n        {% do return(api.Relation.create()) %}\n    {% endif %}\n\n{% endmacro %}", "hash": "95e8669773943b55a1381b3ba69cfef5", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/graph_parsing/get_model_relation.sql"}, "dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_rolling.sql": {"contents": "{%- macro default__secondary_calculation_rolling(metric_name, grain, dimensions, calc_config) %}\n    {%- set calc_sql -%}\n    {{ adapter.dispatch('gen_primary_metric_aggregate', 'metrics')(calc_config.aggregate, metric_name) }} over (\n            {% if dimensions -%}\n            partition by {{ dimensions | join(\", \") }} \n            {%- endif %}\n            order by date_{{grain}}\n            {%- if calc_config.interval %}\n            rows between {{ calc_config.interval - 1 }} preceding and current row\n            {%- else %}\n            rows between unbounded preceding and current row\n            {%- endif %}\n        )\n    {%- endset %}\n    {% do return (calc_sql) %}\n{%- endmacro %}", "hash": "98a5c7880956e7f13f731e78f45d9828", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_rolling.sql"}, "dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_period_to_date.sql": {"contents": "{% macro default__secondary_calculation_period_to_date(metric_name, grain, dimensions, calc_config) %}\n    {%- set calc_sql -%}\n        {{- adapter.dispatch('gen_primary_metric_aggregate', 'metrics')(calc_config.aggregate, metric_name) -}} over (\n            partition by date_{{ calc_config.period }}{% if dimensions -%}, {{ dimensions | join(\", \") }}{%- endif %}\n            order by date_{{grain}}\n            rows between unbounded preceding and current row\n        )\n    {%- endset %}\n    {%- do return (calc_sql) %}\n{% endmacro %}", "hash": "4b6aac96277ec1b3cd5c669ebdbcca5b", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_period_to_date.sql"}, "dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_period_over_period.sql": {"contents": "{%- macro default__secondary_calculation_period_over_period(metric_name, grain, dimensions, calc_config, metric_config) -%}\n    {%- set calc_sql %}\n            lag({{ metric_name }}, {{ calc_config.interval }}) over (\n                {%- if dimensions %}\n                    partition by {{ dimensions | join(\", \") }} \n                {%- endif %}\n                order by date_{{grain}}\n            )\n    {%- endset-%}\n    \n    {%- if calc_config.comparison_strategy == 'difference' -%}\n        {% do return (adapter.dispatch('metric_comparison_strategy_difference', 'metrics')(metric_name, calc_sql, metric_config)) %}\n    \n    {%- elif calc_config.comparison_strategy == 'ratio' -%}\n        {% do return (adapter.dispatch('metric_comparison_strategy_ratio', 'metrics')(metric_name, calc_sql, metric_config)) %}\n    \n    {%- else -%}\n        {% do exceptions.raise_compiler_error(\"Bad comparison_strategy for period_over_period: \" ~ calc_config.comparison_strategy ~ \". calc_config: \" ~ calc_config) %}\n    {%- endif -%}\n\n{% endmacro %}\n\n{% macro default__metric_comparison_strategy_difference(metric_name, calc_sql, metric_config) -%}\n    {%- if not metric_config.get(\"treat_null_values_as_zero\", True) %}\n        {{ metric_name }} - {{ calc_sql }}\n    {%- else -%}\n        coalesce({{ metric_name }}, 0) - coalesce({{ calc_sql }}, 0)\n    {%- endif %}\n{%- endmacro -%}\n\n{% macro default__metric_comparison_strategy_ratio(metric_name, calc_sql, metric_config) -%}\n\n    {%- if not metric_config.get(\"treat_null_values_as_zero\", True) %}\n        cast({{ metric_name }} as {{ type_float() }}) / nullif({{ calc_sql }}, 0)\n    {%- else %}\n            coalesce(cast({{ metric_name }} as {{ type_float() }}) / nullif({{ calc_sql }}, 0) , 0)\n    {%- endif %}\n    \n{%- endmacro %}\n", "hash": "2736ce941cd1c2c24b8f5e2e870ec22b", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_period_over_period.sql"}, "dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_prior.sql": {"contents": "{%- macro default__secondary_calculation_prior(metric_name, grain, dimensions, calc_config, metric_config) -%}\n    \n    {%- set calc_sql -%}\n        lag({{ metric_name }}, {{ calc_config.interval }}) over (\n            {% if dimensions -%}\n            partition by {{ dimensions | join(\", \") }} \n            {% endif -%}\n            order by date_{{grain}}\n        )\n    {%- endset-%}\n    {{ calc_sql }}\n\n{%- endmacro %}\n", "hash": "12dbadff07b1cc1e52f8ecc1c7877d6a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations/secondary_calculation_prior.sql"}, "dbt_packages/metrics/macros/secondary_calculations/generate_secondary_calculation_alias.sql": {"contents": "{% macro generate_secondary_calculation_alias(metric_name, calc_config, grain, is_multiple_metrics) %}\n\n    {{ return(adapter.dispatch('generate_secondary_calculation_alias', 'metrics')(metric_name, calc_config, grain, is_multiple_metrics)) }}\n\n{% endmacro %}\n\n{% macro default__generate_secondary_calculation_alias(metric_name, calc_config, grain, is_multiple_metrics) %}\n    {%- if calc_config.alias -%}\n        {%- if is_multiple_metrics -%}\n            {%- do return(metric_name ~ \"_\" ~ calc_config.alias) -%}\n        {%- else -%}\n            {% do return(calc_config.alias) %}\n        {%- endif -%}\n    {%- endif -%}\n    \n    {%- set calc_type = calc_config.calculation -%}\n    {%- if calc_type == 'period_over_period' -%}\n        {%- if is_multiple_metrics -%}\n            {%- do return(metric_name ~ \"_\" ~ calc_config.comparison_strategy ~ \"_to_\" ~ calc_config.interval ~ \"_\" ~ grain ~ \"_ago\") %}\n        {%- else -%}\n            {%- do return(calc_config.comparison_strategy ~ \"_to_\" ~ calc_config.interval ~ \"_\" ~ grain ~ \"_ago\") %}\n        {%- endif -%}\n   \n    {%- elif calc_type == 'rolling' %}\n        {%- if is_multiple_metrics -%}\n            {%- if calc_config.interval -%}\n                {%- do return(metric_name ~ \"_\" ~ \"rolling_\" ~ calc_config.aggregate ~ \"_\" ~ calc_config.interval ~ \"_\" ~ grain) %}\n            {%- else -%}\n                {%- do return(metric_name ~ \"_\" ~ \"rolling_\" ~ calc_config.aggregate) %}\n            {%- endif -%}\n        {%- else -%}\n            {%- if calc_config.interval -%}\n                {%- do return(\"rolling_\" ~ calc_config.aggregate ~ \"_\" ~ calc_config.interval ~ \"_\" ~ grain) %}\n            {%- else -%}\n                {%- do return(\"rolling_\" ~ calc_config.aggregate) %}\n            {%- endif -%}\n        {%- endif -%}\n    \n    {%- elif calc_type == 'period_to_date' %}\n        {% if is_multiple_metrics %}\n            {%- do return(metric_name ~ \"_\" ~ calc_config.aggregate ~ \"_for_\" ~ calc_config.period) %}\n        {% else %}\n            {%- do return(calc_config.aggregate ~ \"_for_\" ~ calc_config.period) %}\n        {% endif %}\n        \n    {%- elif calc_type == 'prior' %}\n        {% if is_multiple_metrics %}\n            {%- do return(metric_name ~ \"_\" ~ calc_config.interval ~ \"_\" ~ grain ~ \"s_prior\") %}\n        {% else %}\n            {%- do return(calc_config.interval ~ \"_\" ~ grain ~ \"s_prior\") %}\n        {% endif %}\n\n    {%- else %}\n        {%- do exceptions.raise_compiler_error(\"Can't generate alias for unknown secondary calculation: \" ~ calc_type ~ \". calc_config: \" ~ calc_config) %}  \n    {%- endif %}\n\n    {{ calc_sql }}\n{% endmacro %}", "hash": "fc23d207148aa5750bb8e9425f0c4922", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations/generate_secondary_calculation_alias.sql"}, "dbt_packages/metrics/macros/secondary_calculations/perform_secondary_calculation.sql": {"contents": "{%- macro perform_secondary_calculation(metric_name, grain, dimensions, calendar_dimensions, calc_config, metric_config) -%}\n    {{ return(adapter.dispatch('perform_secondary_calculation', 'metrics')(metric_name, grain, dimensions, calendar_dimensions, calc_config, metric_config)) }}\n{%- endmacro -%}\n\n{% macro default__perform_secondary_calculation(metric_name, grain, dimensions, calendar_dimensions, calc_config, metric_config) %}\n    {%- set combined_dimensions = dimensions+calendar_dimensions -%}\n    {%- set calc_type = calc_config.calculation -%}\n    {%- set calc_sql = '' -%}\n    \n    {%- if calc_type == 'period_over_period' -%}\n        {%- set calc_sql = adapter.dispatch('secondary_calculation_period_over_period', 'metrics')(metric_name, grain, combined_dimensions, calc_config, metric_config) -%}\n    {%- elif calc_type == 'rolling' -%}\n        {%- set calc_sql = adapter.dispatch('secondary_calculation_rolling', 'metrics')(metric_name, grain, combined_dimensions, calc_config) -%}\n    {%- elif calc_type == 'period_to_date' -%}\n        {%- set calc_sql = adapter.dispatch('secondary_calculation_period_to_date', 'metrics')(metric_name, grain, combined_dimensions, calc_config) -%}\n    {%- elif calc_type == 'prior' -%}\n        {%- set calc_sql = adapter.dispatch('secondary_calculation_prior', 'metrics')(metric_name, grain, combined_dimensions, calc_config) -%}\n    {%- else -%}\n        {%- do exceptions.raise_compiler_error(\"Unknown secondary calculation: \" ~ calc_type ~ \". calc_config: \" ~ calc_config) -%}  \n    {%- endif -%}\n    {{ calc_sql }} as {{ metrics.generate_secondary_calculation_alias(metric_name, calc_config, grain, true) }}\n{%- endmacro -%}", "hash": "ffcfc7f7d9bce2cb096dff5493c70de3", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations/perform_secondary_calculation.sql"}, "dbt_packages/metrics/macros/variables/get_model_group.sql": {"contents": "{%- macro get_model_group(models_grouping, metric_model, metric_model_name, metric_name, metric_timestamp=none, metric_filters=none, metric_window=none) -%}\n\n{#- \nThis macro is called from get_models_grouping in order to calculate\nthe group for each model based on the inputs. This allows us to reduce\nthe complexity of the aforementioned macro because there is a factorial \ncombination of possibilities based on the inputs, minus some combinations\nthat are invalid.\n\nBy factorial, we mean that the three potential inputs can be combined in \na multitude of different ways in order to calculate the group. The potential \ncombinations are:\n    - timestamp\n    - filters\n    - timestamp + window\n    - timestamp + filters\n    - timestamp + filters + window\n -#}\n\n    {% set metric_model_list = [metric_model_name] %}\n\n    {% if metric_timestamp %}\n        {% set timestamp_list = [\n            metric_timestamp | lower\n        ]%}\n    {% else %}\n        {% set timestamp_list = [] %}\n    {% endif %}\n\n    {% if metric_window %}\n        {% set window_list = [\n                metric_window.count | lower\n                ,metric_window.period | lower\n            ]%}\n    {% else %}\n        {% set window_list = [] %}\n    {% endif %}\n\n    {% if metric_filters %}\n        {% set filter_list = [] %}\n        {% for filter in metric_filters %}\n            {% do filter_list.append(filter.field | lower)%}\n            {% do filter_list.append(filter.operator | lower)%}\n            {% do filter_list.append(filter.value | lower)%}\n        {% endfor %}\n    {% else %}\n        {% set filter_list = [] %}\n    {% endif %}\n\n    {% set group_list = (metric_model_list + timestamp_list + window_list + filter_list) | sort %}\n    {% set group_name = 'model_' ~ local_md5(group_list | join('_')) %}\n\n    {% if not models_grouping[group_name] %}\n        {% do models_grouping.update({group_name:{}})%}\n        {% do models_grouping[group_name].update({'metric_names':{}})%}\n        {% do models_grouping[group_name].update({'metric_model':metric_model})%}\n        {% do models_grouping[group_name].update({'timestamp':metric_timestamp})%}\n        {% do models_grouping[group_name].update({'filters':metric_filters})%}\n        {% do models_grouping[group_name].update({'window':metric_window})%}\n        {% do models_grouping[group_name].update({'metric_names':[metric_name]})%}\n    {% else %}\n        {% set metric_names = models_grouping[group_name]['metric_names'] %}\n        {% do metric_names.append(metric_name)%}\n        {% do models_grouping[group_name].update({'metric_names':metric_names})%}\n    {% endif %}\n\n    {% do return(metrics_grouping) %}\n\n{%- endmacro -%}", "hash": "eb11059f31f472c2a7516333b763a8d6", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_model_group.sql"}, "dbt_packages/metrics/macros/variables/get_faux_metric_tree.sql": {"contents": "{% macro get_faux_metric_tree(metric_list,develop_yml)%}\n\n    {%- set metric_tree = {'full_set':[]} %}\n    {%- do metric_tree.update({'parent_set':[]}) -%}\n    {%- do metric_tree.update({'derived_set':[]}) -%}\n    {%- do metric_tree.update({'base_set':metric_list}) -%}\n    {%- do metric_tree.update({'ordered_derived_set':{}}) -%}\n\n    {% for metric_name in metric_list %}\n        {% set metric_definition = develop_yml[metric_name]%}\n        {%- set metric_tree = metrics.update_faux_metric_tree(metric_definition, metric_tree, develop_yml) -%}\n    {% endfor %}\n\n    {%- do metric_tree.update({'full_set':set(metric_tree['full_set'])}) -%}\n    {%- do metric_tree.update({'parent_set':set(metric_tree['parent_set'])}) -%}\n    {%- do metric_tree.update({'derived_set':set(metric_tree['derived_set'])}) -%}\n\n    {% for metric_name in metric_tree['parent_set']|unique%}\n        {%- do metric_tree['ordered_derived_set'].pop(metric_name) -%}\n    {% endfor %}\n\n    {# This section overrides the derived set by ordering the metrics on their depth so they \n    can be correctly referenced in the downstream sql query #}\n    {% set ordered_expression_list = []%}\n    {% for item in metric_tree['ordered_derived_set']|dictsort(false, 'value') %}\n        {% if item[0] in metric_tree[\"derived_set\"]%}\n            {% do ordered_expression_list.append(item[0])%}\n        {% endif %}\n    {% endfor %}\n    {%- do metric_tree.update({'derived_set':ordered_expression_list}) -%}\n\n    {%- do return(metric_tree) -%}\n\n{% endmacro %}", "hash": "7cea50ad85982ab297add5eeceef438e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_faux_metric_tree.sql"}, "dbt_packages/metrics/macros/variables/get_metrics_dictionary.sql": {"contents": "{% macro get_metrics_dictionary(metric_tree, develop_yml = none) %}\n\n    {% set metrics_dictionary = {} %}\n\n    {% for metric_name in metric_tree.full_set %}\n        {% if develop_yml is not none %}\n            {% set metric_object = develop_yml[metric_name]%}\n        {% else %}\n            {% set metric_object = metrics.get_metric_relation(metric_name) %}\n        {% endif %}\n        {% set metric_definition = metrics.get_metric_definition(metric_object) %}\n        {% if not metric_definition.config %}\n            {% do metric_definition.update({'config':{}}) %}\n        {% endif %}\n        {% do metrics_dictionary.update({metric_name:{}})%}\n        {% do metrics_dictionary.update({metric_name:metric_definition})%}\n    {% endfor %}\n\n    {% do return(metrics_dictionary) %}\n\n{% endmacro %}", "hash": "49fc44be5d9ed43839e95331bd85af42", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_metrics_dictionary.sql"}, "dbt_packages/metrics/macros/variables/get_calendar_dimensions.sql": {"contents": "{% macro get_calendar_dimensions(dimensions) %}\n    \n    {% set approved_calendar_dimensions = var('custom_calendar_dimension_list',[]) %}\n\n    {# Here we set the calendar as either being the default provided by the package\n    or the variable provided in the project #}\n    {% set calendar_dimensions = [] %}\n    {% for dim in dimensions %}\n        {%- if dim in approved_calendar_dimensions -%}\n            {%- do calendar_dimensions.append(dim | lower) -%}\n        {%- endif -%}\n    {% endfor %}\n    {%- do return(calendar_dimensions) -%}\n\n{% endmacro %}", "hash": "c300b7df1cd7d601152a9e13a42553b2", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_calendar_dimensions.sql"}, "dbt_packages/metrics/macros/variables/get_non_calendar_dimension_list.sql": {"contents": "{% macro get_non_calendar_dimension_list(dimensions,calendar_dimensions) %}\n    \n    {% set calendar_dims = calendar_dimensions %}\n\n    {# Here we set the calendar as either being the default provided by the package\n    or the variable provided in the project #}\n    {% set dimension_list = [] %}\n    {% for dim in dimensions %}\n        {%- if dim not in calendar_dimensions -%}\n            {%- do dimension_list.append(dim | lower) -%}\n        {%- endif -%}\n    {% endfor %}\n    {%- do return(dimension_list) -%}\n\n{% endmacro %}", "hash": "c0f390706e0cc7b1cc2519255241ab4d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_non_calendar_dimension_list.sql"}, "dbt_packages/metrics/macros/variables/update_metric_tree.sql": {"contents": "{% macro update_metric_tree(metric,metric_tree,metric_count=999)%}\n    \n    {# Now we see if the node already exists in the metric tree and return that if \n    it does so that we're not creating duplicates #}\n    {%- if metric.name not in metric_tree|map(attribute=\"full_set\") -%}\n\n        {%- set full_set = metric_tree[\"full_set\"] -%}\n        {%- do full_set.append(metric.name) -%}\n        {%- do metric_tree.update({'full_set':full_set}) -%}\n\n    {%- endif -%}\n\n    {%- do metric_tree[\"ordered_derived_set\"].update({metric.name:metric_count}) -%}\n    {%- set metric_count = metric_count - 1 -%}\n\n    {# Here we create two sets, sets being the same as lists but they account for uniqueness. \n    One is the full set, which contains all of the parent metrics and the other is the leaf\n    set, which we'll use to determine the leaf, or base metrics. #}\n\n    {# We define parent nodes as being the parent nodes that begin with metric, which lets\n    us filter out model nodes #}\n    {%- set parent_metrics = metrics.get_metric_unique_id_list(metric) -%}\n\n    {# We set an if condition based on if parent nodes. If there are none, then this metric\n    is a leaf node and any recursive loop should end #}\n        {%- if parent_metrics | length > 0 -%}\n\n            {# Now we finally recurse through the nodes. We begin by filtering the overall list we\n            recurse through by limiting it to depending on metric nodes and not ALL nodes #}\n            {%- for parent_id in parent_metrics -%}\n\n                {# Then we add the parent_id of the metric to the full set. If it already existed\n                then it won't make an impact but we want to make sure it is represented #}\n                {# {%- do full_set.append(parent_id) -%} #}\n                {%- set full_set_plus = metric_tree[\"full_set\"] -%}\n                {%- if parent_id in metric_tree|map(attribute=\"full_set\") -%}\n                    {%- do full_set_plus.append(parent_id) -%}\n                {%- endif -%}\n                {%- do metric_tree.update({'full_set':full_set_plus}) -%}\n                {# The parent_id variable here is a mapping back to the provided manifest and doesn't \n                allow for string parsing. So we create this variable to use instead #}\n                {# {%- set parent_metric_name = (parent_id | string).split('.')[2] -%} #}\n\n                {# And here we re-run the current macro but fill in the parent_id so that we loop again\n                with that metric information. You may be wondering, why are you using parent_id? Doesn't \n                the DAG always go from parent to child? Normally, yes! With this, no! We're reversing the \n                DAG and going up to parents to find the leaf nodes that are really parent nodes. #}\n                {%- set new_parent = metrics.get_metric_relation(parent_id) -%}\n\n                {%- set metric_tree =  metrics.update_metric_tree(new_parent,metric_tree,metric_count) -%}\n\n            {%- endfor -%}\n        \n        {%- else -%}\n\n            {%- set parent_set_plus = metric_tree[\"parent_set\"] -%}\n            {%- if parent_id in metric_tree|map(attribute=\"full_set\") -%}\n                {%- do parent_set_plus.append(metric.name) -%}\n            {%- endif -%}\n            {%- do metric_tree.update({'parent_set':parent_set_plus}) -%}\n\n        {%- endif -%}\n\n        {%- set derived_set_plus = ( metric_tree[\"full_set\"] | reject('in',metric_tree[\"parent_set\"]) | list) -%}\n        {%- do metric_tree.update({'derived_set':derived_set_plus}) -%}\n\n    {%- do return(metric_tree) -%}\n\n{% endmacro %}", "hash": "0c72af871c1a8559aeb9ce526623765a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/update_metric_tree.sql"}, "dbt_packages/metrics/macros/variables/get_metric_tree.sql": {"contents": "{% macro get_metric_tree(metric_list)%}\n\n{# We are creating the metric tree here - this includes all the leafs (first level parents)\n, the derived metrics, and the full combination of them both #}\n\n{# This line creates the metric tree dictionary and the full_set key. \nFull Set contains ALL metrics that are referenced, which includes metrics in the macro\nAND all parent/derived metrics. #}\n{%- set metric_tree = {'full_set':[]} %}\n{# The parent set is a list of parent metrics that are NOT derived metrics. IE if \nmetric C is built off of metric A and B, A and B would be the parent metrics because they \nare both upstream of Metric C AND not derived metrics themselves. #}\n{%- do metric_tree.update({'parent_set':[]}) -%}\n{# The derived set is a list of derived metrics. This includes all derived metrics referenced\nin the macro itself OR upstream of the metrics referenced in the macro #}\n{%- do metric_tree.update({'derived_set':[]}) -%}\n{# The base set is the list of metrics that are provided into the macro #}\n{%- do metric_tree.update({'base_set':[]}) -%}\n{# The ordered derived set is the list of derived metrics that are ordered based on their\nnode depth. So if Metric C were downstream of Metric A and B, which were also derived metrics,\nMetric C would have the value of 999 (max depth) and A and B would have 998, representing that they\nare one depth upstream #}\n{%- do metric_tree.update({'ordered_derived_set':{}}) -%}\n\n{% set base_set_list = []%}\n{% for metric in metric_list %}\n    {%- do base_set_list.append(metric.name) -%}\n    {%- set metric_tree = metrics.update_metric_tree(metric ,metric_tree) -%}\n{% endfor %}\n{%- do metric_tree.update({'base_set':base_set_list}) -%}\n\n{# Now we will iterate over the metric tree and make it a unique list to account for duplicates #}\n{% set full_set = [] %}\n{% set parent_set = [] %}\n{% set derived_set = [] %}\n{% set base_set = [] %}\n\n{% for metric_name in metric_tree['full_set']|unique%}\n    {% do full_set.append(metric_name)%}\n{% endfor %}\n{%- do metric_tree.update({'full_set':full_set}) -%}\n\n{% for metric_name in metric_tree['parent_set']|unique%}\n    {% do parent_set.append(metric_name)%}\n{% endfor %}\n{%- do metric_tree.update({'parent_set':parent_set}) -%}\n\n{% for metric_name in metric_tree['derived_set']|unique%}\n    {% do derived_set.append(metric_name)%}\n{% endfor %}\n{%- do metric_tree.update({'derived_set':derived_set}) -%}\n\n{% for metric in metric_tree['parent_set']|unique%}\n    {%- do metric_tree['ordered_derived_set'].pop(metric) -%}\n{% endfor %}\n\n{# This section overrides the derived set by ordering the metrics on their depth so they \ncan be correctly referenced in the downstream sql query #}\n{% set ordered_expression_list = []%}\n{% for item in metric_tree['ordered_derived_set']|dictsort(false, 'value') %}\n    {% if item[0] in metric_tree[\"derived_set\"]%}\n        {% do ordered_expression_list.append(item[0])%}\n    {% endif %}\n{% endfor %}\n{%- do metric_tree.update({'derived_set':ordered_expression_list}) -%}\n\n{%- do return(metric_tree) -%}\n\n{% endmacro %}", "hash": "5c92b93aa4b31fbff6ca492f30aa79ff", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_metric_tree.sql"}, "dbt_packages/metrics/macros/variables/update_faux_metric_tree.sql": {"contents": "{% macro update_faux_metric_tree(metric_definition, metric_tree, develop_yml, metric_count=999)%}\n    \n\n    {# Now we see if the node already exists in the metric tree and return that if \n    it does so that we're not creating duplicates #}\n    {%- if metric_definition.name not in metric_tree|map(attribute=\"full_set\") -%}\n\n        {%- set full_set = metric_tree[\"full_set\"] -%}\n        {%- do full_set.append(metric_definition.name) -%}\n        {%- do metric_tree.update({'full_set':full_set}) -%}\n\n    {%- endif -%}\n\n    {# Here we're starting with the highest level and assigning the metric tree that first level\n    value. This is used before de-duping in get_faux_metric_tree #}\n    {%- do metric_tree[\"ordered_derived_set\"].update({metric_definition.name:metric_count}) -%}\n    {%- set metric_count = metric_count - 1 -%}\n\n    {# Here we create two sets, sets being the same as lists but they account for uniqueness. \n    One is the full set, which contains all of the parent metrics and the other is the leaf\n    set, which we'll use to determine the leaf, or base metrics. #}\n\n    {% set develop_metric_list = [] %}\n    {% for develop_metric_name in develop_yml %}\n        {% do develop_metric_list.append(develop_metric_name) %}\n    {% endfor %}\n\n    {# We define parent nodes as being the parent nodes that begin with metric, which lets\n    us filter out model nodes #}\n    {%- set parent_metrics = metrics.get_develop_unique_metric_id_list(metric_definition) -%}\n    {# We set an if condition based on if parent nodes. If there are none, then this metric\n    is a leaf node and any recursive loop should end #}\n    {%- if parent_metrics | length > 0 -%}\n\n        {# Now we finally recurse through the nodes. We begin by filtering the overall list we\n        recurse through by limiting it to depending on metric nodes and not ALL nodes #}\n        {%- for parent_metric_name in parent_metrics -%}\n\n            {# Then we add the parent_id of the metric to the full set. If it already existed\n            then it won't make an impact but we want to make sure it is represented. Will dedupe\n            in final macro #}\n            {%- set full_set_plus = metric_tree[\"full_set\"] -%}\n            {%- if parent_metric_name in metric_tree|map(attribute=\"full_set\") -%}\n                {%- do full_set_plus.append(parent_metric_name) -%}\n            {%- endif -%}\n            {%- do metric_tree.update({'full_set':full_set_plus}) -%}\n\n            {# And here we re-run the current macro but fill in the parent_id so that we loop again\n            with that metric information. You may be wondering, why are you using parent_id? Doesn't \n            the DAG always go from parent to child? Normally, yes! With this, no! We're reversing the \n            DAG and going up to parents to find the leaf nodes that are really parent nodes. #}\n            \n            {# So here we need to test if the parent id/metric name exists in the manifest OR in\n            the develop yml. Manifest takes priority and then defaults back to yml if not present #}\n            {% if parent_metric_name in develop_metric_list and parent_metric_name is not none %}\n                {% set parent_metric_definition = develop_yml[parent_metric_name] %}\n            {% else %}\n                {%- set parent_metric_definition = metrics.get_metric_relation(parent_metric_name) -%}\n            {% endif %}\n\n            {%- set metric_tree =  metrics.update_faux_metric_tree(parent_metric_definition, metric_tree, develop_yml, metric_count) -%}\n\n        {%- endfor -%}\n    \n    {%- else -%}\n\n        {%- set parent_set_plus = metric_tree[\"parent_set\"] -%}\n        {%- do parent_set_plus.append(metric_definition.name) -%}\n        {%- do metric_tree.update({'parent_set':parent_set_plus}) -%}\n\n    {%- endif -%}\n\n    {%- set derived_set_plus = ( metric_tree[\"full_set\"] | reject('in',metric_tree[\"parent_set\"]) | list) -%}\n    {%- do metric_tree.update({'derived_set':derived_set_plus}) -%}\n\n    {%- do return(metric_tree) -%}\n\n{% endmacro %}", "hash": "c887544e67b2e16bbd122cdc70032973", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/update_faux_metric_tree.sql"}, "dbt_packages/metrics/macros/variables/get_models_grouping.sql": {"contents": "{%- macro get_models_grouping(metric_tree, metrics_dictionary) -%}\n{#- \nThe purpose of this macro is to create a dictionary that can be used by\ngen_base_query and gen_aggregate_query in order to intelligently group\nmetrics together on whether they can be queried in the same query. These\nwill be grouped together with a unique model name as the key and the value \ncontaining the list of the metrics. This is complicated because we allow\ndifferent properties that affect the base query, so we can't do a single \ngrouping based on model. As such, if a metric contains one of these properties\nwe have to create a group for that specific combination.\n\nThe properties that cause us to group the metric seperately are:\n    - windows\n    - filters\n    - timestamp fields\n\nIn order to ensure consistency, we will also include those values in the \ndictionary so we can reference them from the metrics grouping (ie a single\nlocation) instead of from a randomly selected metric in the list of metrics.\n\nAn example output looks like:\n{\n    'model_4f977327f02b5c04af4337f54ed81a17': {\n        'metric_names':['metric_a','metric_b'],\n        'metric_timestamp': order_date,\n        'metric_filters':[\n            MetricFilter(field='had_discount', operator='is', value='true'), \n            MetricFilter(field='order_country', operator='=', value='CA')\n        ]\n        'metric_window': MetricTime(count=14, period=<MetricTimePeriod.month: 'month'>)\n    }\n} \n -#}\n\n    {% set models_grouping = {} %}\n\n    {% for metric_name in metric_tree.parent_set %}\n        {% set metric_dictionary = metrics_dictionary[metric_name] %}\n\n        {% set models_grouping = metrics.get_model_group(\n                models_grouping=models_grouping,\n                metric_model=metric_dictionary.metric_model,\n                metric_model_name=metric_dictionary.metric_model_name,\n                metric_name=metric_dictionary.name,\n                metric_timestamp=metric_dictionary.timestamp,\n                metric_filters=metric_dictionary.filters,\n                metric_window=metric_dictionary.window\n            ) %}\n\n    {% endfor %}\n\n    {% do return(models_grouping) %}\n\n{%- endmacro -%}", "hash": "7a5c2581bc26b16ee44178775d0e51be", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_models_grouping.sql"}, "dbt_packages/metrics/macros/variables/get_total_dimension_count.sql": {"contents": "{%- macro get_total_dimension_count(grain, dimensions, calendar_dimensions, relevant_periods) %}\n\n{# This macro calcualtes the total amount of dimensions that will need to be grouped by #}\n\n    {%- set dimension_length = dimensions | length -%}\n    {%- set calendar_dimension_length = calendar_dimensions | length -%}\n\n    {%- if grain -%}\n        {%- set grain_length = 1 -%}\n    {%- else -%}\n        {%- set grain_length = 0 -%}\n    {%- endif -%}\n\n    {%- set cleaned_relevant_periods = [] -%}\n    {%- set period_length = relevant_periods | length -%}\n    {%- set total_length = grain_length + dimension_length + period_length + calendar_dimension_length -%}\n\n    {% do return(total_length) %}\n\n{% endmacro %}", "hash": "3fa39e4edb49bd64b920dd5ae674397e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_total_dimension_count.sql"}, "dbt_packages/metrics/macros/variables/get_metric_model_name.sql": {"contents": "{% macro get_metric_model_name(metric_model) %}\n\n    {% set metric_model_name = metric_model.replace('\"','\\'').split('\\'')[1] %}\n\n    {% do return(metric_model_name) %}\n\n{% endmacro %}", "hash": "7ecf8e93692ec84b4f70eb7ecbeade31", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_metric_model_name.sql"}, "dbt_packages/metrics/macros/variables/get_grain_order.sql": {"contents": "{% macro get_grain_order() %}\n    {{ return(adapter.dispatch('get_grain_order', 'metrics')()) }}\n{% endmacro %}\n\n{% macro default__get_grain_order() %}\n    {% do return (['day', 'week', 'month', 'quarter', 'year']) %}\n{% endmacro %}", "hash": "dc03a9db246abaa414db837b17ad1b67", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_grain_order.sql"}, "dbt_packages/metrics/macros/variables/get_relevent_periods.sql": {"contents": "{%- macro get_relevent_periods(grain, secondary_calculations) %}\n\n    {%- set relevant_periods = [] %}\n    {%- for calc_config in secondary_calculations if calc_config.period and calc_config.period not in relevant_periods and calc_config.period != grain %}\n        {%- do relevant_periods.append(calc_config.period) %}\n    {%- endfor -%}\n\n    {%- do return(relevant_periods)-%}\n\n{% endmacro %}", "hash": "4591b93483504db3d95c937bb82bb753", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_relevent_periods.sql"}, "dbt_packages/metrics/macros/variables/get_develop_unique_metric_id_list.sql": {"contents": "{%- macro get_develop_unique_metric_id_list(metric_definition) %}\n\n    {% set re = modules.re %}\n\n    {%- set metric_list = [] -%}\n\n    {%- if metric_definition.calculation_method == 'derived' %}\n\n        {# First we get the list of nodes that this metric is dependent on. This is inclusive \n        of all parent metrics and SHOULD only contain parent metrics #}\n        {%- set dependency_metrics = re.findall(\"'[^']+'\",metric_definition.expression) -%}\n\n        {# This part is suboptimal - we're looping through the dependent nodes and extracting\n        the model name from the idenitfier. Ideally we'd just use the metrics attribute but \n        right now its a list of lists #}\n        {%- for metric_name in dependency_metrics -%} \n=           {% do metric_list.append(metric_name.replace('\\'','')) %} \n        {%- endfor -%}\n\n    {%- endif %}\n\n    {% do return(metric_list) %}\n\n{% endmacro %}", "hash": "4242f01e165bd80577bbf4552a82cca8", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_develop_unique_metric_id_list.sql"}, "dbt_packages/metrics/macros/variables/get_metric_list.sql": {"contents": "{%- macro get_metric_list(metric) %}\n\n    {%- if metric.metrics | length > 0 %}\n\n        {# First we get the list of nodes that this metric is dependent on. This is inclusive \n        of all parent metrics and SHOULD only contain parent metrics #}\n        {%- set node_list = metric.depends_on.nodes -%}\n        {%- set metric_list = [] -%}\n\n        {# This part is suboptimal - we're looping through the dependent nodes and extracting\n        the model name from the idenitfier. Ideally we'd just use the metrics attribute but \n        right now its a list of lists #}\n        {%- for node in node_list -%}  \n            {% set metric_name = node.split('.')[2] %}\n            {% do metric_list.append(metric_name) %}\n        {%- endfor -%}\n\n    {% else %}\n\n        {# For non-derived metrics, we just need the relation of the base model ie \n        the model that its built. Then we append it to the metric list name so the same\n        variable used in derived metrics can be used below #}\n        {%- set metric_list = [] -%}\n        {% do metric_list.append(metric.name) %}\n\n    {%- endif %}\n\n    {% do return(metric_list) %}\n\n{% endmacro %}", "hash": "5afea3f98ec8f4c3677aeafa9eb5ba60", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_metric_list.sql"}, "dbt_packages/metrics/macros/variables/get_metric_definition.sql": {"contents": "{% macro get_metric_definition(metric_definition) %}\n\n    {% set metrics_dictionary_dict = {} %}\n\n    {% do metrics_dictionary_dict.update({'name': metric_definition.name})%}\n    {% do metrics_dictionary_dict.update({'calculation_method': metric_definition.calculation_method})%}\n    {% do metrics_dictionary_dict.update({'timestamp': metric_definition.timestamp})%}\n    {% do metrics_dictionary_dict.update({'time_grains': metric_definition.time_grains})%}\n    {% do metrics_dictionary_dict.update({'dimensions': metric_definition.dimensions})%}\n    {% do metrics_dictionary_dict.update({'filters': metric_definition.filters})%}\n    {% do metrics_dictionary_dict.update({'config': metric_definition.config})%}\n    {% if metric_definition.calculation_method != 'derived' %}\n        {% set metric_model_name = metrics.get_metric_model_name(metric_model=metric_definition.model) %}\n        {% do metrics_dictionary_dict.update({'metric_model_name': metric_model_name }) %}\n        {% do metrics_dictionary_dict.update({'metric_model': metrics.get_model_relation(metric_model_name, metric_name)}) %}\n    {% endif %}\n\n    {# Behavior specific to develop #}\n    {% if metric_definition is mapping %}\n        {# We need to do some cleanup for metric parsing #}\n        {% set metric_expression = metric_definition.expression | replace(\"metric(\",\"\") | replace(\")\",\"\") | replace(\"{{\",\"\") | replace(\"}}\",\"\")  | replace(\"'\",\"\") | replace('\"',\"\")  %}\n        {% do metrics_dictionary_dict.update({'expression': metric_expression})%} \n        {% if metric_definition.window %}\n            {% do metrics_dictionary_dict.update({'window': metric_definition.window}) %}\n        {% else %}\n            {% do metrics_dictionary_dict.update({'window': none}) %}\n        {% endif %}\n\n    {# Behavior specific to calculate #}\n    {% else %}\n        {% do metrics_dictionary_dict.update({'expression': metric_definition.expression})%} \n        {% do metrics_dictionary_dict.update({'window': metric_definition.window})%}\n    {% endif %}\n\n    {% do return(metrics_dictionary_dict) %}\n\n{% endmacro %}", "hash": "4c2264ab3adbe956160254a20b69c511", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_metric_definition.sql"}, "dbt_packages/metrics/macros/variables/get_metric_unique_id_list.sql": {"contents": "{%- macro get_metric_unique_id_list(metric) %}\n\n    {%- if metric.metrics | length > 0 %}\n\n        {# First we get the list of nodes that this metric is dependent on. This is inclusive \n        of all parent metrics and SHOULD only contain parent metrics #}\n        {%- set node_list = metric.depends_on.nodes -%}\n        {%- set metric_list = [] -%}\n\n        {# This part is suboptimal - we're looping through the dependent nodes and extracting\n        the model name from the idenitfier. Ideally we'd just use the metrics attribute but \n        right now its a list of lists #}\n        {%- for node in node_list -%}  \n            {%- if node.split('.')[0] == 'metric' -%}\n                {% do metric_list.append(node.split('.')[2]) %} \n            {%- endif -%}\n        {%- endfor -%}\n\n    {% else %}\n\n        {# For non-derived metrics, we just need the relation of the base model ie \n        the model that its built. Then we append it to the metric list name so the same\n        variable used in derived metrics can be used below #}\n        {%- set metric_list = [] -%}\n\n    {%- endif %}\n\n    {% do return(metric_list) %}\n\n{% endmacro %}", "hash": "0b57187cbc9779b2d69c92f013457780", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_metric_unique_id_list.sql"}, "dbt_packages/metrics/macros/variables/get_metric_allowlist.sql": {"contents": "{% macro get_metric_allowlist() %}\n    {{ return(adapter.dispatch('get_metric_allowlist', 'metrics')()) }}\n{% endmacro %}\n\n{% macro default__get_metric_allowlist() %}\n    {# Keys are the primary aggregation, values are the permitted aggregations to run in secondary calculations. #}\n    {% do return ({\n        \"average\": ['min', 'max'],\n        \"median\": ['min', 'max'],\n        \"count\": ['min', 'max', 'sum', 'average'],\n        \"count_distinct\": ['min', 'max', 'sum', 'average'],\n        \"sum\": ['min', 'max', 'sum', 'average'],\n        \"max\": ['min', 'max', 'sum', 'average'],\n        \"min\": ['min', 'max', 'sum', 'average'],\n        \"derived\": ['min', 'max', 'sum'],\n    }) %}\n{% endmacro %}", "hash": "8db90f0a3a9634294a5a29d73c9eac85", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_metric_allowlist.sql"}, "dbt_packages/metrics/macros/variables/get_base_metrics.sql": {"contents": "{% macro get_base_metrics(metric) %}\n\n    -- this checks whether it is a relation or a list\n    {%- if (metric is mapping and metric.get('metadata', {}).get('calculation_method', '').endswith('Relation')) %}\n\n        {%- for child in metric recursive -%}\n\n            {%- if metric.metrics | length > 0 %}\n\n            {# First we get the list of nodes that this metric is dependent on. This is inclusive \n            of all parent metrics and SHOULD only contain parent metrics #}\n            {%- set node_list = metric.depends_on.nodes -%}\n            {%- set metric_list = [] -%}\n            {# This part is suboptimal - we're looping through the dependent nodes and extracting\n            the metric name from the idenitfier. Ideally we'd just use the metrics attribute but \n            right now its a list of lists #}\n                {%- for node in node_list -%}  \n                    {% set metric_name = node.split('.')[2] %}\n                    {% do metric_list.append(metric_name) %}\n                {%- endfor -%}\n            {%- endif -%}\n        {%- endfor -%}\n\n    {% else %}\n\n        {# For non-derived metrics, we just need the relation of the base model ie \n        the model that its built. Then we append it to the metric list name so the same\n        variable used in derived metrics can be used below #}\n        {%- set metric_list = [] -%}\n        {% do metric_list.append(metric.name) %}\n\n    {%- endif %}\n\n    {% do return(metric_list) %}\n\n{% endmacro %}", "hash": "1f66d60b90d17623b92050d230791b2b", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/variables/get_base_metrics.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_final_cte.sql": {"contents": "{%- macro gen_final_cte(metric_tree, metrics_dictionary, models_grouping, grain, dimensions, calendar_dimensions, relevant_periods, secondary_calculations, where, date_alias) -%}\n    {{ return(adapter.dispatch('gen_final_cte', 'metrics')(metric_tree, metrics_dictionary, models_grouping, grain, dimensions, calendar_dimensions, relevant_periods, secondary_calculations, where, date_alias)) }}\n{%- endmacro -%}\n\n{%- macro default__gen_final_cte(metric_tree, metrics_dictionary, models_grouping, grain, dimensions, calendar_dimensions, relevant_periods, secondary_calculations, where, date_alias) %}\n\n{%- if secondary_calculations | length > 0 %}\n{#- This section is for queries using secondary calculations -#}\nselect \n    date_{{grain}} {% if date_alias%}as {{date_alias}}{%endif%}\n    {%- if secondary_calculations | length > 0 -%}\n        {%- for period in relevant_periods %}\n    ,date_{{ period }}\n        {%- endfor %}\n    {%- endif -%}\n    {%- for dim in dimensions %}\n    ,{{ dim }}\n    {%- endfor %}\n    {%- for calendar_dim in calendar_dimensions %}\n    ,{{ calendar_dim }}\n    {%- endfor %}\n    {%- for metric_name in metric_tree.parent_set|list + metric_tree.derived_set|list %}\n    ,{{metric_name}}\n    {%- endfor %}  \n    {{ metrics.gen_secondary_calculations(metric_tree, metrics_dictionary, grain, dimensions, secondary_calculations, calendar_dimensions)}}\n    {%- if models_grouping| length > 1 or metric_tree['derived_set'] | length > 0  %}\nfrom joined_metrics \n    {%- else %} \nfrom {% for group_name, group_values in models_grouping.items()-%}{{group_name}}__final {%-endfor-%}\n    {%- endif %}\n{# metric where clauses #}\n    {%- if where %}\nwhere {{ where }}\n    {%- endif %}\n{{ metrics.gen_order_by(grain, dimensions, calendar_dimensions, relevant_periods) }}\n\n{%- elif models_grouping| length > 1 or metric_tree['derived_set'] | length > 0 -%}\n{#- This section is for queries from multiple models or using derived metrics -#}\nselect \n    {%- if grain %}\n    date_{{grain}} {% if date_alias%}as {{date_alias}}{%endif%},\n    {%- endif %}\n    {%- for dim in dimensions %}\n    {{ dim }},\n    {%- endfor %}\n    {%- for calendar_dim in calendar_dimensions %}\n    {{ calendar_dim }},\n    {%- endfor %}\n    {%- for metric_name in metric_tree.parent_set|list + metric_tree.derived_set|list %}\n    {{metric_name}}{%- if not loop.last -%},{%- endif -%}\n    {%- endfor %}  \nfrom joined_metrics\n{#- metric where clauses -#}\n    {%- if where %}\nwhere {{ where }}\n    {%- endif -%}\n{{ metrics.gen_order_by(grain, dimensions, calendar_dimensions, relevant_periods) }}\n    \n{%- else -%}\n{#- This section is for non-derived, non-secondary calc queries -#}\nselect \n    {%- if grain %}\n    date_{{grain}} {% if date_alias%}as {{date_alias}}{%endif%},\n    {%- endif %}\n    {%- for dim in dimensions %}\n    {{ dim }},\n    {%- endfor %}\n    {%- for calendar_dim in calendar_dimensions %}\n    {{ calendar_dim }},\n    {% endfor -%}\n    {%- for metric_name in metric_tree.parent_set|list + metric_tree.derived_set|list %}\n    {{metric_name}}{%- if not loop.last -%},{%- endif -%}\n    {%- endfor %}  \n    {# {%- for metric_name in metric_tree.full_set %}\n    {{metric_name}}{%if not loop.last%},{%endif%}\n    {%- endfor %} #}\nfrom {% for group_name, group_values in models_grouping.items()-%}{{group_name}}__final {%-endfor-%}\n    {%- if where %}\nwhere {{ where }}\n    {%- endif -%}\n{{ metrics.gen_order_by(grain, dimensions, calendar_dimensions, relevant_periods) }}\n{%- endif %}\n\n{%- endmacro %}", "hash": "d761d920bb544596840accec8a8c976d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_final_cte.sql"}, "dbt_packages/metrics/macros/sql_gen/build_metric_sql.sql": {"contents": "{%- macro build_metric_sql(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions, dimensions_provided, total_dimension_count, group_name, group_values) %}\n    \n    {#- This is the SQL Gen part - we've broken each component out into individual macros -#}\n    {#- We broke this out so it can loop for composite metrics -#}\n    {{ metrics.gen_aggregate_cte(\n        metrics_dictionary=metrics_dictionary,\n        grain=grain, \n        dimensions=dimensions, \n        secondary_calculations=secondary_calculations,\n        start_date=start_date, \n        end_date=end_date, \n        relevant_periods=relevant_periods, \n        calendar_dimensions=calendar_dimensions,\n        total_dimension_count=total_dimension_count,\n        group_name=group_name,\n        group_values=group_values\n    ) }}\n    \n    {#- Diverging path for secondary calcs and needing to datespine -#}\n    {%- if grain and secondary_calculations | length > 0 -%}\n\n        {%- if dimensions_provided == true -%}\n        \n            {{ metrics.gen_dimensions_cte(\n                group_name=group_name, \n                dimensions=dimensions\n            ) }}\n        \n        {%- endif -%}\n\n        {{ metrics.gen_spine_time_cte(\n            group_name=group_name, \n            grain=grain, \n            dimensions=dimensions, \n            secondary_calculations=secondary_calculations, \n            relevant_periods=relevant_periods, \n            calendar_dimensions=calendar_dimensions, \n            dimensions_provided=dimensions_provided\n        )}}\n\n    {%- endif -%}\n\n    {{ metrics.gen_metric_cte(\n        metrics_dictionary=metrics_dictionary,\n        group_name=group_name, \n        group_values=group_values,\n        grain=grain, \n        dimensions=dimensions, \n        secondary_calculations=secondary_calculations, \n        start_date=start_date, \n        end_date=end_date, \n        relevant_periods=relevant_periods, \n        calendar_dimensions=calendar_dimensions\n    )}} \n\n{%- endmacro -%}\n", "hash": "d866572bf0201e167b5b2a9a62b96060", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/build_metric_sql.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_dimensions_cte.sql": {"contents": "{%- macro gen_dimensions_cte(group_name, dimensions) -%}\n    {{ return(adapter.dispatch('gen_dimensions_cte', 'metrics')(group_name, dimensions)) }}\n{%- endmacro -%}\n\n{% macro default__gen_dimensions_cte(group_name, dimensions) %}\n\n, {{group_name}}__dims as (\n\n    select distinct\n        {%- for dim in dimensions %}\n        {{ dim }}{%- if not loop.last -%},{% endif -%}\n        {%- endfor %}\n    from {{group_name}}__aggregate\n)\n\n{%- endmacro -%}\n", "hash": "24e11146c4a81c96623f10f00693b1b9", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_dimensions_cte.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_filters.sql": {"contents": "{%- macro gen_filters(model_values, start_date, end_date) -%}\n    {{ return(adapter.dispatch('gen_filters', 'metrics')(model_values, start_date, end_date)) }}\n{%- endmacro -%}\n\n{%- macro default__gen_filters(model_values, start_date, end_date) -%}\n\n    {#- metric start/end dates also applied here to limit incoming data -#}\n    {% if start_date or end_date %}\n        and (\n        {% if start_date and end_date -%}\n            cast(base_model.{{model_values.timestamp}} as date) >= cast('{{ start_date }}' as date)\n            and cast(base_model.{{model_values.timestamp}} as date) <= cast('{{ end_date }}' as date)\n        {%- elif start_date and not end_date -%}\n            cast(base_model.{{model_values.timestamp}} as date) >= cast('{{ start_date }}' as date)\n        {%- elif end_date and not start_date -%}\n            cast(base_model.{{model_values.timestamp}} as date) <= cast('{{ end_date }}' as date)\n        {%- endif %} \n        )\n    {% endif -%} \n\n    {#- metric filter clauses... -#}\n    {% if model_values.filters %}\n        and (\n            {% for filter in model_values.filters -%}\n                {%- if not loop.first -%} and {% endif %}{{ filter.field }} {{ filter.operator }} {{ filter.value }}\n            {% endfor -%}\n        )\n    {% endif -%}\n\n{%- endmacro -%}", "hash": "f97ea891e59f2e9fbab4ede9cfe503ba", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_filters.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_order_by.sql": {"contents": "{%- macro gen_order_by(grain, dimensions, calendar_dimensions, relevant_periods) -%}\n    {{ return(adapter.dispatch('gen_order_by', 'metrics')(grain, dimensions, calendar_dimensions, relevant_periods)) }}\n{%- endmacro -%}\n\n{% macro default__gen_order_by(grain, dimensions, calendar_dimensions, relevant_periods) %}\n    {# #}\n    {%- if grain %}\norder by 1 desc\n    {% endif -%}\n    {# #}\n{% endmacro %}", "hash": "872586069b6c058a45c2cbbc22a3465a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_order_by.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_spine_time_cte.sql": {"contents": "{%- macro gen_spine_time_cte(group_name, grain, dimensions, secondary_calculations, relevant_periods, calendar_dimensions, dimensions_provided) -%}\n    {{ return(adapter.dispatch('gen_spine_time_cte', 'metrics')(group_name, grain, dimensions, secondary_calculations, relevant_periods, calendar_dimensions, dimensions_provided)) }}\n{%- endmacro -%}\n\n{% macro default__gen_spine_time_cte(group_name, grain, dimensions, secondary_calculations, relevant_periods, calendar_dimensions, dimensions_provided) %}\n\n, {{group_name}}__spine_time as (\n\n    select\n        calendar.date_{{grain}}\n        {%- if secondary_calculations | length > 0 -%}\n            {% for period in relevant_periods %}\n                {%- if period != grain -%}\n        , calendar.date_{{ period }}\n                {%- endif -%}\n            {% endfor -%}\n        {% endif -%}\n        {% for calendar_dim in calendar_dimensions %}\n        , calendar.{{ calendar_dim }}\n        {%- endfor %}\n        {%- for dim in dimensions %}\n        , {{group_name}}__dims.{{ dim }}\n        {%- endfor %}\n    from calendar\n    {%- if dimensions_provided %}\n    cross join {{group_name}}__dims\n    {%- endif %}\n    {{ metrics.gen_group_by(grain,dimensions,calendar_dimensions,relevant_periods) }}\n\n)\n{%- endmacro -%}\n", "hash": "0cb78170ffc61c69038acd513bd00e62", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_spine_time_cte.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_calendar_join.sql": {"contents": "{% macro gen_calendar_join(group_values) %}\n    {{ return(adapter.dispatch('gen_calendar_join', 'metrics')(group_values)) }}\n{%- endmacro -%}\n\n{% macro default__gen_calendar_join(group_values) %}\n        left join calendar\n        {%- if group_values.window is not none %}\n            on cast(base_model.{{group_values.timestamp}} as date) > dateadd({{group_values.window.period}}, -{{group_values.window.count}}, calendar.date_day)\n            and cast(base_model.{{group_values.timestamp}} as date) <= calendar.date_day\n        {%- else %}\n            on cast(base_model.{{group_values.timestamp}} as date) = calendar.date_day\n        {% endif -%}\n{% endmacro %}\n\n{% macro bigquery__gen_calendar_join(group_values) %}\n        left join calendar\n        {%- if group_values.window is not none %}\n            on cast(base_model.{{group_values.timestamp}} as date) > date_sub(calendar.date_day, interval {{group_values.window.count}} {{group_values.window.period}})\n            and cast(base_model.{{group_values.timestamp}} as date) <= calendar.date_day\n        {%- else %}\n            on cast(base_model.{{group_values.timestamp}} as date) = calendar.date_day\n        {% endif -%}\n{% endmacro %}\n\n{% macro postgres__gen_calendar_join(group_values) %}\n        left join calendar\n        {%- if group_values.window is not none %}\n            on cast(base_model.{{group_values.timestamp}} as date) > calendar.date_day - interval '{{group_values.window.count}} {{group_values.window.period}}'\n            and cast(base_model.{{group_values.timestamp}} as date) <= calendar.date_day\n        {%- else %}\n            on cast(base_model.{{group_values.timestamp}} as date) = calendar.date_day\n        {% endif -%}\n{% endmacro %}\n\n{% macro redshift__gen_calendar_join(group_values) %}\n        left join calendar\n        {%- if group_values.window is not none %}\n            on cast(base_model.{{group_values.timestamp}} as date) > dateadd({{group_values.window.period}}, -{{group_values.window.count}}, calendar.date_day)\n            and cast(base_model.{{group_values.timestamp}} as date) <= calendar.date_day\n        {%- else %}\n            on cast(base_model.{{group_values.timestamp}} as date) = calendar.date_day\n        {% endif -%}\n{% endmacro %}\n", "hash": "d1345450a4043dc1e55dcd0cf7fc6ad2", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_calendar_join.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_calendar_cte.sql": {"contents": "{%- macro gen_calendar_cte(calendar_tbl, start_date, end_date) -%}\n    {{ return(adapter.dispatch('gen_calendar_cte', 'metrics')(calendar_tbl, start_date, end_date)) }}\n{%- endmacro -%}\n\n{%- macro default__gen_calendar_cte(calendar_tbl, start_date, end_date) %}\n\nwith calendar as (\n    {# This CTE creates our base calendar and then limits the date range for the \n    start and end date provided by the macro call -#}\n    select \n        * \n    from {{ calendar_tbl }}\n    {% if start_date or end_date %}\n        {%- if start_date and end_date -%}\n            where date_day >= cast('{{ start_date }}' as date)\n            and date_day <= cast('{{ end_date }}' as date)\n        {%- elif start_date and not end_date -%}\n            where date_day >= cast('{{ start_date }}' as date)\n        {%- elif end_date and not start_date -%}\n            where date_day <= cast('{{ end_date }}' as date)\n        {%- endif -%}       \n    {% endif %} \n)\n\n{%- endmacro -%}\n", "hash": "a9f9352f56d03682a11447382c9d8185", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_calendar_cte.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_metric_cte.sql": {"contents": "{%- macro gen_metric_cte(metrics_dictionary, group_name, group_values, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions) -%}\n    {{ return(adapter.dispatch('gen_metric_cte', 'metrics')(metrics_dictionary, group_name, group_values, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions)) }}\n{%- endmacro -%}\n\n{%- macro default__gen_metric_cte(metrics_dictionary, group_name, group_values, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions) %}\n\n{%- set combined_dimensions = calendar_dimensions | list + dimensions | list -%}\n, {{group_name}}__final as (\n    {# #}\n    select\n        {%- if grain %}\n        parent_metric_cte.date_{{grain}},\n            {%- if secondary_calculations | length > 0 -%}\n                {% for period in relevant_periods %}\n        parent_metric_cte.date_{{ period }},\n                {%- endfor -%}\n            {%- endif -%}\n        {%- endif -%}\n        \n        {%- for calendar_dim in calendar_dimensions %}\n        parent_metric_cte.{{ calendar_dim }},\n        {%- endfor %}\n\n        {%- for dim in dimensions %}\n        parent_metric_cte.{{ dim }},\n        {%- endfor %}\n\n        {%- for metric_name in group_values.metric_names -%}\n            {# TODO: coalesce based on the value. Need to bring this config #}\n            {%- if not metrics_dictionary[metric_name].get(\"config\").get(\"treat_null_values_as_zero\", True) %}\n        {{ metric_name }}\n            {%- else %}\n        coalesce({{ metric_name }}, 0) as {{ metric_name }}\n            {%- endif %}\n        {%- if not loop.last-%},{%endif%}\n        {%- endfor %}\n\n    {%- if secondary_calculations | length > 0 %}\n    from {{group_name}}__spine_time as parent_metric_cte\n    left outer join {{group_name}}__aggregate\n        using (date_{{grain}} {%- if combined_dimensions | length > 0 -%}, {{ combined_dimensions | join(\", \") }} {%-endif-%} )\n\n    {% if not start_date or not end_date -%}\n    where (\n        {% if not start_date and not end_date -%}\n        parent_metric_cte.date_{{grain}} >= (\n            select \n                min(case when has_data then date_{{grain}} end) \n            from {{group_name}}__aggregate\n        )\n        and parent_metric_cte.date_{{grain}} <= (\n            select \n                max(case when has_data then date_{{grain}} end) \n            from {{group_name}}__aggregate\n        )\n        {% elif not start_date and end_date -%}\n        parent_metric_cte.date_{{grain}} >= (\n            select \n                min(case when has_data then date_{{grain}} end) \n            from {{group_name}}__aggregate\n        )\n        {% elif start_date and not end_date -%}\n        parent_metric_cte.date_{{grain}} <= (\n            select \n                max(case when has_data then date_{{grain}} end) \n            from {{group_name}}__aggregate\n        )\n        {%- endif %} \n        )\n    {%- endif %} \n\n    {%- else %}\n    from {{group_name}}__aggregate as parent_metric_cte\n    {%- endif %}\n)\n\n{% endmacro %}\n", "hash": "7ecb66d7f71c572c0808a6b64320d7f5", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_metric_cte.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_group_by.sql": {"contents": "{%- macro gen_group_by(grain, dimensions, calendar_dimensions, relevant_periods) -%}\n    {{ return(adapter.dispatch('gen_group_by', 'metrics')(grain, dimensions, calendar_dimensions, relevant_periods)) }}\n{%- endmacro -%}\n\n{%- macro default__gen_group_by(grain, dimensions, calendar_dimensions, relevant_periods) -%}\n\n{#- This model exclusively exists because dynamic group by counts based on range \nwere too funky when we hardcoded values for 1+1. So we're getting around it by\nmaking it its own function -#}\n\n{#- The issue arises when we have an initial date column (ie date_month) where month \nis also included in the relevent periods. This causes issues and so we need to\nremove the grain from the list of relevant periods so it isnt double counted -#}\n\n    {%- set total_dimension_count = metrics.get_total_dimension_count(grain, dimensions, calendar_dimensions, relevant_periods) -%}\n\n    {%- if grain -%}\n        group by {% for number in range(1,total_dimension_count+1) -%}{{ number }}{%- if not loop.last -%}, {% endif -%}\n        {%- endfor -%}\n    {%- else -%}\n        {%- if total_dimension_count > 0 -%}\n            group by {% for number in range(1,total_dimension_count+1) -%}{{ number }} {%- if not loop.last -%}, {% endif -%}\n            {%- endfor -%}\n        {%- endif -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n", "hash": "54d9e08f35adcc74b860b2da70e23c1f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_group_by.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_secondary_calculations.sql": {"contents": "{%- macro gen_secondary_calculations(metric_tree, metrics_dictionary, grain, dimensions, secondary_calculations, calendar_dimensions) -%}\n    {{ return(adapter.dispatch('gen_secondary_calculations', 'metrics')(metric_tree, metrics_dictionary, grain, dimensions, secondary_calculations, calendar_dimensions)) }}\n{%- endmacro -%}\n\n{% macro default__gen_secondary_calculations(metric_tree, metrics_dictionary, grain, dimensions, secondary_calculations, calendar_dimensions) %}\n\n{%- for calc_config in secondary_calculations %}\n    {%- if calc_config.metric_list | length > 0 -%}\n        {%- for metric_name in calc_config.metric_list -%}\n    ,{{ metrics.perform_secondary_calculation(metric_name, grain, dimensions, calendar_dimensions, calc_config, metrics_dictionary[metric_name].config) }}\n        {%- endfor %}  \n    {%- else %}\n        {%- for metric_name in metric_tree.base_set -%}\n    , {{ metrics.perform_secondary_calculation(metric_name, grain, dimensions, calendar_dimensions, calc_config, metrics_dictionary[metric_name].config) }}\n        {%- endfor %}\n    {%- endif %}\n{%- endfor %}\n\n{%- endmacro %}\n", "hash": "522ade4c75c100cc00b000a52bdc098d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_secondary_calculations.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_base_query.sql": {"contents": "{% macro gen_base_query(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions, total_dimension_count, group_name, group_values) %}\n    {{ return(adapter.dispatch('gen_base_query', 'metrics')(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions, total_dimension_count, group_name, group_values)) }}\n{% endmacro %}\n\n{% macro default__gen_base_query(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions, total_dimension_count, group_name, group_values) %}\n        {# This is the \"base\" CTE which selects the fields we need to correctly \n        calculate the metric.  -#}\n        select \n            {% if grain -%}\n            {#- \n                Given that we've already determined the metrics in metric_names share\n                the same windows & filters, we can base the conditional off of the first \n                value in the list because the order doesn't matter. \n            -#}\n            cast(base_model.{{group_values.timestamp}} as date) as metric_date_day,\n            calendar.date_{{ grain }} as date_{{grain}},\n            calendar.date_day as window_filter_date,\n                {%- if secondary_calculations | length > 0 %}\n                    {%- for period in relevant_periods %}\n            calendar.date_{{ period }},\n                    {%- endfor -%}\n                {%- endif -%}\n            {%- endif -%}\n            {#- -#}\n            {%- for dim in dimensions %}\n            base_model.{{ dim }},\n            {%- endfor %}\n            {%- for calendar_dim in calendar_dimensions -%}\n            calendar.{{ calendar_dim }},\n            {%- endfor -%}\n            {%- for metric_name in group_values.metric_names -%}\n            {{ metrics.gen_property_to_aggregate(metrics_dictionary[metric_name], grain, dimensions, calendar_dimensions) }}\n            {%- if not loop.last -%},{%- endif -%}\n            {%- endfor%}\n        from {{ group_values.metric_model }} base_model \n        {# -#}\n        {%- if grain or calendar_dimensions|length > 0 -%}\n        {{ metrics.gen_calendar_join(group_values) }} \n        {%- endif -%}\n        {# #}\n        where 1=1\n        {#- -#}\n        {{ metrics.gen_filters(group_values, start_date, end_date) }}\n        {# #}\n\n{%- endmacro -%}", "hash": "0f77c445af4da2b405bb5bbb49292096", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_base_query.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_aggregate_cte.sql": {"contents": "{%- macro gen_aggregate_cte(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions, total_dimension_count, group_name, group_values) -%}\n    {{ return(adapter.dispatch('gen_aggregate_cte', 'metrics')(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions, total_dimension_count, group_name, group_values)) }}\n{%- endmacro -%}\n\n{%- macro default__gen_aggregate_cte(metrics_dictionary, grain, dimensions, secondary_calculations, start_date, end_date, relevant_periods, calendar_dimensions, total_dimension_count, group_name, group_values) %}\n\n, {{group_name}}__aggregate as (\n    {# This is the most important CTE. Instead of joining all relevant information\n    and THEN aggregating, we are instead aggregating from the beginning and then \n    joining downstream for performance. Additionally, we're using a subquery instead \n    of a CTE, which was significantly more performant during our testing. -#}\n    {#- #}\n    select\n\n        {%- if grain %}\n        date_{{grain}},\n\n        {#- All of the other relevant periods that aren't currently selected as the grain\n        are neccesary for downstream secondary calculations. We filter it on whether \n        there are secondary calculations to reduce the need for overhead -#}\n            {%- if secondary_calculations | length > 0 -%}\n                {%- for period in relevant_periods %}\n        date_{{ period }},\n                {%- endfor -%}\n            {% endif -%}\n        {%- endif -%}\n\n        {#- This is the consistent code you'll find that loops through the list of \n        dimensions. It is used throughout this macro, with slight differences to \n        account for comma syntax around loop last -#}\n        {%- for dim in dimensions %}\n        {{ dim }},\n        {%- endfor %}\n\n        {%- for calendar_dim in calendar_dimensions %}\n        {{ calendar_dim }},\n        {% endfor -%}\n\n        {%- if grain %}\n        {{ bool_or('metric_date_day is not null') }} as has_data,\n        {%- endif %}\n\n        {#- This line performs the relevant aggregation by calling the \n        gen_primary_metric_aggregate macro. Take a look at that one if you're curious -#}\n        {%- for metric_name in group_values.metric_names -%} \n        {{ metrics.gen_primary_metric_aggregate(metrics_dictionary[metric_name].calculation_method, 'property_to_aggregate__'~metric_name) }} as {{ metric_name }}\n        {%- if not loop.last -%},{%- endif -%}\n        {%- endfor%}\n    from ({{ metrics.gen_base_query(\n                metrics_dictionary=metrics_dictionary,\n                grain=grain, \n                dimensions=dimensions, \n                secondary_calculations=secondary_calculations, \n                start_date=start_date, \n                end_date=end_date, \n                relevant_periods=relevant_periods, \n                calendar_dimensions=calendar_dimensions,\n                total_dimension_count=total_dimension_count,\n                group_name=group_name,\n                group_values=group_values\n                )\n            }}\n    ) as base_query\n\n    where 1=1\n    {#- \n        Given that we've already determined the metrics in metric_names share\n        the same windows & filters, we can base the conditional off of the first \n        value in the list because the order doesn't matter. \n     -#}\n    {%- if group_values.window is not none and grain %}\n    and date_{{grain}} = window_filter_date\n    {%- endif %}\n    {{ metrics.gen_group_by(grain, dimensions, calendar_dimensions, relevant_periods) }}\n\n)\n\n{%- endmacro -%}\n", "hash": "7ed7947b716d9dbde655d8fd13e8681d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_aggregate_cte.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_property_to_aggregate.sql": {"contents": "{%- macro gen_property_to_aggregate(metric_dictionary, grain, dimensions, calendar_dimensions) -%}\n    {{ return(adapter.dispatch('gen_property_to_aggregate', 'metrics')(metric_dictionary, grain, dimensions, calendar_dimensions)) }}\n{%- endmacro -%}\n\n{% macro default__gen_property_to_aggregate(metric_dictionary, grain, dimensions, calendar_dimensions) %}\n    {% if metric_dictionary.calculation_method == 'median' -%}\n        {{ return(adapter.dispatch('property_to_aggregate_median', 'metrics')(metric_dictionary, grain, dimensions, calendar_dimensions)) }}\n\n    {% elif metric_dictionary.calculation_method == 'count' -%}\n        {{ return(adapter.dispatch('property_to_aggregate_count', 'metrics')(metric_dictionary)) }}\n\n    {% elif metric_dictionary.expression and metric_dictionary.expression | replace('*', '') | trim != '' %}\n        {{ return(adapter.dispatch('property_to_aggregate_default', 'metrics')(metric_dictionary)) }}\n\n    {% else %}\n        {%- do exceptions.raise_compiler_error(\"Expression to aggregate is required for non-count aggregation in metric `\" ~ metric_dictionary.name ~ \"`\") -%}  \n    {% endif %}\n\n{%- endmacro -%}\n\n{% macro default__property_to_aggregate_median(metric_dictionary, grain, dimensions, calendar_dimensions) %}\n            ({{metric_dictionary.expression }}) as property_to_aggregate__{{metric_dictionary.name}}\n{%- endmacro -%}\n\n{% macro bigquery__property_to_aggregate_median(metric_dictionary, grain, dimensions, calendar_dimensions) %}\n\n            percentile_cont({{metric_dictionary.expression }}, 0.5) over (\n                {% if grain or dimensions | length > 0 or calendar_dimensions | length > 0 -%}\n                partition by \n                {% if grain -%}\n                calendar.date_{{ grain }}\n                {%- endif %}\n                {% for dim in dimensions -%}\n                    {%- if loop.first and not grain-%}\n                base_model.{{ dim }}\n                    {%- else -%}\n                ,base_model.{{ dim }}\n                    {%- endif -%}\n                {%- endfor -%}\n                {% for calendar_dim in calendar_dimensions -%}\n                    {%- if loop.first and dimensions | length == 0 and not grain %}\n                calendar.{{ calendar_dim }}\n                    {%else -%}\n                ,calendar.{{ calendar_dim }}\n                    {%- endif -%}\n                {%- endfor %}\n                {%- endif %}\n            ) as property_to_aggregate__{{metric_dictionary.name}}\n\n{%- endmacro -%}\n\n{% macro default__property_to_aggregate_count(metric_dictionary) %}\n            1 as property_to_aggregate__{{metric_dictionary.name}}\n{%- endmacro -%}\n\n{% macro default__property_to_aggregate_default(metric_dictionary) %}\n            ({{metric_dictionary.expression }}) as property_to_aggregate__{{metric_dictionary.name}}\n{%- endmacro -%}", "hash": "18846ad32589dee05dffa720009a5bb7", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_property_to_aggregate.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_primary_metric_aggregate.sql": {"contents": "\n{%- macro gen_primary_metric_aggregate(aggregate, expression) -%}\n    {{ return(adapter.dispatch('gen_primary_metric_aggregate', 'metrics')(aggregate, expression)) }}\n{%- endmacro -%}\n\n{%- macro default__gen_primary_metric_aggregate(aggregate, expression) -%}\n\n    {%- if aggregate == 'count' -%}\n        {{ return(adapter.dispatch('metric_count', 'metrics')(expression)) }}\n    \n    {%- elif aggregate == 'count_distinct' -%}\n        {{ return(adapter.dispatch('metric_count_distinct', 'metrics')(expression)) }}\n    \n    {%- elif aggregate == 'average' -%}\n        {{ return(adapter.dispatch('metric_average', 'metrics')(expression)) }}\n    \n    {%- elif aggregate == 'max' -%}\n        {{ return(adapter.dispatch('metric_max', 'metrics')(expression)) }}\n       \n    {%- elif aggregate == 'min' -%}\n        {{ return(adapter.dispatch('metric_min', 'metrics')(expression)) }}\n    \n    {%- elif aggregate == 'sum' -%}\n        {{ return(adapter.dispatch('metric_sum', 'metrics')(expression)) }}\n\n    {%- elif aggregate == 'median' -%}\n        {{ return(adapter.dispatch('metric_median', 'metrics')(expression)) }}\n\n    {%- elif aggregate == 'derived' -%}\n        {{ return(adapter.dispatch('metric_derived', 'metrics')(expression)) }}\n\n    {%- else -%}\n        {%- do exceptions.raise_compiler_error(\"Unknown aggregation style: \" ~ aggregate) -%}  \n    {%- endif -%}\n{%- endmacro -%}\n\n{% macro default__metric_count(expression) %}\n        count({{ expression }})\n{%- endmacro -%}\n\n{% macro default__metric_count_distinct(expression) %}\n        count(distinct {{ expression }})\n{%- endmacro -%}\n\n{% macro default__metric_average(expression) %}\n        avg({{ expression }})\n{%- endmacro -%}\n\n{% macro redshift__metric_average(expression) %}\n        avg(cast({{ expression }} as float))\n{%- endmacro -%}\n\n{% macro default__metric_max(expression) %}\n        max({{ expression }})\n{%- endmacro -%}\n\n{% macro default__metric_min(expression) %}\n        min({{ expression }})\n{%- endmacro -%}\n\n{% macro default__metric_sum(expression) %}\n        sum({{ expression }})\n{%- endmacro -%}\n\n{% macro default__metric_median(expression) %}\n        median({{ expression }})\n{%- endmacro -%}\n\n{% macro bigquery__metric_median(expression) %}\n        any_value({{ expression }})\n{%- endmacro -%}\n\n{% macro postgres__metric_median(expression) %}\n        percentile_cont(0.5) within group (order by {{ expression }})\n{%- endmacro -%}\n\n{% macro default__metric_derived(expression) %}\n        {{ expression }}\n{%- endmacro -%}", "hash": "f9d3d77be472bb9a82d86a042fc53b1a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_primary_metric_aggregate.sql"}, "dbt_packages/metrics/macros/sql_gen/gen_joined_metrics_cte.sql": {"contents": "{%- macro gen_joined_metrics_cte(metric_tree, metrics_dictionary, models_grouping, grain, dimensions, calendar_dimensions, secondary_calculations, relevant_periods, total_dimension_count) -%}\n    {{ return(adapter.dispatch('gen_joined_metrics_cte', 'metrics')(metric_tree, metrics_dictionary, models_grouping, grain, dimensions, calendar_dimensions, secondary_calculations, relevant_periods, total_dimension_count)) }}\n{%- endmacro -%}\n\n{% macro default__gen_joined_metrics_cte(metric_tree, metrics_dictionary, models_grouping, grain, dimensions, calendar_dimensions, secondary_calculations, relevant_periods, total_dimension_count) %}\n\n{#- This section is a hacky workaround to account for postgres changes -#}\n{%- set cte_numbers = [] -%}\n{%- set unique_cte_numbers = [] -%}\n{#- the cte numbers are more representative of node depth -#}\n{%- if metric_tree.derived_set | length > 0 -%}\n    {%- for metric_name in metric_tree.ordered_derived_set -%}\n        {%- do cte_numbers.append(metric_tree.ordered_derived_set[metric_name]) -%}\n    {%- endfor -%}\n    {%- for cte_num in cte_numbers|unique -%}\n        {%- do unique_cte_numbers.append(cte_num) -%}\n    {%- endfor -%}\n{%- endif -%}\n\n{%- set dimension_count = (dimensions | length + calendar_dimensions | length) | int %}\n, first_join_metrics as (\n\n    select\n        {% if grain -%}\n        date_{{grain}},\n        {%- endif -%}\n        {%- for calendar_dim in calendar_dimensions %}\n        coalesce(\n        {%- for group_name, group_values in models_grouping.items() %}\n                {{group_name}}__final.{{ calendar_dim }}{%- if not loop.last -%},{% endif %}\n                {%- if models_grouping | length == 1 -%}\n                , NULL\n                {%- endif -%}\n            {% endfor %}\n            ) as {{calendar_dim}},\n        {% endfor %}\n    {%- for period in relevant_periods %}\n        coalesce(\n        {%- for group_name, group_values in models_grouping.items() %}\n            {{group_name}}__final.date_{{ period }} {%- if not loop.last -%},{% endif %}\n            {%- if models_grouping | length == 1 %}\n            , NULL\n            {%- endif -%}\n        {% endfor %}\n        ) as date_{{period}},\n    {%- endfor %}\n    {%- for dim in dimensions %}\n        coalesce(\n        {%- for group_name, group_values in models_grouping.items() %}\n            {{group_name}}__final.{{ dim }} {%- if not loop.last -%},{% endif %}\n            {%- if models_grouping | length == 1 %}\n            , NULL\n            {%- endif -%}\n        {% endfor %}\n        ) as {{dim}},\n    {%- endfor %}\n\n    {%- for metric_name in metric_tree.parent_set %}\n        {%- if not metrics_dictionary[metric_name].config.get(\"treat_null_values_as_zero\", True) %}\n        {{metric_name}} as {{metric_name}} {%- if not loop.last -%}, {%- endif -%}\n        {%- else  %}  \n        coalesce({{metric_name}},0) as {{metric_name}} {%- if not loop.last -%}, {%- endif -%}\n        {%- endif %}  \n    {%- endfor %}  \n    {#- Loop through leaf metric list -#}\n    {% for group_name, group_values in models_grouping.items() %}\n        {%- if loop.first %}\n    from {{ group_name }}__final\n        {%- else %}\n            {%- if grain %}\n    full outer join {{group_name}}__final\n        using (\n            date_{{grain}}\n            {%- for calendar_dim in calendar_dimensions %}\n            , {{ calendar_dim }}\n            {% endfor %}\n            {%- for dim in dimensions %}\n            , {{ dim }}\n            {%- endfor %}\n        )\n            {%- else -%}\n                {% if dimension_count != 0 %}\n    full outer join {{group_name}}__final\n        using (\n            {%- for calendar_dim in calendar_dimensions -%}\n                {%- if not loop.first -%},{%- endif -%} {{ calendar_dim }}\n            {%- endfor -%}\n            \n            {%- for dim in dimensions %}\n                {%- if loop.first and calendar_dimensions | length == 0 -%}\n            {{ dim }}\n                {%- elif not loop.first and calendar_dimensions | length == 0 -%}\n            , {{ dim }}\n                {%- else -%}\n            , {{ dim }}\n                {%- endif -%}\n            {%- endfor -%}\n        )\n                {%- elif dimension_count == 0 %}\n    cross join {{group_name}}__final\n                {%- endif %}\n            {%- endif %}\n        {%- endif -%}\n    {%- endfor %} \n{# #}\n)\n\n{%- for cte_number in cte_numbers | unique | sort %}\n{% set previous_cte_number = cte_number - 1 %}\n, join_metrics__{{cte_number}} as (\n\n    select \n    {%- if loop.first %}\n        first_join_metrics.*\n    {%- else %}\n        join_metrics__{{previous_cte_number}}.*\n    {%- endif %}\n    {%- for metric_name in metric_tree.derived_set %}\n        {%- if metric_tree.ordered_derived_set[metric_name] == cte_number %}\n            {#- this logic will parse an expression for divisions signs (/) and wrap all divisors in nullif functions to prevent divide by zero -#}\n            {#- \"1 / 2 / 3 / ... / N\" results in \"1 / nullif(2, 0) / nullif(3, 0) / ... / nullif(N, 0)\"  -#}\n            {%- set metric_expression = metrics_dictionary[metric_name].expression %}\n            {%- if \"/\" in metric_expression -%}\n                {%- set split_division_metric = metric_expression.split('/') -%}\n                {%- set dividend = split_division_metric[0] -%}\n                {%- set divisors = split_division_metric[1:] | list -%}\n                {%- set expression = dividend ~ \" / nullif(\" ~ divisors | join(\", 0) / nullif(\") ~ \", 0)\" -%}\n            {%- else -%}\n                {%- set expression = metric_expression -%}\n            {%- endif %}\n        , ({{ expression | replace(\".metric_value\",\"\") }}) as {{ metrics_dictionary[metric_name].name }}\n        {%- endif -%}\n    {%- endfor -%}\n    {% if loop.first %}\n    from first_join_metrics\n    {%- else %}\n    from join_metrics__{{previous_cte_number}}\n    {%- endif %}\n    {# #}\n)\n    \n{%- endfor %}\n\n, joined_metrics as (\n\n    select \n\n    {%- if grain %}\n        date_{{grain}},\n    {%- endif %}\n\n    {%- for period in relevant_periods %}\n        date_{{ period }},\n    {%- endfor %}\n\n    {%- for calendar_dim in calendar_dimensions %}\n        {{ calendar_dim }},\n    {%- endfor %}\n\n    {%- for dim in dimensions %}\n        {{ dim }},\n    {%- endfor %}\n\n    {%- for metric_name in metric_tree.parent_set|list + metric_tree.derived_set|list %}\n        {{metric_name}}{%- if not loop.last -%}, {%- endif -%}\n    {%- endfor %}  \n\n    {%- if metric_tree.derived_set | length == 0 %}\n    from first_join_metrics\n    {%- else %}\n    from join_metrics__999\n    {%- endif %}\n\n)\n\n{% endmacro %}", "hash": "3668c1bf3230c1b7bb2766a301351cb9", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/sql_gen/gen_joined_metrics_cte.sql"}, "dbt_packages/metrics/macros/secondary_calculations_configuration/period_over_period.sql": {"contents": "{% macro period_over_period(comparison_strategy, interval, alias, metric_list = []) %}\n\n    {% set missing_args = [] %}\n    {% if not comparison_strategy %}\n        {% set _ = missing_args.append(\"comparison_strategy\") %}\n    {% endif %}\n    {% if not interval %} \n        {% set _ = missing_args.append(\"interval\") %}\n    {% endif %}\n    {% if missing_args | length > 0 %}\n        {% do exceptions.raise_compiler_error( missing_args | join(\", \") ~ ' not provided to period_over_period') %}\n    {% endif %}\n    {% if metric_list is string %}\n        {% set metric_list = [metric_list] %}\n    {% endif %}\n\n    {% do return ({\n        \"calculation\": \"period_over_period\",\n        \"comparison_strategy\": comparison_strategy,\n        \"interval\": interval,\n        \"alias\": alias,\n        \"metric_list\": metric_list\n        })\n    %}\n{% endmacro %}", "hash": "fd8be3452f2b3f1eee1da7bb24b91120", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations_configuration/period_over_period.sql"}, "dbt_packages/metrics/macros/secondary_calculations_configuration/prior.sql": {"contents": "{% macro prior(interval, alias, metric_list = []) %}\n\n    {% set missing_args = [] %}\n    {% if not interval %} \n        {% set _ = missing_args.append(\"interval\") %}\n    {% endif %}\n    {% if missing_args | length > 0 %}\n        {% do exceptions.raise_compiler_error( missing_args | join(\", \") ~ ' not provided to prior') %}\n    {% endif %}\n    {% if metric_list is string %}\n        {% set metric_list = [metric_list] %}\n    {% endif %}\n\n    {% do return ({\n        \"calculation\": \"prior\",\n        \"interval\": interval,\n        \"alias\": alias,\n        \"metric_list\": metric_list\n        })\n    %}\n{% endmacro %}", "hash": "ed64d3de5b2ab7d9122531e146740c63", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations_configuration/prior.sql"}, "dbt_packages/metrics/macros/secondary_calculations_configuration/period_to_date.sql": {"contents": "{% macro period_to_date(aggregate, period, alias, metric_list = []) %}\n\n    {% set missing_args = [] %}\n    {% if not aggregate %} \n        {% set _ = missing_args.append(\"aggregate\") %}\n    {% endif %}\n    {% if not period %}\n        {% set _ = missing_args.append(\"period\") %}\n    {% endif %}\n    {% if missing_args | length > 0 %}\n        {% do exceptions.raise_compiler_error( missing_args | join(\", \") ~ ' not provided to period_to_date') %}\n    {% endif %}\n    {% if metric_list is string %}\n        {% set metric_list = [metric_list] %}\n    {% endif %}\n\n    {% do return ({\n        \"calculation\": \"period_to_date\",\n        \"aggregate\": aggregate,\n        \"period\": period,\n        \"alias\": alias,\n        \"metric_list\": metric_list\n        })\n    %}\n{% endmacro %}", "hash": "856604b2f150076e7758b92a2628c950", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations_configuration/period_to_date.sql"}, "dbt_packages/metrics/macros/secondary_calculations_configuration/rolling.sql": {"contents": "{% macro rolling(aggregate, interval, alias, metric_list=[]) %}\n\n    {% set missing_args = [] %}\n    {% if not aggregate %} \n        {% set _ = missing_args.append(\"aggregate\") %}\n    {% endif %}\n    {% if missing_args | length > 0 %}\n        {% do exceptions.raise_compiler_error( missing_args | join(\", \") ~ ' not provided to rolling') %}\n    {% endif %}\n    {% if metric_list is string %}\n        {% set metric_list = [metric_list] %}\n    {% endif %}\n\n    {% do return ({\n        \"calculation\": \"rolling\",\n        \"aggregate\": aggregate,\n        \"interval\": interval,\n        \"alias\": alias,\n        \"metric_list\": metric_list\n        })\n    %}\n{% endmacro %}", "hash": "6a4a7e67fd10ddc8293843c31cb8031e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/secondary_calculations_configuration/rolling.sql"}, "dbt_packages/metrics/macros/validation/is_valid_dimension.sql": {"contents": "{% macro is_valid_dimension(dim_name, dimension_list) %}\n    {% if execute %}\n        {%- if dim_name not in dimension_list -%}\n            {%- do exceptions.raise_compiler_error(dim_name ~ \" is not a valid dimension\") %}\n        {%- endif -%}\n    {% endif %}\n{% endmacro %}", "hash": "2470d9967a9040df58c9dea26ed1d65f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/is_valid_dimension.sql"}, "dbt_packages/metrics/macros/validation/validate_where.sql": {"contents": "{% macro validate_where(where) %}\n\n    {%- if where is iterable and (where is not string and where is not mapping) -%}\n        {%- do exceptions.raise_compiler_error(\"From v0.3.0 onwards, the where clause takes a single string, not a list of filters. Please fix to reflect this change\") %}\n    {%- endif -%}\n\n{% endmacro %}", "hash": "efc036d1c7008af0256ad2d615fcee89", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_where.sql"}, "dbt_packages/metrics/macros/validation/validate_aggregate_coherence.sql": {"contents": "{% macro validate_aggregate_coherence(metric_aggregate, calculation_aggregate) %}\n    {% set allowlist = metrics.get_metric_allowlist()[metric_aggregate] %}\n\n    {% if (calculation_aggregate not in allowlist) %}\n        {% do exceptions.raise_compiler_error(\"Can't calculate secondary aggregate \" ~ calculation_aggregate ~ \" when metric's aggregation is \" ~ metric_aggregate ~ \". Allowed options are \" ~ allowlist ~ \".\") %}\n    {% endif %}\n{% endmacro %}", "hash": "cad926a1a22ff685bb73180243b21905", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_aggregate_coherence.sql"}, "dbt_packages/metrics/macros/validation/validate_secondary_calculations.sql": {"contents": "{% macro validate_secondary_calculations(metric_tree, metrics_dictionary, grain, secondary_calculations) %}\n\n\n    {%- for metric_name in metric_tree.base_set %}\n        {%- for calc_config in secondary_calculations if calc_config.aggregate -%}\n            {%- do metrics.validate_aggregate_coherence(metric_aggregate=metrics_dictionary[metric_name].calculation_method, calculation_aggregate=calc_config.aggregate) -%}\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- for calc_config in secondary_calculations if calc_config.period -%}\n        {%- do metrics.validate_grain_order(metric_grain=grain, calculation_grain=calc_config.period) -%}\n    {%- endfor -%} \n\n{% endmacro %}", "hash": "bc5b8711801e8278f6177647b1076647", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_secondary_calculations.sql"}, "dbt_packages/metrics/macros/validation/validate_derived_metrics.sql": {"contents": "{% macro validate_derived_metrics(metric_tree) %}\n\n    {# We loop through the full set here to ensure that metrics that aren't listed \n    as derived are not dependent on another metric.  #}\n\n    {% for metric_name in metric_tree.full_set %}\n        {% set metric_relation = metric(metric_name)%}\n        {% set metric_relation_depends_on = metric_relation.metrics  | join (\",\") %}\n        {% if metric_relation.calculation_method != \"derived\" and metric_relation.metrics | length > 0 %}\n            {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric_relation.name ~\" also references '\" ~ metric_relation_depends_on ~ \"' but its calculation method is '\" ~ metric_relation.calculation_method ~ \"'. Only metrics of calculation method derived can reference other metrics.\") %}\n        {%- endif %}\n    {% endfor %}\n\n{% endmacro %}", "hash": "7df92240b4e56d81e0d6cc5cc4988f71", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_derived_metrics.sql"}, "dbt_packages/metrics/macros/validation/validate_develop_metrics.sql": {"contents": "{% macro validate_develop_metrics(metric_list, develop_yml) %}\n\n   {% for metric_name in metric_list %}\n        {% set metric_definition = develop_yml[metric_name] %}\n\n        {%- if not metric_definition.name %}\n            {%- do exceptions.raise_compiler_error(\"The provided yml is missing a metric name\") -%}\n        {%- endif %}\n\n        {%- if not metric_definition.calculation_method %}\n            {%- do exceptions.raise_compiler_error(\"The provided yml for metric \" ~ metric_definition.name ~ \" is missing a calculation method\") -%}\n        {%- endif %}\n\n        {%- if not metric_definition.model and metric_definition.calculation_method != 'derived' %}\n            {%- do exceptions.raise_compiler_error(\"The provided yml for metric \" ~ metric_definition.name ~ \" is missing a model\") -%}\n        {%- endif %}\n\n        {%- if metric_definition.time_grains and grain %}\n            {%- if grain not in metric_definition.time_grains %}\n            {%- do exceptions.raise_compiler_error(\"The selected grain is missing from the metric definition of metric \" ~ metric_definition.name ) -%}\n            {%- endif %}\n        {%- endif %}\n\n        {%- if not metric_definition.expression %}\n            {%- do exceptions.raise_compiler_error(\"The provided yml for metric \" ~ metric_definition.name ~ \" is missing an expression\") -%}\n        {%- endif %}\n\n    {%- endfor -%}\n\n{% endmacro %}", "hash": "535b03ad70c82927216a8f966bef93ac", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_develop_metrics.sql"}, "dbt_packages/metrics/macros/validation/validate_grain_order.sql": {"contents": "{% macro validate_grain_order(metric_grain, calculation_grain) %}\n    {% set grains = metrics.get_grain_order() %}\n    \n    {% if metric_grain not in grains or calculation_grain not in grains %}\n        {% set comma = joiner(\", \") %}\n        {% do exceptions.raise_compiler_error(\"Unknown grains: [\" ~ (comma() ~ metric_grain if metric_grain not in grains) ~ (comma() ~ calculation_grain if calculation_grain not in grains) ~ \"]\") %}\n    {% endif %}\n\n    {% set metric_grain_index = grains.index(metric_grain) %}\n    {% set calculation_grain_index = grains.index(calculation_grain) %}\n\n    {% if (calculation_grain_index < metric_grain_index) %}\n        {% do exceptions.raise_compiler_error(\"Can't calculate secondary metric at \" ~ calculation_grain ~\"-level when metric is at \" ~ metric_grain ~ \"-level\") %}\n    {% endif %}\n{% endmacro %}", "hash": "996f908e3dffba2e1a2fb906a43766ce", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_grain_order.sql"}, "dbt_packages/metrics/macros/validation/validate_timestamp.sql": {"contents": "{% macro validate_timestamp(grain, metric_tree, metrics_dictionary, dimensions) %}\n\n    {# We check the metrics being used and if there is no grain we ensure that \n    none of the dimensions provided are from the calendar #}\n    {% if not grain %}\n        {%- if metrics.get_calendar_dimensions(dimensions) | length > 0 -%}\n\n        {% for metric_name in metric_tree.full_set %}\n            {% set metric_relation = metrics_dictionary[metric_name]%}\n            {% if not metric_relation.timestamp %}\n                {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric_name ~ \" is using a calendar dimension but does not have a timestamp defined.\") %}\n            {% endif %}\n        {% endfor %}\n\n        {% endif %}\n    {% endif %}\n\n{% endmacro %}", "hash": "5b2b1f3d166cb43e9504c1b28f280865", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_timestamp.sql"}, "dbt_packages/metrics/macros/validation/validate_dimension_list.sql": {"contents": "{% macro validate_dimension_list(dimensions, metric_tree, metrics_dictionary) %}\n    \n    {# This macro exists to invalidate dimensions provided to the metric macro that are not viable \n    candidates based on metric definitions. This prevents downstream run issues when the sql \n    logic attempts to group by provided dimensions and fails because they don't exist for \n    one or more of the required metrics. #}\n\n    {% set calendar_dimensions = var('custom_calendar_dimension_list',[]) %}\n\n    {% for dim in dimensions %}\n\n        {# Now we loop through all the metrics in the full set, which is all metrics, parent metrics,\n        and derived metrics associated with the macro call #}\n        {% for metric_name in metric_tree.full_set %}\n            {% set metric_relation = metrics_dictionary[metric_name]%}\n\n            {# This macro returns a list of dimensions that are inclusive of calendar dimensions #}\n            {% set complete_dimension_list = metric_relation.dimensions + calendar_dimensions %}\n\n            {# If the dimension provided is not present in the loop metrics dimension list then we \n            will raise an error. If it is missing in ANY of the metrics, it cannot be used in the \n            macro call. Only dimensions that are valid in all metrics are valid in the macro call #}\n            {% if dim not in complete_dimension_list %}\n                {% if dim not in calendar_dimensions  %}\n                    {% do exceptions.raise_compiler_error(\"The dimension \" ~ dim ~ \" is not part of the metric \" ~ metric_relation.name) %}\n                {% else %}\n                    {% do exceptions.raise_compiler_error(\"The dimension \" ~ dim ~ \" is not part of the metric \" ~ metric_relation.name ~ \". If the dimension is from a custom calendar table, please create the custom_calendar_dimension_list as shown in the README.\") %}\n                {% endif %}\n            {% endif %}\n\n        {%endfor%}\n    {%endfor%}\n\n{% endmacro %}", "hash": "a6d57d5091a55e09cf0b3193f88c07fe", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_dimension_list.sql"}, "dbt_packages/metrics/macros/validation/validate_metric_config.sql": {"contents": "{%- macro validate_metric_config(metrics_dictionary) -%}\n\n    {#- We loop through the metrics dictionary here to ensure that\n    1) all configs are real configs we know about\n    2) all of those have valid values passed\n    returned or used, not just those listed -#}\n\n    {%- set accepted_configs = {\n        \"enabled\" : {\"accepted_values\" : [True, False]},\n        \"treat_null_values_as_zero\" : {\"accepted_values\" : [True, False]},\n        \"restrict_no_time_grain\" : {\"accepted_values\" : [True, False]}\n        }\n    -%}\n\n    {%- for metric in metrics_dictionary -%}\n        {%- set metric_config = metrics_dictionary[metric].get(\"config\", none) -%}\n        {%- if metric_config -%}\n            {%- for config in metric_config -%}\n                {%- set config_value = metric_config[config] -%}\n                {#- some wonkiness here -- metric_config is not a dictionary, it's a MetricConfig object, so can't use the items() method -#}\n                {#- check that the config is one that we expect -#}\n                {%- if not accepted_configs[config] -%}\n                    {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric ~ \" has an invalid config option. The config '\" ~ config ~ \"' is not accepted.\") -%}\n                {%- endif -%}\n                {#- check that the config datatype is expected -#}\n                {%- if accepted_configs[config] -%}\n                    {%- set accepted_values = accepted_configs[config][\"accepted_values\"] -%}\n                    {%- if not config_value in accepted_values -%}\n                        {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric ~ \" has an invalid config value specified. The config '\" ~ config ~ \"' expects one of \" ~ accepted_values) -%}\n                    {%- endif -%}\n                {% endif %}\n            {%- endfor %}\n        {%- endif -%}\n    {%- endfor %}\n            \n\n\n{%- endmacro -%}", "hash": "68f1a628b64ae4c7ad12534e03ac6e4e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_metric_config.sql"}, "dbt_packages/metrics/macros/validation/validate_grain.sql": {"contents": "{% macro validate_grain(grain, metric_tree, metrics_dictionary, secondary_calculations, dimensions) %}\n\n    {# We loop through the full set here to ensure that the provided grain works for all metrics\n    returned or used, not just those listed #}\n    {% if grain %}\n        {%- if not grain and secondary_calculations | length > 0 -%}\n            {%- do exceptions.raise_compiler_error(\"Secondary calculations require a grain to be provided\") -%}\n        {%- endif -%}\n\n\n        {% for metric_name in metric_tree.full_set %}\n            {% set metric_relation = metrics_dictionary[metric_name]%}\n\n            {% if grain not in metric_relation.time_grains%}\n                {% if metric_name not in metric_tree.base_set %}\n                    {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric_name ~ \" is an upstream metric of one of the provided metrics. The grain \" ~ grain ~ \" is not defined in its metric definition.\") %}\n                {% else %}\n                    {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric_name ~ \" does not have the provided time grain \" ~ grain ~ \" defined in the metric definition.\") %}\n                {% endif %}\n            {% endif %}\n        {% endfor %}\n\n    {% elif not grain %}\n        {% for metric_name in metric_tree.full_set %}\n            {% set metric_relation = metrics_dictionary[metric_name]%}\n            {% if metric_relation.get(\"config\").get(\"restrict_no_time_grain\", False) == True %}\n                {% if metric_name not in metric_tree.base_set %}\n                    {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric_relation.name ~ \" is an upstream metric of one of the provided metrics and has been configured to not allow non time-grain queries.\") %}\n                {% else %}\n                    {%- do exceptions.raise_compiler_error(\"The metric \" ~ metric_relation.name ~ \" has been configured to not allow non time-grain queries.\") %}\n                {% endif %}\n            {% endif %}\n\n        {% endfor %}\n\n        {% if secondary_calculations | length > 0 %}\n            {%- do exceptions.raise_compiler_error(\"Using secondary calculations without a grain is not supported.\") %}\n        {% endif %}\n\n        {% for metric_name in metric_tree.full_set %}\n            {% if metrics_dictionary[metric_name].window is not none%}\n                {%- do exceptions.raise_compiler_error(\"Aggregating without a grain does not support metrics with window definitions.\") %}\n            {% endif%}\n        {% endfor%}\n\n    {% endif %}\n\n{% endmacro %}", "hash": "50d47a577ce8da811ee46e79ed6b209e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/metrics/macros/validation/validate_grain.sql"}, "dbt_packages/dbt_utils/dbt_project.yml": {"contents": "name: 'dbt_utils'\nversion: '0.1.0'\n\nrequire-dbt-version: [\">=1.3.0\", \"<2.0.0\"]\n\nconfig-version: 2\n\ntarget-path: \"target\"\nclean-targets: [\"target\", \"dbt_modules\", \"dbt_packages\"]\nmacro-paths: [\"macros\"]\nlog-path: \"logs\"\n", "hash": "58ef8ee2434e0f78b806066298beb0ef", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/dbt_project.yml"}, "dbt_packages/dbt_utils/tests/conftest.py": {"contents": "import pytest\nimport os\n\npytest_plugins = [\"dbt.tests.fixtures.project\"]\n\n\ndef pytest_addoption(parser):\n    parser.addoption(\"--profile\", action=\"store\", default=\"postgres\", type=str)\n\n\n# Using @pytest.mark.skip_profile('postgres') uses the 'skip_by_profile_type'\n# autouse fixture below\ndef pytest_configure(config):\n    config.addinivalue_line(\n        \"markers\",\n        \"skip_profile(profile): skip test for the given profile\",\n    )\n    config.addinivalue_line(\n        \"markers\",\n        \"only_profile(profile): only test the given profile\",\n    )\n\n\n@pytest.fixture(scope=\"session\")\ndef dbt_profile_target(request):\n    profile_type = request.config.getoption(\"--profile\")\n    if profile_type == \"postgres\":\n        target = postgres_target()\n    elif profile_type == \"redshift\":\n        target = redshift_target()\n    elif profile_type == \"snowflake\":\n        target = snowflake_target()\n    elif profile_type == \"bigquery\":\n        target = bigquery_target()\n    else:\n        raise ValueError(f\"Invalid profile type '{profile_type}'\")\n    return target\n\n\ndef postgres_target():\n    return {\n        \"type\": \"postgres\",\n        \"host\": os.getenv('POSTGRES_TEST_HOST'),\n        \"user\": os.getenv('POSTGRES_TEST_USER'),\n        \"pass\": os.getenv('POSTGRES_TEST_PASS'),\n        \"port\": int(os.getenv('POSTGRES_TEST_PORT')),\n        \"dbname\": os.getenv('POSTGRES_TEST_DBNAME'),\n    }\n\n\ndef redshift_target():\n    return {\n        \"type\": \"redshift\",\n        \"host\": os.getenv('REDSHIFT_TEST_HOST'),\n        \"user\": os.getenv('REDSHIFT_TEST_USER'),\n        \"pass\": os.getenv('REDSHIFT_TEST_PASS'),\n        \"port\": int(os.getenv('REDSHIFT_TEST_PORT')),\n        \"dbname\": os.getenv('REDSHIFT_TEST_DBNAME'),\n    }\n\n\ndef bigquery_target():\n    return {\n        \"type\": \"bigquery\",\n        \"method\": \"service-account\",\n        \"keyfile\": os.getenv('BIGQUERY_SERVICE_KEY_PATH'),\n        \"project\": os.getenv('BIGQUERY_TEST_DATABASE'),\n    }\n\n\ndef snowflake_target():\n    return {\n        \"type\": \"snowflake\",\n        \"account\": os.getenv('SNOWFLAKE_TEST_ACCOUNT'),\n        \"user\": os.getenv('SNOWFLAKE_TEST_USER'),\n        \"password\": os.getenv('SNOWFLAKE_TEST_PASSWORD'),\n        \"role\": os.getenv('SNOWFLAKE_TEST_ROLE'),\n        \"database\": os.getenv('SNOWFLAKE_TEST_DATABASE'),\n        \"warehouse\": os.getenv('SNOWFLAKE_TEST_WAREHOUSE'),\n    }\n\n\n@pytest.fixture(autouse=True)\ndef skip_by_profile_type(request):\n    profile_type = request.config.getoption(\"--profile\")\n    if request.node.get_closest_marker(\"skip_profile\"):\n        for skip_profile_type in request.node.get_closest_marker(\"skip_profile\").args:\n            if skip_profile_type == profile_type:\n                pytest.skip(\"skipped on '{profile_type}' profile\")\n\n\n@pytest.fixture(autouse=True)\ndef only_profile_type(request):\n    profile_type = request.config.getoption(\"--profile\")\n    if request.node.get_closest_marker(\"only_profile\"):\n        for only_profile_type in request.node.get_closest_marker(\"only_profile\").args:\n            if only_profile_type != profile_type:\n                pytest.skip(\"skipped on '{profile_type}' profile\")\n", "hash": "355a4c4818024c7a8f7e7e63f7974a43", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/tests/conftest.py"}, "dbt_packages/dbt_utils/tests/__init__.py": {"contents": "", "hash": "d41d8cd98f00b204e9800998ecf8427e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/tests/__init__.py"}, "dbt_packages/dbt_utils/macros/web/get_url_host.sql": {"contents": "{% macro get_url_host(field) -%}\n    {{ return(adapter.dispatch('get_url_host', 'dbt_utils')(field)) }}\n{% endmacro %}\n\n{% macro default__get_url_host(field) -%}\n\n{%- set parsed =\n    dbt.split_part(\n        dbt.split_part(\n            dbt.replace(\n                dbt.replace(\n                    dbt.replace(field, \"'android-app://'\", \"''\"\n                    ), \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n\n-%}\n\n\n    {{ dbt.safe_cast(\n        parsed,\n        dbt.type_string()\n        )}}\n\n{%- endmacro %}\n", "hash": "bc0fb9b58cf58ca6dee2e24aeacf3087", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/web/get_url_host.sql"}, "dbt_packages/dbt_utils/macros/web/get_url_path.sql": {"contents": "{% macro get_url_path(field) -%}\n    {{ return(adapter.dispatch('get_url_path', 'dbt_utils')(field)) }}\n{% endmacro %}\n\n{% macro default__get_url_path(field) -%}\n\n    {%- set stripped_url =\n        dbt.replace(\n            dbt.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{ dbt.position(\"'/'\", stripped_url) }}, 0),\n            {{ dbt.position(\"'?'\", stripped_url) }} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt.split_part(\n            dbt.right(\n                stripped_url,\n                dbt.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ),\n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt.safe_cast(\n        parsed_path,\n        dbt.type_string()\n    )}}\n\n{%- endmacro %}\n", "hash": "4c632431a5b5ae59259a6aae3c43dcec", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/web/get_url_path.sql"}, "dbt_packages/dbt_utils/macros/web/get_url_parameter.sql": {"contents": "{% macro get_url_parameter(field, url_parameter) -%}\n    {{ return(adapter.dispatch('get_url_parameter', 'dbt_utils')(field, url_parameter)) }}\n{% endmacro %}\n\n{% macro default__get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt.split_part(dbt.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}\n", "hash": "819784449956cd36fc2e9f37106ecb55", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/web/get_url_parameter.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/fewer_rows_than.sql": {"contents": "{% test fewer_rows_than(model, compare_model, group_by_columns = []) %}\n  {{ return(adapter.dispatch('test_fewer_rows_than', 'dbt_utils')(model, compare_model, group_by_columns)) }}\n{% endtest %}\n\n{% macro default__test_fewer_rows_than(model, compare_model, group_by_columns) %}\n\n{{ config(fail_calc = 'sum(coalesce(row_count_delta, 0))') }}\n\n{% if group_by_columns|length() > 0 %}\n  {% set select_gb_cols = group_by_columns|join(' ,') + ', ' %}\n  {% set join_gb_cols %}\n    {% for c in group_by_columns %}\n      and a.{{c}} = b.{{c}}\n    {% endfor %}\n  {% endset %}\n  {% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n{% endif %}\n\n{#-- We must add a fake join key in case additional grouping variables are not provided --#}\n{#-- Redshift does not allow for dynamically created join conditions (e.g. full join on 1 = 1 --#}\n{#-- The same logic is used in equal_rowcount. In case of changes, maintain consistent logic --#}\n{% set group_by_columns = ['id_dbtutils_test_fewer_rows_than'] + group_by_columns %}\n{% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n\n\nwith a as (\n\n    select \n      {{select_gb_cols}}\n      1 as id_dbtutils_test_fewer_rows_than,\n      count(*) as count_our_model \n    from {{ model }}\n    {{ groupby_gb_cols }}\n\n),\nb as (\n\n    select \n      {{select_gb_cols}}\n      1 as id_dbtutils_test_fewer_rows_than,\n      count(*) as count_comparison_model \n    from {{ compare_model }}\n    {{ groupby_gb_cols }}\n\n),\ncounts as (\n\n    select\n\n        {% for c in group_by_columns -%}\n          a.{{c}} as {{c}}_a,\n          b.{{c}} as {{c}}_b,\n        {% endfor %}\n\n        count_our_model,\n        count_comparison_model\n    from a\n    full join b on \n    a.id_dbtutils_test_fewer_rows_than = b.id_dbtutils_test_fewer_rows_than\n    {{ join_gb_cols }}\n\n),\nfinal as (\n\n    select *,\n        case\n            -- fail the test if we have more rows than the reference model and return the row count delta\n            when count_our_model > count_comparison_model then (count_our_model - count_comparison_model)\n            -- fail the test if they are the same number\n            when count_our_model = count_comparison_model then 1\n            -- pass the test if the delta is positive (i.e. return the number 0)\n            else 0\n    end as row_count_delta\n    from counts\n\n)\n\nselect * from final\n\n{% endmacro %}\n", "hash": "c7a46537d8abd5c62a52c9fa2c6e1b9f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/fewer_rows_than.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/equal_rowcount.sql": {"contents": "{% test equal_rowcount(model, compare_model, group_by_columns = []) %}\n  {{ return(adapter.dispatch('test_equal_rowcount', 'dbt_utils')(model, compare_model, group_by_columns)) }}\n{% endtest %}\n\n{% macro default__test_equal_rowcount(model, compare_model, group_by_columns) %}\n\n{#-- Needs to be set at parse time, before we return '' below --#}\n{{ config(fail_calc = 'sum(coalesce(diff_count, 0))') }}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n{% if group_by_columns|length() > 0 %}\n  {% set select_gb_cols = group_by_columns|join(', ') + ', ' %}\n  {% set join_gb_cols %}\n    {% for c in group_by_columns %}\n      and a.{{c}} = b.{{c}}\n    {% endfor %}\n  {% endset %}\n  {% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n{% endif %}\n\n{#-- We must add a fake join key in case additional grouping variables are not provided --#}\n{#-- Redshift does not allow for dynamically created join conditions (e.g. full join on 1 = 1 --#}\n{#-- The same logic is used in fewer_rows_than. In case of changes, maintain consistent logic --#}\n{% set group_by_columns = ['id_dbtutils_test_equal_rowcount'] + group_by_columns %}\n{% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n\nwith a as (\n\n    select \n      {{select_gb_cols}}\n      1 as id_dbtutils_test_equal_rowcount,\n      count(*) as count_a \n    from {{ model }}\n    {{groupby_gb_cols}}\n\n\n),\nb as (\n\n    select \n      {{select_gb_cols}}\n      1 as id_dbtutils_test_equal_rowcount,\n      count(*) as count_b \n    from {{ compare_model }}\n    {{groupby_gb_cols}}\n\n),\nfinal as (\n\n    select\n    \n        {% for c in group_by_columns -%}\n          a.{{c}} as {{c}}_a,\n          b.{{c}} as {{c}}_b,\n        {% endfor %}\n\n        count_a,\n        count_b,\n        abs(count_a - count_b) as diff_count\n\n    from a\n    full join b\n    on\n    a.id_dbtutils_test_equal_rowcount = b.id_dbtutils_test_equal_rowcount\n    {{join_gb_cols}}\n\n\n)\n\nselect * from final\n\n{% endmacro %}\n", "hash": "410e3770c906626d3d37d4b0ca408f69", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/equal_rowcount.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/relationships_where.sql": {"contents": "{% test relationships_where(model, column_name, to, field, from_condition=\"1=1\", to_condition=\"1=1\") %}\n  {{ return(adapter.dispatch('test_relationships_where', 'dbt_utils')(model, column_name, to, field, from_condition, to_condition)) }}\n{% endtest %}\n\n{% macro default__test_relationships_where(model, column_name, to, field, from_condition=\"1=1\", to_condition=\"1=1\") %}\n\n{# T-SQL has no boolean data type so we use 1=1 which returns TRUE #}\n{# ref https://stackoverflow.com/a/7170753/3842610 #}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect * from exceptions\n\n{% endmacro %}\n", "hash": "25b03ddee99a0f595a3c4e940d818458", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/relationships_where.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/recency.sql": {"contents": "{% test recency(model, field, datepart, interval, ignore_time_component=False, group_by_columns = []) %}\n  {{ return(adapter.dispatch('test_recency', 'dbt_utils')(model, field, datepart, interval, ignore_time_component, group_by_columns)) }}\n{% endtest %}\n\n{% macro default__test_recency(model, field, datepart, interval, ignore_time_component, group_by_columns) %}\n\n{% set threshold = 'cast(' ~ dbt.dateadd(datepart, interval * -1, dbt.current_timestamp()) ~ ' as ' ~ ('date' if ignore_time_component else dbt.type_timestamp()) ~ ')'  %}\n\n{% if group_by_columns|length() > 0 %}\n  {% set select_gb_cols = group_by_columns|join(' ,') + ', ' %}\n  {% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n{% endif %}\n\n\nwith recency as (\n\n    select \n\n      {{ select_gb_cols }}\n      {% if ignore_time_component %}\n        cast(max({{ field }}) as date) as most_recent\n      {%- else %}\n        max({{ field }}) as most_recent\n      {%- endif %}\n\n    from {{ model }}\n\n    {{ groupby_gb_cols }}\n\n)\n\nselect\n\n    {{ select_gb_cols }}\n    most_recent,\n    {{ threshold }} as threshold\n\nfrom recency\nwhere most_recent < {{ threshold }}\n\n{% endmacro %}\n", "hash": "d7b9df7d8060fb607c068eac7ad1d963", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/recency.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/not_constant.sql": {"contents": "\n{% test not_constant(model, column_name, group_by_columns = []) %}\n  {{ return(adapter.dispatch('test_not_constant', 'dbt_utils')(model, column_name, group_by_columns)) }}\n{% endtest %}\n\n{% macro default__test_not_constant(model, column_name, group_by_columns) %}\n\n{% if group_by_columns|length() > 0 %}\n  {% set select_gb_cols = group_by_columns|join(' ,') + ', ' %}\n  {% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n{% endif %}\n\n\nselect\n    {# In TSQL, subquery aggregate columns need aliases #}\n    {# thus: a filler col name, 'filler_column' #}\n    {{select_gb_cols}}\n    count(distinct {{ column_name }}) as filler_column\n\nfrom {{ model }}\n\n  {{groupby_gb_cols}}\n\nhaving count(distinct {{ column_name }}) = 1\n\n\n{% endmacro %}\n", "hash": "4d4e5ed74c5d82993103a664cd3e648b", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/not_constant.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/accepted_range.sql": {"contents": "{% test accepted_range(model, column_name, min_value=none, max_value=none, inclusive=true) %}\n  {{ return(adapter.dispatch('test_accepted_range', 'dbt_utils')(model, column_name, min_value, max_value, inclusive)) }}\n{% endtest %}\n\n{% macro default__test_accepted_range(model, column_name, min_value=none, max_value=none, inclusive=true) %}\n\nwith meet_condition as(\n  select *\n  from {{ model }}\n),\n\nvalidation_errors as (\n  select *\n  from meet_condition\n  where\n    -- never true, defaults to an empty result set. Exists to ensure any combo of the `or` clauses below succeeds\n    1 = 2\n\n  {%- if min_value is not none %}\n    -- records with a value >= min_value are permitted. The `not` flips this to find records that don't meet the rule.\n    or not {{ column_name }} > {{- \"=\" if inclusive }} {{ min_value }}\n  {%- endif %}\n\n  {%- if max_value is not none %}\n    -- records with a value <= max_value are permitted. The `not` flips this to find records that don't meet the rule.\n    or not {{ column_name }} < {{- \"=\" if inclusive }} {{ max_value }}\n  {%- endif %}\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}\n", "hash": "de5d37bc335c5ce7defa8b1d480e2315", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/accepted_range.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/not_accepted_values.sql": {"contents": "{% test not_accepted_values(model, column_name, values, quote=True) %}\n  {{ return(adapter.dispatch('test_not_accepted_values', 'dbt_utils')(model, column_name, values, quote)) }}\n{% endtest %}\n\n{% macro default__test_not_accepted_values(model, column_name, values, quote=True) %}\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field in (\n        {% for value in values -%}\n            {% if quote -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n        )\n\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}\n", "hash": "37c7cc748301fc3c9c56bfa9441cfc33", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/not_accepted_values.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/at_least_one.sql": {"contents": "{% test at_least_one(model, column_name, group_by_columns = []) %}\n  {{ return(adapter.dispatch('test_at_least_one', 'dbt_utils')(model, column_name, group_by_columns)) }}\n{% endtest %}\n\n{% macro default__test_at_least_one(model, column_name, group_by_columns) %}\n\n{% if group_by_columns|length() > 0 %}\n  {% set select_gb_cols = group_by_columns|join(' ,') + ', ' %}\n  {% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n{% endif %}\n\nselect *\nfrom (\n    select\n        {# In TSQL, subquery aggregate columns need aliases #}\n        {# thus: a filler col name, 'filler_column' #}\n      {{select_gb_cols}}\n      count({{ column_name }}) as filler_column\n\n    from {{ model }}\n\n    {{groupby_gb_cols}}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}\n", "hash": "84b27d429687da31819751d882835a9d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/at_least_one.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/unique_combination_of_columns.sql": {"contents": "{% test unique_combination_of_columns(model, combination_of_columns, quote_columns=false) %}\n  {{ return(adapter.dispatch('test_unique_combination_of_columns', 'dbt_utils')(model, combination_of_columns, quote_columns)) }}\n{% endtest %}\n\n{% macro default__test_unique_combination_of_columns(model, combination_of_columns, quote_columns=false) %}\n\n{% if not quote_columns %}\n    {%- set column_list=combination_of_columns %}\n{% elif quote_columns %}\n    {%- set column_list=[] %}\n        {% for column in combination_of_columns -%}\n            {% set column_list = column_list.append( adapter.quote(column) ) %}\n        {%- endfor %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`quote_columns` argument for unique_combination_of_columns test must be one of [True, False] Got: '\" ~ quote ~\"'.'\"\n    ) }}\n{% endif %}\n\n{%- set columns_csv=column_list | join(', ') %}\n\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n{% endmacro %}\n", "hash": "1bda0b8ff5d0a29d2471b1f87adac377", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/unique_combination_of_columns.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/cardinality_equality.sql": {"contents": "{% test cardinality_equality(model, column_name, to, field) %}\n    {{ return(adapter.dispatch('test_cardinality_equality', 'dbt_utils')(model, column_name, to, field)) }}\n{% endtest %}\n\n{% macro default__test_cardinality_equality(model, column_name, to, field) %}\n\n{# T-SQL does not let you use numbers as aliases for columns #}\n{# Thus, no \"GROUP BY 1\" #}\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by {{ column_name }}\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by {{ field }}\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect *\nfrom unioned\n\n{% endmacro %}\n", "hash": "05156dcb155f67b74b0c899bf30261dc", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/cardinality_equality.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/expression_is_true.sql": {"contents": "{% test expression_is_true(model, expression, column_name=None) %}\n  {{ return(adapter.dispatch('test_expression_is_true', 'dbt_utils')(model, expression, column_name)) }}\n{% endtest %}\n\n{% macro default__test_expression_is_true(model, expression, column_name) %}\n\n{% set column_list = '*' if should_store_failures() else \"1\" %}\n\nselect\n    {{ column_list }}\nfrom {{ model }}\n{% if column_name is none %}\nwhere not({{ expression }})\n{%- else %}\nwhere not({{ column_name }} {{ expression }})\n{%- endif %}\n\n{% endmacro %}\n", "hash": "5bf1aa46e51ce7ec5093c1c7f6160188", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/expression_is_true.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/not_null_proportion.sql": {"contents": "{% macro test_not_null_proportion(model, group_by_columns = []) %}\n  {{ return(adapter.dispatch('test_not_null_proportion', 'dbt_utils')(model, group_by_columns, **kwargs)) }}\n{% endmacro %}\n\n{% macro default__test_not_null_proportion(model, group_by_columns) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n{% set at_least = kwargs.get('at_least', kwargs.get('arg')) %}\n{% set at_most = kwargs.get('at_most', kwargs.get('arg', 1)) %}\n\n{% if group_by_columns|length() > 0 %}\n  {% set select_gb_cols = group_by_columns|join(' ,') + ', ' %}\n  {% set groupby_gb_cols = 'group by ' + group_by_columns|join(',') %}\n{% endif %}\n\nwith validation as (\n  select\n    {{select_gb_cols}}\n    sum(case when {{ column_name }} is null then 0 else 1 end) / cast(count(*) as numeric) as not_null_proportion\n  from {{ model }}\n  {{groupby_gb_cols}}\n),\nvalidation_errors as (\n  select\n    {{select_gb_cols}}\n    not_null_proportion\n  from validation\n  where not_null_proportion < {{ at_least }} or not_null_proportion > {{ at_most }}\n)\nselect\n  *\nfrom validation_errors\n\n{% endmacro %}\n", "hash": "5077f21acaa1be717e431e6725dc69c4", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/not_null_proportion.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/sequential_values.sql": {"contents": "{% test sequential_values(model, column_name, interval=1, datepart=None, group_by_columns = []) %}\n\n  {{ return(adapter.dispatch('test_sequential_values', 'dbt_utils')(model, column_name, interval, datepart, group_by_columns)) }}\n\n{% endtest %}\n\n{% macro default__test_sequential_values(model, column_name, interval=1, datepart=None, group_by_columns = []) %}\n\n{% set previous_column_name = \"previous_\" ~ dbt_utils.slugify(column_name) %}\n\n{% if group_by_columns|length() > 0 %}\n  {% set select_gb_cols = group_by_columns|join(',') + ', ' %}\n  {% set partition_gb_cols = 'partition by ' + group_by_columns|join(',') %}\n{% endif %}\n\nwith windowed as (\n\n    select\n        {{ select_gb_cols }}\n        {{ column_name }},\n        lag({{ column_name }}) over (\n            {{partition_gb_cols}}\n            order by {{ column_name }}\n        ) as {{ previous_column_name }}\n    from {{ model }}\n),\n\nvalidation_errors as (\n    select\n        *\n    from windowed\n    {% if datepart %}\n    where not(cast({{ column_name }} as {{ dbt.type_timestamp() }})= cast({{ dbt.dateadd(datepart, interval, previous_column_name) }} as {{ dbt.type_timestamp() }}))\n    {% else %}\n    where not({{ column_name }} = {{ previous_column_name }} + {{ interval }})\n    {% endif %}\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}\n", "hash": "7012ef29a464fa5dd193dd8d4db34d23", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/sequential_values.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/equality.sql": {"contents": "{% test equality(model, compare_model, compare_columns=None) %}\n  {{ return(adapter.dispatch('test_equality', 'dbt_utils')(model, compare_model, compare_columns)) }}\n{% endtest %}\n\n{% macro default__test_equality(model, compare_model, compare_columns=None) %}\n\n{% set set_diff %}\n    count(*) + coalesce(abs(\n        sum(case when which_diff = 'a_minus_b' then 1 else 0 end) -\n        sum(case when which_diff = 'b_minus_a' then 1 else 0 end)\n    ), 0)\n{% endset %}\n\n{#-- Needs to be set at parse time, before we return '' below --#}\n{{ config(fail_calc = set_diff) }}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n\n{#-\nIf the compare_cols arg is provided, we can run this test without querying the\ninformation schema\u00a0\u2014 this allows the model to be an ephemeral model\n-#}\n\n{%- if not compare_columns -%}\n    {%- do dbt_utils._is_ephemeral(model, 'test_equality') -%}\n    {%- set compare_columns = adapter.get_columns_in_relation(model) | map(attribute='quoted') -%}\n{%- endif -%}\n\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select 'a_minus_b' as which_diff, a_minus_b.* from a_minus_b\n    union all\n    select 'b_minus_a' as which_diff, b_minus_a.* from b_minus_a\n\n)\n\nselect * from unioned\n\n{% endmacro %}\n", "hash": "ee9ad9c37536295c2fa1008aceb97633", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/equality.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/not_empty_string.sql": {"contents": "{% test not_empty_string(model, column_name, trim_whitespace=true) %}\n\n  {{ return(adapter.dispatch('test_not_empty_string', 'dbt_utils')(model, column_name, trim_whitespace)) }}\n\n{% endtest %}\n\n{% macro default__test_not_empty_string(model, column_name, trim_whitespace=true) %}\n\n    with\n    \n    all_values as (\n\n        select \n\n\n            {% if trim_whitespace == true -%}\n\n                trim({{ column_name }}) as {{ column_name }}\n\n            {%- else -%}\n\n                {{ column_name }}\n\n            {%- endif %}\n            \n        from {{ model }}\n\n    ),\n\n    errors as (\n\n        select * from all_values\n        where {{ column_name }} = ''\n\n    )\n\n    select * from errors\n\n{% endmacro %}", "hash": "32eddb11313f99ffb9473951d7ca0667", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/not_empty_string.sql"}, "dbt_packages/dbt_utils/macros/generic_tests/mutually_exclusive_ranges.sql": {"contents": "{% test mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed', zero_length_range_allowed=False) %}\n  {{ return(adapter.dispatch('test_mutually_exclusive_ranges', 'dbt_utils')(model, lower_bound_column, upper_bound_column, partition_by, gaps, zero_length_range_allowed)) }}\n{% endtest %}\n\n{% macro default__test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed', zero_length_range_allowed=False) %}\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n{% endif %}\n{% if not zero_length_range_allowed %}\n    {% set allow_zero_length_operator='<' %}\n    {% set allow_zero_length_operator_in_words='less_than' %}\n{% elif zero_length_range_allowed %}\n    {% set allow_zero_length_operator='<=' %}\n    {% set allow_zero_length_operator_in_words='less_than_or_equal_to' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`zero_length_range_allowed` argument for mutually_exclusive_ranges test must be one of [true, false] Got: '\" ~ zero_length_range_allowed ~\"'.'\"\n    ) }}\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }} as partition_by_col,\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}, {{ upper_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc, {{ upper_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions more cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound {{ allow_zero_length_operator }} upper_bound,\n            false\n        ) as lower_bound_{{ allow_zero_length_operator_in_words }}_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_{{ allow_zero_length_operator_in_words }}_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect * from validation_errors\n{% endmacro %}\n", "hash": "7e289ab00d09f99a6497239a5f6e107a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/generic_tests/mutually_exclusive_ranges.sql"}, "dbt_packages/dbt_utils/macros/jinja_helpers/pretty_log_format.sql": {"contents": "{% macro pretty_log_format(message) %}\n    {{ return(adapter.dispatch('pretty_log_format', 'dbt_utils')(message)) }}\n{% endmacro %}\n\n{% macro default__pretty_log_format(message) %}\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n{% endmacro %}\n", "hash": "ca99b538e732d4198f43d1e3f3716273", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/jinja_helpers/pretty_log_format.sql"}, "dbt_packages/dbt_utils/macros/jinja_helpers/_is_relation.sql": {"contents": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}\n", "hash": "bbd08dc4829293a4f62846e6a1638315", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/jinja_helpers/_is_relation.sql"}, "dbt_packages/dbt_utils/macros/jinja_helpers/pretty_time.sql": {"contents": "{% macro pretty_time(format='%H:%M:%S') %}\n    {{ return(adapter.dispatch('pretty_time', 'dbt_utils')(format)) }}\n{% endmacro %}\n\n{% macro default__pretty_time(format='%H:%M:%S') %}\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n{% endmacro %}\n", "hash": "37bbeebaa71384e70417feab5af15f93", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/jinja_helpers/pretty_time.sql"}, "dbt_packages/dbt_utils/macros/jinja_helpers/log_info.sql": {"contents": "{% macro log_info(message) %}\n    {{ return(adapter.dispatch('log_info', 'dbt_utils')(message)) }}\n{% endmacro %}\n\n{% macro default__log_info(message) %}\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n{% endmacro %}\n", "hash": "708be89241a19c683045d87912965aab", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/jinja_helpers/log_info.sql"}, "dbt_packages/dbt_utils/macros/jinja_helpers/slugify.sql": {"contents": "{% macro slugify(string) %}\n\n{#- Lower case the string -#}\n{% set string = string | lower %}\n{#- Replace spaces and dashes with underscores -#}\n{% set string = modules.re.sub('[ -]+', '_', string) %}\n{#- Only take letters, numbers, and underscores -#}\n{% set string = modules.re.sub('[^a-z0-9_]+', '', string) %}\n{#- Prepends \"_\" if string begins with a number -#}\n{% set string = modules.re.sub('^[0-9]', '_' + string[0], string) %}\n\n{{ return(string) }}\n\n{% endmacro %}", "hash": "15cfbd58912264b9bad5abbefa5d033f", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/jinja_helpers/slugify.sql"}, "dbt_packages/dbt_utils/macros/jinja_helpers/_is_ephemeral.sql": {"contents": "{% macro _is_ephemeral(obj, macro) %}\n    {%- if obj.is_cte -%}\n        {% set ephemeral_prefix = api.Relation.add_ephemeral_prefix('') %}\n        {% if obj.name.startswith(ephemeral_prefix) %}\n            {% set model_name = obj.name[(ephemeral_prefix|length):] %}\n        {% else %}\n            {% set model_name = obj.name %}\n        {%- endif -%}\n        {% set error_message %}\nThe `{{ macro }}` macro cannot be used with ephemeral models, as it relies on the information schema.\n\n`{{ model_name }}` is an ephemeral model. Consider making it a view or table instead.\n        {% endset %}\n        {%- do exceptions.raise_compiler_error(error_message) -%}\n    {%- endif -%}\n{% endmacro %}\n", "hash": "a80e86abde62c5dc1b9aa32743157e45", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/jinja_helpers/_is_ephemeral.sql"}, "dbt_packages/dbt_utils/macros/sql/date_spine.sql": {"contents": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n    {{ return(adapter.dispatch('get_intervals_between', 'dbt_utils')(start_date, end_date, datepart)) }}\n{%- endmacro %}\n\n{% macro default__get_intervals_between(start_date, end_date, datepart) -%}\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{ dbt.datediff(start_date, end_date, datepart) }}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}\n\n\n\n\n{% macro date_spine(datepart, start_date, end_date) %}\n    {{ return(adapter.dispatch('date_spine', 'dbt_utils')(datepart, start_date, end_date)) }}\n{%- endmacro %}\n\n{% macro default__date_spine(datepart, start_date, end_date) %}\n\n\n{# call as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dbt.dateadd(week, 1, current_date)\"\n) #}\n\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}\n", "hash": "85c572a7e9202ddfd6c41983d2cf6323", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/date_spine.sql"}, "dbt_packages/dbt_utils/macros/sql/nullcheck_table.sql": {"contents": "{% macro nullcheck_table(relation) %}\n    {{ return(adapter.dispatch('nullcheck_table', 'dbt_utils')(relation)) }}\n{% endmacro %}\n\n{% macro default__nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n\n{% endmacro %}\n", "hash": "a26b804dd6f3dcbf06e5d4e55ad89ef2", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/nullcheck_table.sql"}, "dbt_packages/dbt_utils/macros/sql/get_relations_by_pattern.sql": {"contents": "{% macro get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_pattern', 'dbt_utils')(schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}\n\n{% macro default__get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}\n", "hash": "026c3e0214fc3eb3433d4648d5a786f0", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_relations_by_pattern.sql"}, "dbt_packages/dbt_utils/macros/sql/generate_series.sql": {"contents": "{% macro get_powers_of_two(upper_bound) %}\n    {{ return(adapter.dispatch('get_powers_of_two', 'dbt_utils')(upper_bound)) }}\n{% endmacro %}\n\n{% macro default__get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}\n\n\n{% macro generate_series(upper_bound) %}\n    {{ return(adapter.dispatch('generate_series', 'dbt_utils')(upper_bound)) }}\n{% endmacro %}\n\n{% macro default__generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * power(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}\n", "hash": "faa4c49c7bc9539db3f1d5d0bde465db", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/generate_series.sql"}, "dbt_packages/dbt_utils/macros/sql/get_relations_by_prefix.sql": {"contents": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_prefix', 'dbt_utils')(schema, prefix, exclude, database)) }}\n{% endmacro %}\n\n{% macro default__get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}\n", "hash": "09b43d194d6e8b0a2b660477e7bb9e84", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_relations_by_prefix.sql"}, "dbt_packages/dbt_utils/macros/sql/get_tables_by_prefix_sql.sql": {"contents": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_prefix_sql', 'dbt_utils')(schema, prefix, exclude, database)) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n    {{ dbt_utils.get_tables_by_pattern_sql(\n        schema_pattern = schema,\n        table_pattern = prefix ~ '%',\n        exclude = exclude,\n        database = database\n    ) }}\n    \n{% endmacro %}\n", "hash": "cd8d696cd4d1f1eda855eec0e845e7ac", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_tables_by_prefix_sql.sql"}, "dbt_packages/dbt_utils/macros/sql/star.sql": {"contents": "{% macro star(from, relation_alias=False, except=[], prefix='', suffix='', quote_identifiers=True) -%}\r\n    {{ return(adapter.dispatch('star', 'dbt_utils')(from, relation_alias, except, prefix, suffix, quote_identifiers)) }}\r\n{% endmacro %}\r\n\r\n{% macro default__star(from, relation_alias=False, except=[], prefix='', suffix='', quote_identifiers=True) -%}\r\n    {%- do dbt_utils._is_relation(from, 'star') -%}\r\n    {%- do dbt_utils._is_ephemeral(from, 'star') -%}\r\n\r\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\r\n    {%- if not execute -%}\r\n        {% do return('*') %}\r\n    {%- endif -%}\r\n\r\n    {% set cols = dbt_utils.get_filtered_columns_in_relation(from, except) %}\r\n\r\n    {%- if cols|length <= 0 -%}\r\n        {% if flags.WHICH == 'compile' %}\r\n            {% set response %}\r\n*\r\n/* No columns were returned. Maybe the relation doesn't exist yet \r\nor all columns were excluded. This star is only output during  \r\ndbt compile, and exists to keep SQLFluff happy. */\r\n            {% endset %}\r\n            {% do return(response) %}\r\n        {% else %}\r\n            {% do return(\"/* no columns returned from star() macro */\") %}\r\n        {% endif %}\r\n    {%- else -%}\r\n        {%- for col in cols %}\r\n            {%- if relation_alias %}{{ relation_alias }}.{% else %}{%- endif -%}\r\n                {%- if quote_identifiers -%}\r\n                    {{ adapter.quote(col)|trim }} {%- if prefix!='' or suffix!='' %} as {{ adapter.quote(prefix ~ col ~ suffix)|trim }} {%- endif -%}\r\n                {%- else -%}\r\n                    {{ col|trim }} {%- if prefix!='' or suffix!='' %} as {{ (prefix ~ col ~ suffix)|trim }} {%- endif -%}\r\n                {% endif %}\r\n            {%- if not loop.last %},{{ '\\n  ' }}{%- endif -%}\r\n        {%- endfor -%}\r\n    {% endif %}\r\n{%- endmacro %}\r\n\r\n", "hash": "8b7a5aa417df26d6172936dc04e5e2fe", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/star.sql"}, "dbt_packages/dbt_utils/macros/sql/unpivot.sql": {"contents": "{#\nPivot values from columns to rows. Similar to pandas DataFrame melt() function.\n\nExample Usage: {{ unpivot(relation=ref('users'), cast_to='integer', exclude=['id','created_at']) }}\n\nArguments:\n    relation: Relation object, required.\n    cast_to: The datatype to cast all unpivoted columns to. Default is varchar.\n    exclude: A list of columns to keep but exclude from the unpivot operation. Default is none.\n    remove: A list of columns to remove from the resulting table. Default is none.\n    field_name: Destination table column name for the source table column names.\n    value_name: Destination table column name for the pivoted values\n#}\n\n{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value') -%}\n    {{ return(adapter.dispatch('unpivot', 'dbt_utils')(relation, cast_to, exclude, remove, field_name, value_name)) }}\n{% endmacro %}\n\n{% macro default__unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value') -%}\n\n    {% if not relation %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt.type_string() }}) as {{ field_name }},\n      cast(  {% if col.data_type == 'boolean' %}\n           {{ dbt.cast_bool_to_text(col.column) }}\n             {% else %}\n           {{ col.column }}\n             {% endif %}\n           as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}\n", "hash": "1a6624492053c107dc826609c95e14ac", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/unpivot.sql"}, "dbt_packages/dbt_utils/macros/sql/safe_divide.sql": {"contents": "{% macro safe_divide(numerator, denominator) -%}\n  {{ return(adapter.dispatch('safe_divide', 'dbt_utils')(numerator, denominator)) }}\n{%- endmacro %}\n\n{% macro default__safe_divide(numerator, denominator) %}\n    ( {{ numerator }} ) / nullif( ( {{ denominator }} ), 0)\n{% endmacro %}", "hash": "31b6089bc4f9b88f6ae90163900c33ca", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/safe_divide.sql"}, "dbt_packages/dbt_utils/macros/sql/union.sql": {"contents": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation', where=none) -%}\n    {{ return(adapter.dispatch('union_relations', 'dbt_utils')(relations, column_override, include, exclude, source_column_name, where)) }}\n{% endmacro %}\n\n{%- macro default__union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation', where=none) -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n    {%- set all_excludes = [] -%}\n    {%- set all_includes = [] -%}\n\n    {%- if exclude -%}\n        {%- for exc in exclude -%}\n            {%- do all_excludes.append(exc | lower) -%}\n        {%- endfor -%}\n    {%- endif -%}\n\n    {%- if include -%}\n        {%- for inc in include -%}\n            {%- do all_includes.append(inc | lower) -%}\n        {%- endfor -%}\n    {%- endif -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- do dbt_utils._is_ephemeral(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column | lower in all_excludes -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column | lower not in all_includes -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n    {%- set dbt_command = flags.WHICH -%}\n\n\n    {% if dbt_command in ['run', 'build'] %}\n    {% if (include | length > 0 or exclude | length > 0) and not column_superset.keys() %}\n        {%- set relations_string -%}\n            {%- for relation in relations -%}\n                {{ relation.name }}\n            {%- if not loop.last %}, {% endif -%}\n            {%- endfor -%}\n        {%- endset -%}\n\n        {%- set error_message -%}\n            There were no columns found to union for relations {{ relations_string }}\n        {%- endset -%}\n\n        {{ exceptions.raise_compiler_error(error_message) }}\n    {%- endif -%}\n    {%- endif -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                {%- if source_column_name is not none %}\n                cast({{ dbt.string_literal(relation) }} as {{ dbt.type_string() }}) as {{ source_column_name }},\n                {%- endif %}\n\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ relation }}\n\n            {% if where -%}\n            where {{ where }}\n            {%- endif %}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}\n", "hash": "6376f9ffb3d575a3849bee9882ccb17e", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/union.sql"}, "dbt_packages/dbt_utils/macros/sql/groupby.sql": {"contents": "{%- macro group_by(n) -%}\n    {{ return(adapter.dispatch('group_by', 'dbt_utils')(n)) }}\n{% endmacro %}\n\n{%- macro default__group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}\n", "hash": "27b1395991995f53ba26c5a8183deb7a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/groupby.sql"}, "dbt_packages/dbt_utils/macros/sql/deduplicate.sql": {"contents": "{%- macro deduplicate(relation, partition_by, order_by) -%}\n    {{ return(adapter.dispatch('deduplicate', 'dbt_utils')(relation, partition_by, order_by)) }}\n{% endmacro %}\n\n{%- macro default__deduplicate(relation, partition_by, order_by) -%}\n\n    with row_numbered as (\n        select\n            _inner.*,\n            row_number() over (\n                partition by {{ partition_by }}\n                order by {{ order_by }}\n            ) as rn\n        from {{ relation }} as _inner\n    )\n\n    select\n        distinct data.*\n    from {{ relation }} as data\n    {#\n    -- Not all DBs will support natural joins but the ones that do include:\n    -- Oracle, MySQL, SQLite, Redshift, Teradata, Materialize, Databricks\n    -- Apache Spark, SingleStore, Vertica\n    -- Those that do not appear to support natural joins include:\n    -- SQLServer, Trino, Presto, Rockset, Athena\n    #}\n    natural join row_numbered\n    where row_numbered.rn = 1\n\n{%- endmacro -%}\n\n{# Redshift should use default instead of Postgres #}\n{% macro redshift__deduplicate(relation, partition_by, order_by) -%}\n\n    {{ return(dbt_utils.default__deduplicate(relation, partition_by, order_by=order_by)) }}\n\n{% endmacro %}\n\n{#\n-- Postgres has the `DISTINCT ON` syntax:\n-- https://www.postgresql.org/docs/current/sql-select.html#SQL-DISTINCT\n#}\n{%- macro postgres__deduplicate(relation, partition_by, order_by) -%}\n\n    select\n        distinct on ({{ partition_by }}) *\n    from {{ relation }}\n    order by {{ partition_by }}{{ ',' ~ order_by }}\n\n{%- endmacro -%}\n\n{#\n-- Snowflake has the `QUALIFY` syntax:\n-- https://docs.snowflake.com/en/sql-reference/constructs/qualify.html\n#}\n{%- macro snowflake__deduplicate(relation, partition_by, order_by) -%}\n\n    select *\n    from {{ relation }}\n    qualify\n        row_number() over (\n            partition by {{ partition_by }}\n            order by {{ order_by }}\n        ) = 1\n\n{%- endmacro -%}\n\n{#\n--  It is more performant to deduplicate using `array_agg` with a limit\n--  clause in BigQuery:\n--  https://github.com/dbt-labs/dbt-utils/issues/335#issuecomment-788157572\n#}\n{%- macro bigquery__deduplicate(relation, partition_by, order_by) -%}\n\n    select unique.*\n    from (\n        select\n            array_agg (\n                original\n                order by {{ order_by }}\n                limit 1\n            )[offset(0)] unique\n        from {{ relation }} original\n        group by {{ partition_by }}\n    )\n\n{%- endmacro -%}\n", "hash": "3bd2b4e447e219071b5429a7e4d4b34a", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/deduplicate.sql"}, "dbt_packages/dbt_utils/macros/sql/surrogate_key.sql": {"contents": "{%- macro surrogate_key(field_list) -%}\n    {% set frustrating_jinja_feature = varargs %}\n    {{ return(adapter.dispatch('surrogate_key', 'dbt_utils')(field_list, *varargs)) }}\n{% endmacro %}\n\n{%- macro default__surrogate_key(field_list) -%}\n\n{%- set error_message = '\nWarning: `dbt_utils.surrogate_key` has been replaced by \\\n`dbt_utils.generate_surrogate_key`. The new macro treats null values \\\ndifferently to empty strings. To restore the behaviour of the original \\\nmacro, add a global variable in dbt_project.yml called \\\n`surrogate_key_treat_nulls_as_empty_strings` to your \\\ndbt_project.yml file with a value of True. \\\nThe {}.{} model triggered this warning. \\\n'.format(model.package_name, model.name) -%}\n\n{%- do exceptions.raise_compiler_error(error_message) -%}\n\n{%- endmacro -%}\n", "hash": "67f665f558583703b02c75e4b96cf3df", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/surrogate_key.sql"}, "dbt_packages/dbt_utils/macros/sql/safe_add.sql": {"contents": "{%- macro safe_add(field_list) -%}\n    {{ return(adapter.dispatch('safe_add', 'dbt_utils')(field_list)) }}\n{% endmacro %}\n\n{%- macro default__safe_add(field_list) -%}\n\n{%- if field_list is not iterable or field_list is string or field_list is mapping -%}\n\n{%- set error_message = '\nWarning: the `safe_add` macro now takes a single list argument instead of \\\nstring arguments. The {}.{} model triggered this warning. \\\n'.format(model.package_name, model.name) -%}\n\n{%- do exceptions.warn(error_message) -%}\n\n{%- endif -%}\n\n{% set fields = [] %}\n\n{%- for field in field_list -%}\n\n    {% do fields.append(\"coalesce(\" ~ field ~ \", 0)\") %}\n\n{%- endfor -%}\n\n{{ fields|join(' +\\n  ') }}\n\n{%- endmacro -%}\n", "hash": "0f5e9ed4e3425b527b77b48eca08fe93", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/safe_add.sql"}, "dbt_packages/dbt_utils/macros/sql/nullcheck.sql": {"contents": "{% macro nullcheck(cols) %}\n    {{ return(adapter.dispatch('nullcheck', 'dbt_utils')(cols)) }}\n{% endmacro %}\n\n{% macro default__nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}\n", "hash": "81f5499e4d897e05a9a4889a13bc0be0", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/nullcheck.sql"}, "dbt_packages/dbt_utils/macros/sql/get_tables_by_pattern_sql.sql": {"contents": "{% macro get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_pattern_sql', 'dbt_utils')\n        (schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}\n\n{% macro default__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n        select distinct\n            table_schema as {{ adapter.quote('table_schema') }},\n            table_name as {{ adapter.quote('table_name') }},\n            {{ dbt_utils.get_table_types_sql() }}\n        from {{ database }}.information_schema.tables\n        where table_schema ilike '{{ schema_pattern }}'\n        and table_name ilike '{{ table_pattern }}'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}\n\n\n{% macro bigquery__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {% if '%' in schema_pattern %}\n        {% set schemata=dbt_utils._bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% else %}\n        {% set schemata=[schema_pattern] %}\n    {% endif %}\n\n    {% set sql %}\n        {% for schema in schemata %}\n            select distinct\n                table_schema,\n                table_name,\n                {{ dbt_utils.get_table_types_sql() }}\n\n            from {{ adapter.quote(database) }}.{{ schema }}.INFORMATION_SCHEMA.TABLES\n            where lower(table_name) like lower ('{{ table_pattern }}')\n                and lower(table_name) not like lower ('{{ exclude }}')\n\n            {% if not loop.last %} union all {% endif %}\n\n        {% endfor %}\n    {% endset %}\n\n    {{ return(sql) }}\n\n{% endmacro %}\n\n\n{% macro _bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% if execute %}\n\n        {% set sql %}\n        select schema_name from {{ adapter.quote(database) }}.INFORMATION_SCHEMA.SCHEMATA\n        where lower(schema_name) like lower('{{ schema_pattern }}')\n        {% endset %}\n\n        {% set results=run_query(sql) %}\n\n        {% set schemata=results.columns['schema_name'].values() %}\n\n        {{ return(schemata) }}\n\n    {% else %}\n\n        {{ return([]) }}\n\n    {% endif %}\n\n\n{% endmacro %}\n", "hash": "5d49381df15562623ea83ddaa7e273a1", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_tables_by_pattern_sql.sql"}, "dbt_packages/dbt_utils/macros/sql/get_column_values.sql": {"contents": "{% macro get_column_values(table, column, order_by='count(*) desc', max_records=none, default=none, where=none) -%}\n    {{ return(adapter.dispatch('get_column_values', 'dbt_utils')(table, column, order_by, max_records, default, where)) }}\n{% endmacro %}\n\n{% macro default__get_column_values(table, column, order_by='count(*) desc', max_records=none, default=none, where=none) -%}\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {% set default = [] if not default %}\n        {{ return(default) }}\n    {% endif %}\n\n    {%- do dbt_utils._is_ephemeral(table, 'get_column_values') -%}\n\n    {# Not all relations are tables. Renaming for internal clarity without breaking functionality for anyone using named arguments #}\n    {# TODO: Change the method signature in a future 0.x.0 release #}\n    {%- set target_relation = table -%}\n\n    {# adapter.load_relation is a convenience wrapper to avoid building a Relation when we already have one #}\n    {% set relation_exists = (load_relation(target_relation)) is not none %}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not relation_exists and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ target_relation ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not relation_exists and default is not none -%}\n\n          {{ log(\"Relation \" ~ target_relation ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n\n            {% if where is not none %}\n            where {{ where }}\n            {% endif %}\n\n            group by {{ column }}\n            order by {{ order_by }}\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}\n", "hash": "966d238f1a0d15bbdcf2b402d61f2fc9", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_column_values.sql"}, "dbt_packages/dbt_utils/macros/sql/pivot.sql": {"contents": "{#\nPivot values from rows to columns.\n\nExample:\n\n    Input: `public.test`\n\n    | size | color |\n    |------+-------|\n    | S    | red   |\n    | S    | blue  |\n    | S    | red   |\n    | M    | red   |\n\n    select\n      size,\n      {{ dbt_utils.pivot('color', dbt_utils.get_column_values('public.test',\n                                                              'color')) }}\n    from public.test\n    group by size\n\n    Output:\n\n    | size | red | blue |\n    |------+-----+------|\n    | S    | 2   | 1    |\n    | M    | 1   | 0    |\n\nArguments:\n    column: Column name, required\n    values: List of row values to turn into columns, required\n    alias: Whether to create column aliases, default is True\n    agg: SQL aggregation function, default is sum\n    cmp: SQL value comparison, default is =\n    prefix: Column alias prefix, default is blank\n    suffix: Column alias postfix, default is blank\n    then_value: Value to use if comparison succeeds, default is 1\n    else_value: Value to use if comparison fails, default is 0\n    quote_identifiers: Whether to surround column aliases with double quotes, default is true\n    distinct: Whether to use distinct in the aggregation, default is False\n#}\n\n{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n    {{ return(adapter.dispatch('pivot', 'dbt_utils')(column, values, alias, agg, cmp, prefix, suffix, then_value, else_value, quote_identifiers, distinct)) }}\n{% endmacro %}\n\n{% macro default__pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n  {% for value in values %}\n    {{ agg }}(\n      {% if distinct %} distinct {% endif %}\n      case\n      when {{ column }} {{ cmp }} '{{ dbt.escape_single_quotes(value) }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ value ~ suffix) }}\n      {% else %}\n        as {{ dbt_utils.slugify(prefix ~ value ~ suffix) }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}\n", "hash": "6308ab0808bf3ec9e77050f324601eb7", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/pivot.sql"}, "dbt_packages/dbt_utils/macros/sql/get_filtered_columns_in_relation.sql": {"contents": "{% macro get_filtered_columns_in_relation(from, except=[]) -%}\n    {{ return(adapter.dispatch('get_filtered_columns_in_relation', 'dbt_utils')(from, except)) }}\n{% endmacro %}\n\n{% macro default__get_filtered_columns_in_relation(from, except=[]) -%}\n    {%- do dbt_utils._is_relation(from, 'get_filtered_columns_in_relation') -%}\n    {%- do dbt_utils._is_ephemeral(from, 'get_filtered_columns_in_relation') -%}\n\n    {# -- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n    {%- set except = except | map(\"lower\") | list %}\n    {%- for col in cols -%}\n        {%- if col.column|lower not in except -%}\n            {% do include_cols.append(col.column) %}\n        {%- endif %}\n    {%- endfor %}\n\n    {{ return(include_cols) }}\n\n{%- endmacro %}", "hash": "1b1381c8e36232fe43f024c21133a9a1", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_filtered_columns_in_relation.sql"}, "dbt_packages/dbt_utils/macros/sql/width_bucket.sql": {"contents": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ return(adapter.dispatch('width_bucket', 'dbt_utils') (expr, min_value, max_value, num_buckets)) }}\n{% endmacro %}\n\n\n{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt.safe_cast(expr, dbt.type_numeric() ) }},\n                    {{ dbt.safe_cast(bin_size, dbt.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt.safe_cast(expr, dbt.type_numeric() ) }} %\n                {{ dbt.safe_cast(bin_size, dbt.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}\n\n{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}\n", "hash": "a67eb86109e7aeb0c3ddbd8c71f39d86", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/width_bucket.sql"}, "dbt_packages/dbt_utils/macros/sql/get_query_results_as_dict.sql": {"contents": "{% macro get_query_results_as_dict(query) %}\n    {{ return(adapter.dispatch('get_query_results_as_dict', 'dbt_utils')(query)) }}\n{% endmacro %}\n\n{% macro default__get_query_results_as_dict(query) %}\n\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}\n", "hash": "2b31c4e82dbcde1c02b2ac2409c25e12", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_query_results_as_dict.sql"}, "dbt_packages/dbt_utils/macros/sql/generate_surrogate_key.sql": {"contents": "{%- macro generate_surrogate_key(field_list) -%}\n    {{ return(adapter.dispatch('generate_surrogate_key', 'dbt_utils')(field_list)) }}\n{% endmacro %}\n\n{%- macro default__generate_surrogate_key(field_list) -%}\n\n{% if var('surrogate_key_treat_nulls_as_empty_strings', False) %}\n    {% set default_null_value = \"\" %}\n{% else %}\n    {% set default_null_value = '_dbt_utils_surrogate_key_null_'%}\n{% endif %}\n\n{%- set fields = [] -%}\n\n{%- for field in field_list -%}\n\n    {%- do fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt.type_string() ~ \"), '\" ~ default_null_value  ~\"')\"\n    ) -%}\n\n    {%- if not loop.last %}\n        {%- do fields.append(\"'-'\") -%}\n    {%- endif -%}\n\n{%- endfor -%}\n\n{{ dbt.hash(dbt.concat(fields)) }}\n\n{%- endmacro -%}\n", "hash": "12354e6cb9fa3deb841c2346f034a059", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/generate_surrogate_key.sql"}, "dbt_packages/dbt_utils/macros/sql/get_table_types_sql.sql": {"contents": "{%- macro get_table_types_sql() -%}\n  {{ return(adapter.dispatch('get_table_types_sql', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n{% macro default__get_table_types_sql() %}\n            case table_type\n                when 'BASE TABLE' then 'table'\n                when 'EXTERNAL TABLE' then 'external'\n                when 'MATERIALIZED VIEW' then 'materializedview'\n                else lower(table_type)\n            end as {{ adapter.quote('table_type') }}\n{% endmacro %}\n\n\n{% macro postgres__get_table_types_sql() %}\n            case table_type\n                when 'BASE TABLE' then 'table'\n                when 'FOREIGN' then 'external'\n                when 'MATERIALIZED VIEW' then 'materializedview'\n                else lower(table_type)\n            end as {{ adapter.quote('table_type') }}\n{% endmacro %}\n", "hash": "c053a56f6dd46698779c3d911aab8e29", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_table_types_sql.sql"}, "dbt_packages/dbt_utils/macros/sql/get_single_value.sql": {"contents": "{% macro get_single_value(query, default=none) %}\n    {{ return(adapter.dispatch('get_single_value', 'dbt_utils')(query, default)) }}\n{% endmacro %}\n\n{% macro default__get_single_value(query, default) %}\n\n{# This macro returns the (0, 0) record in a query, i.e. the first row of the first column #}\n\n    {%- call statement('get_query_result', fetch_result=True, auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {%- if execute -%}\n\n        {% set r = load_result('get_query_result').table.columns[0].values() %}\n        {% if r | length == 0 %}\n            {% do print('Query `' ~ query ~ '` returned no rows. Using the default value: ' ~ default) %}\n            {% set sql_result = default %}\n        {% else %}\n            {% set sql_result = r[0] %}\n        {% endif %}\n        \n    {%- else -%}\n    \n        {% set sql_result = default %}\n    \n    {%- endif -%}\n\n    {% do return(sql_result) %}\n\n{% endmacro %}", "hash": "a203b8cf8486cafe41a0daa0cba2772d", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/get_single_value.sql"}, "dbt_packages/dbt_utils/macros/sql/haversine_distance.sql": {"contents": "{#\nThis calculates the distance between two sets of latitude and longitude.\nThe formula is from the following blog post:\nhttp://daynebatten.com/2015/09/latitude-longitude-distance-sql/\n\nThe arguments should be float type.\n#}\n\n{% macro degrees_to_radians(degrees) -%}\n    acos(-1) * {{degrees}} / 180\n{%- endmacro %}\n\n{% macro haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n    {{ return(adapter.dispatch('haversine_distance', 'dbt_utils')(lat1,lon1,lat2,lon2,unit)) }}\n{% endmacro %}\n\n{% macro default__haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n{%- if unit == 'mi' %}\n    {% set conversion_rate = 1 %}\n{% elif unit == 'km' %}\n    {% set conversion_rate = 1.60934 %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\"unit input must be one of 'mi' or 'km'. Got \" ~ unit) }}\n{% endif %}\n\n    2 * 3961 * asin(sqrt(power((sin(radians(({{ lat2 }} - {{ lat1 }}) / 2))), 2) +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    power((sin(radians(({{ lon2 }} - {{ lon1 }}) / 2))), 2))) * {{ conversion_rate }}\n\n{%- endmacro %}\n\n\n\n{% macro bigquery__haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n{% set radians_lat1 = dbt_utils.degrees_to_radians(lat1) %}\n{% set radians_lat2 = dbt_utils.degrees_to_radians(lat2) %}\n{% set radians_lon1 = dbt_utils.degrees_to_radians(lon1) %}\n{% set radians_lon2 = dbt_utils.degrees_to_radians(lon2) %}\n{%- if unit == 'mi' %}\n    {% set conversion_rate = 1 %}\n{% elif unit == 'km' %}\n    {% set conversion_rate = 1.60934 %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\"unit input must be one of 'mi' or 'km'. Got \" ~ unit) }}\n{% endif %}\n    2 * 3961 * asin(sqrt(power(sin(({{ radians_lat2 }} - {{ radians_lat1 }}) / 2), 2) +\n    cos({{ radians_lat1 }}) * cos({{ radians_lat2 }}) *\n    power(sin(({{ radians_lon2 }} - {{ radians_lon1 }}) / 2), 2))) * {{ conversion_rate }}\n\n{%- endmacro %}\n\n", "hash": "889541de7c9b60ef6433ebfa6eed2834", "path": "/Users/afinkelstein/work/infra-dbt/test_dbt/dbt_packages/dbt_utils/macros/sql/haversine_distance.sql"}}}